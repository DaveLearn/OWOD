[05/07 16:05:54] detectron2 INFO: Rank of current process: 0. World size: 4
[05/07 16:05:55] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 16:05:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 16:05:55] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 16:05:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 16:05:55] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/07 16:05:55] d2.utils.env INFO: Using a generated random seed 55505362
[05/07 16:05:56] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 16:05:56] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 16:05:56] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 16:05:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 16:05:57] d2.data.build INFO: Known classes: range(0, 80)
[05/07 16:05:57] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 16:05:58] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 16:05:58] d2.data.build INFO: Number of datapoints: 10246
[05/07 16:05:58] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 16:05:58] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 16:05:58] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 16:05:58] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 16:05:58] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/07 16:06:07] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1482 s / img. ETA=0:06:20
[05/07 16:06:12] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1426 s / img. ETA=0:06:02
[05/07 16:06:18] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1444 s / img. ETA=0:06:02
[05/07 16:06:23] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1474 s / img. ETA=0:06:04
[05/07 16:06:28] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1487 s / img. ETA=0:06:02
[05/07 16:06:33] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1503 s / img. ETA=0:06:02
[05/07 16:06:38] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1508 s / img. ETA=0:05:58
[05/07 16:06:43] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1498 s / img. ETA=0:05:50
[05/07 16:06:48] d2.evaluation.evaluator INFO: Inference done 281/2562. 0.1505 s / img. ETA=0:05:47
[05/07 16:06:54] d2.evaluation.evaluator INFO: Inference done 314/2562. 0.1506 s / img. ETA=0:05:42
[05/07 16:06:59] d2.evaluation.evaluator INFO: Inference done 347/2562. 0.1509 s / img. ETA=0:05:38
[05/07 16:07:04] d2.evaluation.evaluator INFO: Inference done 379/2562. 0.1513 s / img. ETA=0:05:34
[05/07 16:07:09] d2.evaluation.evaluator INFO: Inference done 414/2562. 0.1508 s / img. ETA=0:05:27
[05/07 16:07:14] d2.evaluation.evaluator INFO: Inference done 447/2562. 0.1509 s / img. ETA=0:05:22
[05/07 16:07:19] d2.evaluation.evaluator INFO: Inference done 482/2562. 0.1503 s / img. ETA=0:05:16
[05/07 16:07:24] d2.evaluation.evaluator INFO: Inference done 518/2562. 0.1494 s / img. ETA=0:05:08
[05/07 16:07:29] d2.evaluation.evaluator INFO: Inference done 553/2562. 0.1489 s / img. ETA=0:05:02
[05/07 16:07:34] d2.evaluation.evaluator INFO: Inference done 587/2562. 0.1489 s / img. ETA=0:04:57
[05/07 16:07:39] d2.evaluation.evaluator INFO: Inference done 620/2562. 0.1492 s / img. ETA=0:04:53
[05/07 16:07:44] d2.evaluation.evaluator INFO: Inference done 654/2562. 0.1491 s / img. ETA=0:04:47
[05/07 16:07:49] d2.evaluation.evaluator INFO: Inference done 687/2562. 0.1492 s / img. ETA=0:04:42
[05/07 16:07:54] d2.evaluation.evaluator INFO: Inference done 717/2562. 0.1499 s / img. ETA=0:04:39
[05/07 16:08:00] d2.evaluation.evaluator INFO: Inference done 748/2562. 0.1506 s / img. ETA=0:04:36
[05/07 16:08:05] d2.evaluation.evaluator INFO: Inference done 781/2562. 0.1506 s / img. ETA=0:04:31
[05/07 16:08:10] d2.evaluation.evaluator INFO: Inference done 814/2562. 0.1508 s / img. ETA=0:04:26
[05/07 16:08:15] d2.evaluation.evaluator INFO: Inference done 845/2562. 0.1512 s / img. ETA=0:04:22
[05/07 16:08:20] d2.evaluation.evaluator INFO: Inference done 877/2562. 0.1514 s / img. ETA=0:04:18
[05/07 16:08:25] d2.evaluation.evaluator INFO: Inference done 910/2562. 0.1514 s / img. ETA=0:04:13
[05/07 16:08:30] d2.evaluation.evaluator INFO: Inference done 942/2562. 0.1517 s / img. ETA=0:04:08
[05/07 16:08:35] d2.evaluation.evaluator INFO: Inference done 974/2562. 0.1520 s / img. ETA=0:04:04
[05/07 16:08:40] d2.evaluation.evaluator INFO: Inference done 1008/2562. 0.1518 s / img. ETA=0:03:58
[05/07 16:08:45] d2.evaluation.evaluator INFO: Inference done 1042/2562. 0.1516 s / img. ETA=0:03:53
[05/07 16:08:51] d2.evaluation.evaluator INFO: Inference done 1073/2562. 0.1519 s / img. ETA=0:03:48
[05/07 16:08:56] d2.evaluation.evaluator INFO: Inference done 1105/2562. 0.1520 s / img. ETA=0:03:43
[05/07 16:09:01] d2.evaluation.evaluator INFO: Inference done 1139/2562. 0.1519 s / img. ETA=0:03:38
[05/07 16:09:06] d2.evaluation.evaluator INFO: Inference done 1175/2562. 0.1516 s / img. ETA=0:03:32
[05/07 16:09:11] d2.evaluation.evaluator INFO: Inference done 1204/2562. 0.1520 s / img. ETA=0:03:28
[05/07 16:09:16] d2.evaluation.evaluator INFO: Inference done 1237/2562. 0.1521 s / img. ETA=0:03:23
[05/07 16:09:21] d2.evaluation.evaluator INFO: Inference done 1269/2562. 0.1522 s / img. ETA=0:03:19
[05/07 16:09:26] d2.evaluation.evaluator INFO: Inference done 1303/2562. 0.1521 s / img. ETA=0:03:13
[05/07 16:09:31] d2.evaluation.evaluator INFO: Inference done 1334/2562. 0.1524 s / img. ETA=0:03:09
[05/07 16:09:36] d2.evaluation.evaluator INFO: Inference done 1366/2562. 0.1525 s / img. ETA=0:03:04
[05/07 16:09:41] d2.evaluation.evaluator INFO: Inference done 1393/2562. 0.1531 s / img. ETA=0:03:01
[05/07 16:09:46] d2.evaluation.evaluator INFO: Inference done 1427/2562. 0.1529 s / img. ETA=0:02:55
[05/07 16:09:52] d2.evaluation.evaluator INFO: Inference done 1462/2562. 0.1527 s / img. ETA=0:02:49
[05/07 16:09:57] d2.evaluation.evaluator INFO: Inference done 1495/2562. 0.1527 s / img. ETA=0:02:44
[05/07 16:10:02] d2.evaluation.evaluator INFO: Inference done 1528/2562. 0.1527 s / img. ETA=0:02:39
[05/07 16:10:07] d2.evaluation.evaluator INFO: Inference done 1561/2562. 0.1527 s / img. ETA=0:02:34
[05/07 16:10:12] d2.evaluation.evaluator INFO: Inference done 1596/2562. 0.1525 s / img. ETA=0:02:29
[05/07 16:10:17] d2.evaluation.evaluator INFO: Inference done 1632/2562. 0.1522 s / img. ETA=0:02:23
[05/07 16:10:22] d2.evaluation.evaluator INFO: Inference done 1664/2562. 0.1522 s / img. ETA=0:02:18
[05/07 16:10:27] d2.evaluation.evaluator INFO: Inference done 1699/2562. 0.1521 s / img. ETA=0:02:12
[05/07 16:10:32] d2.evaluation.evaluator INFO: Inference done 1733/2562. 0.1520 s / img. ETA=0:02:07
[05/07 16:10:37] d2.evaluation.evaluator INFO: Inference done 1761/2562. 0.1524 s / img. ETA=0:02:03
[05/07 16:10:42] d2.evaluation.evaluator INFO: Inference done 1791/2562. 0.1526 s / img. ETA=0:01:59
[05/07 16:10:47] d2.evaluation.evaluator INFO: Inference done 1822/2562. 0.1528 s / img. ETA=0:01:54
[05/07 16:10:52] d2.evaluation.evaluator INFO: Inference done 1855/2562. 0.1527 s / img. ETA=0:01:49
[05/07 16:10:57] d2.evaluation.evaluator INFO: Inference done 1888/2562. 0.1527 s / img. ETA=0:01:44
[05/07 16:11:02] d2.evaluation.evaluator INFO: Inference done 1922/2562. 0.1526 s / img. ETA=0:01:38
[05/07 16:11:07] d2.evaluation.evaluator INFO: Inference done 1954/2562. 0.1527 s / img. ETA=0:01:33
[05/07 16:11:12] d2.evaluation.evaluator INFO: Inference done 1988/2562. 0.1525 s / img. ETA=0:01:28
[05/07 16:11:17] d2.evaluation.evaluator INFO: Inference done 2023/2562. 0.1524 s / img. ETA=0:01:23
[05/07 16:11:23] d2.evaluation.evaluator INFO: Inference done 2056/2562. 0.1524 s / img. ETA=0:01:17
[05/07 16:11:28] d2.evaluation.evaluator INFO: Inference done 2089/2562. 0.1524 s / img. ETA=0:01:12
[05/07 16:11:33] d2.evaluation.evaluator INFO: Inference done 2120/2562. 0.1525 s / img. ETA=0:01:08
[05/07 16:11:38] d2.evaluation.evaluator INFO: Inference done 2150/2562. 0.1528 s / img. ETA=0:01:03
[05/07 16:11:43] d2.evaluation.evaluator INFO: Inference done 2182/2562. 0.1528 s / img. ETA=0:00:58
[05/07 16:11:48] d2.evaluation.evaluator INFO: Inference done 2216/2562. 0.1527 s / img. ETA=0:00:53
[05/07 16:11:53] d2.evaluation.evaluator INFO: Inference done 2251/2562. 0.1525 s / img. ETA=0:00:47
[05/07 16:11:58] d2.evaluation.evaluator INFO: Inference done 2284/2562. 0.1526 s / img. ETA=0:00:42
[05/07 16:12:03] d2.evaluation.evaluator INFO: Inference done 2316/2562. 0.1527 s / img. ETA=0:00:37
[05/07 16:12:08] d2.evaluation.evaluator INFO: Inference done 2347/2562. 0.1528 s / img. ETA=0:00:33
[05/07 16:12:13] d2.evaluation.evaluator INFO: Inference done 2378/2562. 0.1529 s / img. ETA=0:00:28
[05/07 16:12:18] d2.evaluation.evaluator INFO: Inference done 2410/2562. 0.1529 s / img. ETA=0:00:23
[05/07 16:12:24] d2.evaluation.evaluator INFO: Inference done 2444/2562. 0.1529 s / img. ETA=0:00:18
[05/07 16:12:29] d2.evaluation.evaluator INFO: Inference done 2479/2562. 0.1528 s / img. ETA=0:00:12
[05/07 16:12:34] d2.evaluation.evaluator INFO: Inference done 2508/2562. 0.1530 s / img. ETA=0:00:08
[05/07 16:12:39] d2.evaluation.evaluator INFO: Inference done 2540/2562. 0.1531 s / img. ETA=0:00:03
[05/07 16:12:43] d2.evaluation.evaluator INFO: Total inference time: 0:06:36.305987 (0.154989 s / img per device, on 4 devices)
[05/07 16:12:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:31 (0.153110 s / img per device, on 4 devices)
[05/07 16:13:20] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/07 16:13:20] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 2037 predictions.
[05/07 16:13:22] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 2901 predictions.
[05/07 16:13:22] d2.evaluation.pascal_voc_evaluation INFO: bird has 2264 predictions.
[05/07 16:13:22] d2.evaluation.pascal_voc_evaluation INFO: boat has 3579 predictions.
[05/07 16:13:22] d2.evaluation.pascal_voc_evaluation INFO: bottle has 15544 predictions.
[05/07 16:13:23] d2.evaluation.pascal_voc_evaluation INFO: bus has 2429 predictions.
[05/07 16:13:23] d2.evaluation.pascal_voc_evaluation INFO: car has 21340 predictions.
[05/07 16:13:24] d2.evaluation.pascal_voc_evaluation INFO: cat has 2316 predictions.
[05/07 16:13:24] d2.evaluation.pascal_voc_evaluation INFO: chair has 21435 predictions.
[05/07 16:13:25] d2.evaluation.pascal_voc_evaluation INFO: cow has 2126 predictions.
[05/07 16:13:25] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 10604 predictions.
[05/07 16:13:25] d2.evaluation.pascal_voc_evaluation INFO: dog has 3155 predictions.
[05/07 16:13:26] d2.evaluation.pascal_voc_evaluation INFO: horse has 2513 predictions.
[05/07 16:13:26] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 2708 predictions.
[05/07 16:13:26] d2.evaluation.pascal_voc_evaluation INFO: person has 85953 predictions.
[05/07 16:13:29] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 7037 predictions.
[05/07 16:13:30] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1395 predictions.
[05/07 16:13:30] d2.evaluation.pascal_voc_evaluation INFO: sofa has 5117 predictions.
[05/07 16:13:30] d2.evaluation.pascal_voc_evaluation INFO: train has 2870 predictions.
[05/07 16:13:30] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 4541 predictions.
[05/07 16:13:31] d2.evaluation.pascal_voc_evaluation INFO: truck has 8659 predictions.
[05/07 16:13:31] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 2981 predictions.
[05/07 16:13:31] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1428 predictions.
[05/07 16:13:31] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1450 predictions.
[05/07 16:13:32] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1489 predictions.
[05/07 16:13:32] d2.evaluation.pascal_voc_evaluation INFO: bench has 6334 predictions.
[05/07 16:13:32] d2.evaluation.pascal_voc_evaluation INFO: elephant has 2556 predictions.
[05/07 16:13:32] d2.evaluation.pascal_voc_evaluation INFO: bear has 2595 predictions.
[05/07 16:13:32] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1358 predictions.
[05/07 16:13:33] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1325 predictions.
[05/07 16:13:33] d2.evaluation.pascal_voc_evaluation INFO: backpack has 4739 predictions.
[05/07 16:13:33] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 2490 predictions.
[05/07 16:13:33] d2.evaluation.pascal_voc_evaluation INFO: handbag has 5789 predictions.
[05/07 16:13:34] d2.evaluation.pascal_voc_evaluation INFO: tie has 686 predictions.
[05/07 16:13:34] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 3514 predictions.
[05/07 16:13:34] d2.evaluation.pascal_voc_evaluation INFO: microwave has 2380 predictions.
[05/07 16:13:34] d2.evaluation.pascal_voc_evaluation INFO: oven has 3512 predictions.
[05/07 16:13:34] d2.evaluation.pascal_voc_evaluation INFO: toaster has 2540 predictions.
[05/07 16:13:35] d2.evaluation.pascal_voc_evaluation INFO: sink has 6174 predictions.
[05/07 16:13:35] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 5038 predictions.
[05/07 16:13:35] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2023 predictions.
[05/07 16:13:35] d2.evaluation.pascal_voc_evaluation INFO: skis has 1452 predictions.
[05/07 16:13:36] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2011 predictions.
[05/07 16:13:36] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 1758 predictions.
[05/07 16:13:36] d2.evaluation.pascal_voc_evaluation INFO: kite has 1909 predictions.
[05/07 16:13:36] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1950 predictions.
[05/07 16:13:36] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 2011 predictions.
[05/07 16:13:37] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 3039 predictions.
[05/07 16:13:37] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 3367 predictions.
[05/07 16:13:37] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1920 predictions.
[05/07 16:13:37] d2.evaluation.pascal_voc_evaluation INFO: banana has 1546 predictions.
[05/07 16:13:37] d2.evaluation.pascal_voc_evaluation INFO: apple has 1027 predictions.
[05/07 16:13:38] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 2769 predictions.
[05/07 16:13:38] d2.evaluation.pascal_voc_evaluation INFO: orange has 1440 predictions.
[05/07 16:13:38] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 2495 predictions.
[05/07 16:13:38] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1452 predictions.
[05/07 16:13:39] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 762 predictions.
[05/07 16:13:39] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1869 predictions.
[05/07 16:13:39] d2.evaluation.pascal_voc_evaluation INFO: donut has 1556 predictions.
[05/07 16:13:39] d2.evaluation.pascal_voc_evaluation INFO: cake has 2398 predictions.
[05/07 16:13:39] d2.evaluation.pascal_voc_evaluation INFO: bed has 5001 predictions.
[05/07 16:13:40] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1863 predictions.
[05/07 16:13:40] d2.evaluation.pascal_voc_evaluation INFO: laptop has 2573 predictions.
[05/07 16:13:40] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1385 predictions.
[05/07 16:13:40] d2.evaluation.pascal_voc_evaluation INFO: remote has 1076 predictions.
[05/07 16:13:41] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1266 predictions.
[05/07 16:13:41] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 2874 predictions.
[05/07 16:13:41] d2.evaluation.pascal_voc_evaluation INFO: book has 12130 predictions.
[05/07 16:13:41] d2.evaluation.pascal_voc_evaluation INFO: clock has 2769 predictions.
[05/07 16:13:41] d2.evaluation.pascal_voc_evaluation INFO: vase has 3334 predictions.
[05/07 16:13:42] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1948 predictions.
[05/07 16:13:42] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 3911 predictions.
[05/07 16:13:42] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1248 predictions.
[05/07 16:13:42] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1310 predictions.
[05/07 16:13:42] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 2008 predictions.
[05/07 16:13:43] d2.evaluation.pascal_voc_evaluation INFO: cup has 10013 predictions.
[05/07 16:13:43] d2.evaluation.pascal_voc_evaluation INFO: fork has 1330 predictions.
[05/07 16:13:43] d2.evaluation.pascal_voc_evaluation INFO: knife has 3401 predictions.
[05/07 16:13:43] d2.evaluation.pascal_voc_evaluation INFO: spoon has 2955 predictions.
[05/07 16:13:44] d2.evaluation.pascal_voc_evaluation INFO: bowl has 8572 predictions.
[05/07 16:13:44] d2.evaluation.pascal_voc_evaluation INFO: unknown has 11838 predictions.
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['65.1', '51.5', '50.0', '33.0', '21.6', '58.3', '47.9', '72.3', '19.4', '65.7', '14.2', '71.9', '77.6', '61.0', '46.2', '24.2', '59.1', '42.9', '67.5', '53.2', '13.4', '9.9', '50.7', '49.1', '44.5', '8.6', '55.7', '58.0', '73.0', '72.2', '2.4', '14.7', '1.4', '5.1', '8.6', '10.1', '5.3', '10.8', '8.1', '12.7', '31.9', '6.1', '9.1', '21.7', '14.7', '9.9', '10.7', '17.7', '14.8', '28.7', '8.2', '3.7', '9.6', '7.2', '8.4', '2.5', '6.8', '15.3', '11.2', '6.2', '18.7', '25.9', '31.2', '28.0', '7.4', '22.8', '11.1', '2.4', '30.1', '11.5', '10.4', '26.6', '0.0', '1.1', '4.7', '7.9', '2.9', '1.0', '1.8', '7.6', 'nan']
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['14.4', '15.4', '20.9', '8.7', '6.3', '13.3', '10.5', '19.9', '6.6', '12.6', '5.6', '19.2', '15.1', '16.0', '13.9', '8.3', '18.3', '7.9', '11.6', '10.7', '3.2', '7.3', '4.9', '3.7', '2.8', '2.5', '8.2', '2.4', '17.6', '15.4', '2.2', '7.8', '1.7', '7.6', '3.3', '2.0', '2.4', '0.2', '2.3', '1.8', '4.3', '5.2', '1.7', '6.8', '8.9', '3.0', '3.1', '3.5', '4.3', '6.7', '10.2', '7.1', '4.0', '8.6', '6.6', '6.3', '6.8', '10.5', '8.0', '6.7', '2.4', '7.4', '6.5', '4.8', '6.2', '8.4', '3.9', '3.3', '6.4', '4.4', '0.8', '3.6', '0.1', '0.8', '6.8', '5.3', '5.0', '2.1', '2.0', '5.0', '0.0']
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['86.9', '68.4', '67.9', '63.9', '45.1', '82.7', '70.5', '90.2', '41.0', '84.4', '42.3', '91.3', '91.4', '79.0', '67.3', '61.9', '78.3', '73.5', '91.0', '76.7', '58.2', '29.8', '64.8', '68.8', '65.1', '24.9', '80.7', '84.9', '88.5', '87.2', '18.4', '37.4', '12.6', '14.2', '32.1', '43.9', '28.8', '35.3', '33.4', '43.5', '62.3', '24.1', '41.0', '37.1', '35.9', '30.3', '34.8', '45.5', '46.6', '48.1', '26.8', '18.5', '33.1', '25.6', '30.3', '12.8', '24.8', '37.8', '23.8', '24.5', '63.5', '53.9', '57.4', '55.4', '20.3', '60.2', '29.3', '26.2', '49.4', '38.4', '34.8', '56.0', '5.9', '11.4', '24.4', '33.7', '16.2', '10.7', '12.7', '34.8', 'nan']
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 29.360114657321045
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 7.937713016640767
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 51.16636985526634
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 12.65399176211789
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 4.249965524568722
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 34.73596951873481
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 25.183583933520254
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 7.015776143622754
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 47.05876977113346
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/07 16:13:46] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/07 16:13:46] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/07 16:13:46] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/07 16:13:46] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/07 16:13:46] d2.evaluation.testing INFO: copypaste: nan,nan
[05/07 17:04:24] detectron2 INFO: Rank of current process: 0. World size: 4
[05/07 17:04:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 17:04:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 17:04:25] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 17:04:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 17:04:25] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/07 17:04:25] d2.utils.env INFO: Using a generated random seed 25311574
[05/07 17:04:25] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 17:04:25] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 17:04:25] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 17:04:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 17:04:27] d2.data.build INFO: Known classes: range(0, 80)
[05/07 17:04:27] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 17:04:28] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 17:04:28] d2.data.build INFO: Number of datapoints: 10246
[05/07 17:04:28] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 17:04:28] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 17:04:28] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 17:04:28] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 17:04:28] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/07 17:04:37] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1484 s / img. ETA=0:06:22
[05/07 17:04:42] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1423 s / img. ETA=0:06:01
[05/07 17:04:47] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1442 s / img. ETA=0:06:01
[05/07 17:04:52] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1473 s / img. ETA=0:06:04
[05/07 17:04:57] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1484 s / img. ETA=0:06:02
[05/07 17:05:02] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1498 s / img. ETA=0:06:00
[05/07 17:05:08] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1503 s / img. ETA=0:05:56
[05/07 17:05:13] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1493 s / img. ETA=0:05:49
[05/07 17:05:18] d2.evaluation.evaluator INFO: Inference done 281/2562. 0.1500 s / img. ETA=0:05:45
[05/07 17:05:23] d2.evaluation.evaluator INFO: Inference done 314/2562. 0.1501 s / img. ETA=0:05:41
[05/07 17:05:28] d2.evaluation.evaluator INFO: Inference done 347/2562. 0.1504 s / img. ETA=0:05:36
[05/07 17:05:33] d2.evaluation.evaluator INFO: Inference done 379/2562. 0.1508 s / img. ETA=0:05:32
[05/07 17:05:38] d2.evaluation.evaluator INFO: Inference done 414/2562. 0.1503 s / img. ETA=0:05:26
[05/07 17:05:43] d2.evaluation.evaluator INFO: Inference done 447/2562. 0.1504 s / img. ETA=0:05:21
[05/07 17:05:48] d2.evaluation.evaluator INFO: Inference done 482/2562. 0.1499 s / img. ETA=0:05:15
[05/07 17:05:53] d2.evaluation.evaluator INFO: Inference done 518/2562. 0.1491 s / img. ETA=0:05:08
[05/07 17:05:58] d2.evaluation.evaluator INFO: Inference done 553/2562. 0.1486 s / img. ETA=0:05:01
[05/07 17:06:03] d2.evaluation.evaluator INFO: Inference done 587/2562. 0.1486 s / img. ETA=0:04:56
[05/07 17:06:09] d2.evaluation.evaluator INFO: Inference done 620/2562. 0.1489 s / img. ETA=0:04:52
[05/07 17:06:14] d2.evaluation.evaluator INFO: Inference done 654/2562. 0.1488 s / img. ETA=0:04:47
[05/07 17:06:19] d2.evaluation.evaluator INFO: Inference done 687/2562. 0.1489 s / img. ETA=0:04:42
[05/07 17:06:24] d2.evaluation.evaluator INFO: Inference done 718/2562. 0.1494 s / img. ETA=0:04:38
[05/07 17:06:29] d2.evaluation.evaluator INFO: Inference done 748/2562. 0.1502 s / img. ETA=0:04:35
[05/07 17:06:34] d2.evaluation.evaluator INFO: Inference done 780/2562. 0.1504 s / img. ETA=0:04:31
[05/07 17:06:39] d2.evaluation.evaluator INFO: Inference done 813/2562. 0.1504 s / img. ETA=0:04:26
[05/07 17:06:44] d2.evaluation.evaluator INFO: Inference done 844/2562. 0.1509 s / img. ETA=0:04:22
[05/07 17:06:49] d2.evaluation.evaluator INFO: Inference done 876/2562. 0.1511 s / img. ETA=0:04:17
[05/07 17:06:54] d2.evaluation.evaluator INFO: Inference done 909/2562. 0.1511 s / img. ETA=0:04:12
[05/07 17:06:59] d2.evaluation.evaluator INFO: Inference done 941/2562. 0.1513 s / img. ETA=0:04:08
[05/07 17:07:04] d2.evaluation.evaluator INFO: Inference done 973/2562. 0.1516 s / img. ETA=0:04:03
[05/07 17:07:09] d2.evaluation.evaluator INFO: Inference done 1007/2562. 0.1514 s / img. ETA=0:03:58
[05/07 17:07:14] d2.evaluation.evaluator INFO: Inference done 1041/2562. 0.1512 s / img. ETA=0:03:52
[05/07 17:07:20] d2.evaluation.evaluator INFO: Inference done 1073/2562. 0.1515 s / img. ETA=0:03:48
[05/07 17:07:25] d2.evaluation.evaluator INFO: Inference done 1106/2562. 0.1515 s / img. ETA=0:03:43
[05/07 17:07:30] d2.evaluation.evaluator INFO: Inference done 1139/2562. 0.1515 s / img. ETA=0:03:38
[05/07 17:07:35] d2.evaluation.evaluator INFO: Inference done 1175/2562. 0.1512 s / img. ETA=0:03:32
[05/07 17:07:40] d2.evaluation.evaluator INFO: Inference done 1204/2562. 0.1517 s / img. ETA=0:03:28
[05/07 17:07:45] d2.evaluation.evaluator INFO: Inference done 1237/2562. 0.1517 s / img. ETA=0:03:23
[05/07 17:07:50] d2.evaluation.evaluator INFO: Inference done 1269/2562. 0.1519 s / img. ETA=0:03:18
[05/07 17:07:55] d2.evaluation.evaluator INFO: Inference done 1303/2562. 0.1518 s / img. ETA=0:03:13
[05/07 17:08:00] d2.evaluation.evaluator INFO: Inference done 1334/2562. 0.1520 s / img. ETA=0:03:08
[05/07 17:08:05] d2.evaluation.evaluator INFO: Inference done 1366/2562. 0.1521 s / img. ETA=0:03:04
[05/07 17:08:10] d2.evaluation.evaluator INFO: Inference done 1393/2562. 0.1528 s / img. ETA=0:03:00
[05/07 17:08:15] d2.evaluation.evaluator INFO: Inference done 1427/2562. 0.1526 s / img. ETA=0:02:55
[05/07 17:08:21] d2.evaluation.evaluator INFO: Inference done 1462/2562. 0.1524 s / img. ETA=0:02:49
[05/07 17:08:26] d2.evaluation.evaluator INFO: Inference done 1495/2562. 0.1524 s / img. ETA=0:02:44
[05/07 17:08:31] d2.evaluation.evaluator INFO: Inference done 1529/2562. 0.1522 s / img. ETA=0:02:39
[05/07 17:08:36] d2.evaluation.evaluator INFO: Inference done 1561/2562. 0.1523 s / img. ETA=0:02:34
[05/07 17:08:41] d2.evaluation.evaluator INFO: Inference done 1596/2562. 0.1521 s / img. ETA=0:02:28
[05/07 17:08:46] d2.evaluation.evaluator INFO: Inference done 1632/2562. 0.1518 s / img. ETA=0:02:22
[05/07 17:08:51] d2.evaluation.evaluator INFO: Inference done 1665/2562. 0.1518 s / img. ETA=0:02:17
[05/07 17:08:56] d2.evaluation.evaluator INFO: Inference done 1699/2562. 0.1517 s / img. ETA=0:02:12
[05/07 17:09:01] d2.evaluation.evaluator INFO: Inference done 1733/2562. 0.1517 s / img. ETA=0:02:07
[05/07 17:09:06] d2.evaluation.evaluator INFO: Inference done 1762/2562. 0.1520 s / img. ETA=0:02:03
[05/07 17:09:11] d2.evaluation.evaluator INFO: Inference done 1793/2562. 0.1522 s / img. ETA=0:01:58
[05/07 17:09:16] d2.evaluation.evaluator INFO: Inference done 1823/2562. 0.1524 s / img. ETA=0:01:53
[05/07 17:09:21] d2.evaluation.evaluator INFO: Inference done 1857/2562. 0.1523 s / img. ETA=0:01:48
[05/07 17:09:26] d2.evaluation.evaluator INFO: Inference done 1889/2562. 0.1524 s / img. ETA=0:01:43
[05/07 17:09:31] d2.evaluation.evaluator INFO: Inference done 1923/2562. 0.1523 s / img. ETA=0:01:38
[05/07 17:09:36] d2.evaluation.evaluator INFO: Inference done 1955/2562. 0.1524 s / img. ETA=0:01:33
[05/07 17:09:42] d2.evaluation.evaluator INFO: Inference done 1989/2562. 0.1523 s / img. ETA=0:01:28
[05/07 17:09:47] d2.evaluation.evaluator INFO: Inference done 2025/2562. 0.1521 s / img. ETA=0:01:22
[05/07 17:09:52] d2.evaluation.evaluator INFO: Inference done 2058/2562. 0.1522 s / img. ETA=0:01:17
[05/07 17:09:57] d2.evaluation.evaluator INFO: Inference done 2093/2562. 0.1521 s / img. ETA=0:01:12
[05/07 17:10:02] d2.evaluation.evaluator INFO: Inference done 2124/2562. 0.1522 s / img. ETA=0:01:07
[05/07 17:10:07] d2.evaluation.evaluator INFO: Inference done 2154/2562. 0.1524 s / img. ETA=0:01:02
[05/07 17:10:12] d2.evaluation.evaluator INFO: Inference done 2186/2562. 0.1525 s / img. ETA=0:00:57
[05/07 17:10:18] d2.evaluation.evaluator INFO: Inference done 2220/2562. 0.1525 s / img. ETA=0:00:52
[05/07 17:10:23] d2.evaluation.evaluator INFO: Inference done 2256/2562. 0.1523 s / img. ETA=0:00:47
[05/07 17:10:28] d2.evaluation.evaluator INFO: Inference done 2288/2562. 0.1523 s / img. ETA=0:00:42
[05/07 17:10:33] d2.evaluation.evaluator INFO: Inference done 2320/2562. 0.1524 s / img. ETA=0:00:37
[05/07 17:10:38] d2.evaluation.evaluator INFO: Inference done 2350/2562. 0.1526 s / img. ETA=0:00:32
[05/07 17:10:43] d2.evaluation.evaluator INFO: Inference done 2384/2562. 0.1526 s / img. ETA=0:00:27
[05/07 17:10:48] d2.evaluation.evaluator INFO: Inference done 2416/2562. 0.1526 s / img. ETA=0:00:22
[05/07 17:10:53] d2.evaluation.evaluator INFO: Inference done 2449/2562. 0.1526 s / img. ETA=0:00:17
[05/07 17:10:58] d2.evaluation.evaluator INFO: Inference done 2483/2562. 0.1525 s / img. ETA=0:00:12
[05/07 17:11:03] d2.evaluation.evaluator INFO: Inference done 2513/2562. 0.1527 s / img. ETA=0:00:07
[05/07 17:11:08] d2.evaluation.evaluator INFO: Inference done 2545/2562. 0.1527 s / img. ETA=0:00:02
[05/07 17:11:11] d2.evaluation.evaluator INFO: Total inference time: 0:06:35.514275 (0.154679 s / img per device, on 4 devices)
[05/07 17:11:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:30 (0.152794 s / img per device, on 4 devices)
[05/07 17:11:49] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/07 17:11:49] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 2037 predictions.
[05/07 17:11:51] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 2901 predictions.
[05/07 17:11:51] d2.evaluation.pascal_voc_evaluation INFO: bird has 2264 predictions.
[05/07 17:11:51] d2.evaluation.pascal_voc_evaluation INFO: boat has 3579 predictions.
[05/07 17:11:51] d2.evaluation.pascal_voc_evaluation INFO: bottle has 15544 predictions.
[05/07 17:11:52] d2.evaluation.pascal_voc_evaluation INFO: bus has 2429 predictions.
[05/07 17:11:52] d2.evaluation.pascal_voc_evaluation INFO: car has 21340 predictions.
[05/07 17:11:53] d2.evaluation.pascal_voc_evaluation INFO: cat has 2316 predictions.
[05/07 17:11:53] d2.evaluation.pascal_voc_evaluation INFO: chair has 21435 predictions.
[05/07 17:11:54] d2.evaluation.pascal_voc_evaluation INFO: cow has 2126 predictions.
[05/07 17:11:54] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 10604 predictions.
[05/07 17:11:55] d2.evaluation.pascal_voc_evaluation INFO: dog has 3155 predictions.
[05/07 17:11:55] d2.evaluation.pascal_voc_evaluation INFO: horse has 2513 predictions.
[05/07 17:11:55] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 2708 predictions.
[05/07 17:11:55] d2.evaluation.pascal_voc_evaluation INFO: person has 85953 predictions.
[05/07 17:11:59] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 7037 predictions.
[05/07 17:11:59] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1395 predictions.
[05/07 17:11:59] d2.evaluation.pascal_voc_evaluation INFO: sofa has 5117 predictions.
[05/07 17:11:59] d2.evaluation.pascal_voc_evaluation INFO: train has 2870 predictions.
[05/07 17:12:00] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 4541 predictions.
[05/07 17:12:00] d2.evaluation.pascal_voc_evaluation INFO: truck has 8659 predictions.
[05/07 17:12:00] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 2981 predictions.
[05/07 17:12:01] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1428 predictions.
[05/07 17:12:01] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1450 predictions.
[05/07 17:12:01] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1489 predictions.
[05/07 17:12:01] d2.evaluation.pascal_voc_evaluation INFO: bench has 6334 predictions.
[05/07 17:12:01] d2.evaluation.pascal_voc_evaluation INFO: elephant has 2556 predictions.
[05/07 17:12:02] d2.evaluation.pascal_voc_evaluation INFO: bear has 2595 predictions.
[05/07 17:12:02] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1358 predictions.
[05/07 17:12:02] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1325 predictions.
[05/07 17:12:02] d2.evaluation.pascal_voc_evaluation INFO: backpack has 4739 predictions.
[05/07 17:12:02] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 2490 predictions.
[05/07 17:12:03] d2.evaluation.pascal_voc_evaluation INFO: handbag has 5789 predictions.
[05/07 17:12:03] d2.evaluation.pascal_voc_evaluation INFO: tie has 686 predictions.
[05/07 17:12:03] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 3514 predictions.
[05/07 17:12:03] d2.evaluation.pascal_voc_evaluation INFO: microwave has 2380 predictions.
[05/07 17:12:04] d2.evaluation.pascal_voc_evaluation INFO: oven has 3512 predictions.
[05/07 17:12:04] d2.evaluation.pascal_voc_evaluation INFO: toaster has 2540 predictions.
[05/07 17:12:04] d2.evaluation.pascal_voc_evaluation INFO: sink has 6174 predictions.
[05/07 17:12:04] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 5038 predictions.
[05/07 17:12:05] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2023 predictions.
[05/07 17:12:05] d2.evaluation.pascal_voc_evaluation INFO: skis has 1452 predictions.
[05/07 17:12:05] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2011 predictions.
[05/07 17:12:05] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 1758 predictions.
[05/07 17:12:05] d2.evaluation.pascal_voc_evaluation INFO: kite has 1909 predictions.
[05/07 17:12:06] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1950 predictions.
[05/07 17:12:06] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 2011 predictions.
[05/07 17:12:06] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 3039 predictions.
[05/07 17:12:06] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 3367 predictions.
[05/07 17:12:06] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1920 predictions.
[05/07 17:12:07] d2.evaluation.pascal_voc_evaluation INFO: banana has 1546 predictions.
[05/07 17:12:07] d2.evaluation.pascal_voc_evaluation INFO: apple has 1027 predictions.
[05/07 17:12:07] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 2769 predictions.
[05/07 17:12:07] d2.evaluation.pascal_voc_evaluation INFO: orange has 1440 predictions.
[05/07 17:12:07] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 2495 predictions.
[05/07 17:12:08] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1452 predictions.
[05/07 17:12:08] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 762 predictions.
[05/07 17:12:08] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1869 predictions.
[05/07 17:12:08] d2.evaluation.pascal_voc_evaluation INFO: donut has 1556 predictions.
[05/07 17:12:09] d2.evaluation.pascal_voc_evaluation INFO: cake has 2398 predictions.
[05/07 17:12:09] d2.evaluation.pascal_voc_evaluation INFO: bed has 5001 predictions.
[05/07 17:12:09] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1863 predictions.
[05/07 17:12:09] d2.evaluation.pascal_voc_evaluation INFO: laptop has 2573 predictions.
[05/07 17:12:10] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1385 predictions.
[05/07 17:12:10] d2.evaluation.pascal_voc_evaluation INFO: remote has 1076 predictions.
[05/07 17:12:10] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1266 predictions.
[05/07 17:12:10] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 2874 predictions.
[05/07 17:12:10] d2.evaluation.pascal_voc_evaluation INFO: book has 12130 predictions.
[05/07 17:12:11] d2.evaluation.pascal_voc_evaluation INFO: clock has 2769 predictions.
[05/07 17:12:11] d2.evaluation.pascal_voc_evaluation INFO: vase has 3334 predictions.
[05/07 17:12:11] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1948 predictions.
[05/07 17:12:11] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 3911 predictions.
[05/07 17:12:12] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1248 predictions.
[05/07 17:12:12] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1310 predictions.
[05/07 17:12:12] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 2008 predictions.
[05/07 17:12:12] d2.evaluation.pascal_voc_evaluation INFO: cup has 10013 predictions.
[05/07 17:12:13] d2.evaluation.pascal_voc_evaluation INFO: fork has 1330 predictions.
[05/07 17:12:13] d2.evaluation.pascal_voc_evaluation INFO: knife has 3401 predictions.
[05/07 17:12:13] d2.evaluation.pascal_voc_evaluation INFO: spoon has 2955 predictions.
[05/07 17:12:13] d2.evaluation.pascal_voc_evaluation INFO: bowl has 8572 predictions.
[05/07 17:12:14] d2.evaluation.pascal_voc_evaluation INFO: unknown has 11838 predictions.
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['65.1', '51.5', '50.0', '33.0', '21.6', '58.3', '47.9', '72.3', '19.4', '65.7', '14.2', '71.9', '77.6', '61.0', '46.2', '24.2', '59.1', '42.9', '67.5', '53.2', '13.4', '9.9', '50.7', '49.1', '44.5', '8.6', '55.7', '58.0', '73.0', '72.2', '2.4', '14.7', '1.4', '5.1', '8.6', '10.1', '5.3', '10.8', '8.1', '12.7', '31.9', '6.1', '9.1', '21.7', '14.7', '9.9', '10.7', '17.7', '14.8', '28.7', '8.2', '3.7', '9.6', '7.2', '8.4', '2.5', '6.8', '15.3', '11.2', '6.2', '18.7', '25.9', '31.2', '28.0', '7.4', '22.8', '11.1', '2.4', '30.1', '11.5', '10.4', '26.6', '0.0', '1.1', '4.7', '7.9', '2.9', '1.0', '1.8', '7.6', 'nan']
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['14.4', '15.4', '20.9', '8.7', '6.3', '13.3', '10.5', '19.9', '6.6', '12.6', '5.6', '19.2', '15.1', '16.0', '13.9', '8.3', '18.3', '7.9', '11.6', '10.7', '3.2', '7.3', '4.9', '3.7', '2.8', '2.5', '8.2', '2.4', '17.6', '15.4', '2.2', '7.8', '1.7', '7.6', '3.3', '2.0', '2.4', '0.2', '2.3', '1.8', '4.3', '5.2', '1.7', '6.8', '8.9', '3.0', '3.1', '3.5', '4.3', '6.7', '10.2', '7.1', '4.0', '8.6', '6.6', '6.3', '6.8', '10.5', '8.0', '6.7', '2.4', '7.4', '6.5', '4.8', '6.2', '8.4', '3.9', '3.3', '6.4', '4.4', '0.8', '3.6', '0.1', '0.8', '6.8', '5.3', '5.0', '2.1', '2.0', '5.0', '0.0']
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['86.9', '68.4', '67.9', '63.9', '45.1', '82.7', '70.5', '90.2', '41.0', '84.4', '42.3', '91.3', '91.4', '79.0', '67.3', '61.9', '78.3', '73.5', '91.0', '76.7', '58.2', '29.8', '64.8', '68.8', '65.1', '24.9', '80.7', '84.9', '88.5', '87.2', '18.4', '37.4', '12.6', '14.2', '32.1', '43.9', '28.8', '35.3', '33.4', '43.5', '62.3', '24.1', '41.0', '37.1', '35.9', '30.3', '34.8', '45.5', '46.6', '48.1', '26.8', '18.5', '33.1', '25.6', '30.3', '12.8', '24.8', '37.8', '23.8', '24.5', '63.5', '53.9', '57.4', '55.4', '20.3', '60.2', '29.3', '26.2', '49.4', '38.4', '34.8', '56.0', '5.9', '11.4', '24.4', '33.7', '16.2', '10.7', '12.7', '34.8', 'nan']
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 29.360114657321045
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 7.937713016640767
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 51.16636985526634
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 12.65399176211789
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 4.249965524568722
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 34.73596951873481
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 25.183583933520254
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 7.015776143622754
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 47.05876977113346
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/07 17:12:15] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/07 17:12:15] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/07 17:12:15] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/07 17:12:15] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/07 17:12:15] d2.evaluation.testing INFO: copypaste: nan,nan
[05/08 08:50:10] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 08:50:11] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 08:50:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 08:50:11] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 10
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 08:50:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 10
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 08:50:11] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/08 08:50:11] d2.utils.env INFO: Using a generated random seed 11424034
[05/08 08:50:12] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 08:50:12] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 08:50:12] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 08:50:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 08:50:13] d2.data.build INFO: Known classes: range(0, 80)
[05/08 08:50:13] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 08:50:14] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 08:50:14] d2.data.build INFO: Number of datapoints: 10246
[05/08 08:50:14] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 08:50:14] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 08:50:14] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 08:50:14] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 08:50:14] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 08:50:23] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1475 s / img. ETA=0:06:19
[05/08 08:50:28] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1420 s / img. ETA=0:06:00
[05/08 08:50:33] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1438 s / img. ETA=0:06:00
[05/08 08:50:38] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1468 s / img. ETA=0:06:02
[05/08 08:50:43] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1481 s / img. ETA=0:06:00
[05/08 08:50:49] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1496 s / img. ETA=0:05:59
[05/08 08:50:54] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1501 s / img. ETA=0:05:55
[05/08 08:50:59] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1490 s / img. ETA=0:05:48
[05/08 08:51:04] d2.evaluation.evaluator INFO: Inference done 281/2562. 0.1497 s / img. ETA=0:05:44
[05/08 08:51:09] d2.evaluation.evaluator INFO: Inference done 314/2562. 0.1498 s / img. ETA=0:05:40
[05/08 08:51:14] d2.evaluation.evaluator INFO: Inference done 347/2562. 0.1500 s / img. ETA=0:05:35
[05/08 08:51:19] d2.evaluation.evaluator INFO: Inference done 379/2562. 0.1505 s / img. ETA=0:05:31
[05/08 08:51:24] d2.evaluation.evaluator INFO: Inference done 414/2562. 0.1499 s / img. ETA=0:05:25
[05/08 08:51:29] d2.evaluation.evaluator INFO: Inference done 447/2562. 0.1500 s / img. ETA=0:05:20
[05/08 08:51:34] d2.evaluation.evaluator INFO: Inference done 482/2562. 0.1494 s / img. ETA=0:05:13
[05/08 08:51:39] d2.evaluation.evaluator INFO: Inference done 519/2562. 0.1485 s / img. ETA=0:05:06
[05/08 08:51:44] d2.evaluation.evaluator INFO: Inference done 554/2562. 0.1482 s / img. ETA=0:05:00
[05/08 08:51:49] d2.evaluation.evaluator INFO: Inference done 588/2562. 0.1483 s / img. ETA=0:04:55
[05/08 08:51:55] d2.evaluation.evaluator INFO: Inference done 621/2562. 0.1485 s / img. ETA=0:04:51
[05/08 08:52:00] d2.evaluation.evaluator INFO: Inference done 656/2562. 0.1483 s / img. ETA=0:04:45
[05/08 08:52:05] d2.evaluation.evaluator INFO: Inference done 690/2562. 0.1483 s / img. ETA=0:04:40
[05/08 08:52:10] d2.evaluation.evaluator INFO: Inference done 721/2562. 0.1491 s / img. ETA=0:04:37
[05/08 08:52:15] d2.evaluation.evaluator INFO: Inference done 751/2562. 0.1497 s / img. ETA=0:04:33
[05/08 08:52:20] d2.evaluation.evaluator INFO: Inference done 785/2562. 0.1497 s / img. ETA=0:04:28
[05/08 08:52:25] d2.evaluation.evaluator INFO: Inference done 818/2562. 0.1498 s / img. ETA=0:04:23
[05/08 08:52:30] d2.evaluation.evaluator INFO: Inference done 849/2562. 0.1502 s / img. ETA=0:04:19
[05/08 08:52:35] d2.evaluation.evaluator INFO: Inference done 882/2562. 0.1504 s / img. ETA=0:04:15
[05/08 08:52:40] d2.evaluation.evaluator INFO: Inference done 915/2562. 0.1505 s / img. ETA=0:04:10
[05/08 08:52:45] d2.evaluation.evaluator INFO: Inference done 948/2562. 0.1505 s / img. ETA=0:04:05
[05/08 08:52:51] d2.evaluation.evaluator INFO: Inference done 979/2562. 0.1509 s / img. ETA=0:04:01
[05/08 08:52:56] d2.evaluation.evaluator INFO: Inference done 1013/2562. 0.1508 s / img. ETA=0:03:55
[05/08 08:53:01] d2.evaluation.evaluator INFO: Inference done 1048/2562. 0.1506 s / img. ETA=0:03:50
[05/08 08:53:06] d2.evaluation.evaluator INFO: Inference done 1080/2562. 0.1508 s / img. ETA=0:03:45
[05/08 08:53:11] d2.evaluation.evaluator INFO: Inference done 1114/2562. 0.1508 s / img. ETA=0:03:40
[05/08 08:53:16] d2.evaluation.evaluator INFO: Inference done 1147/2562. 0.1509 s / img. ETA=0:03:35
[05/08 08:53:21] d2.evaluation.evaluator INFO: Inference done 1182/2562. 0.1507 s / img. ETA=0:03:30
[05/08 08:53:26] d2.evaluation.evaluator INFO: Inference done 1211/2562. 0.1512 s / img. ETA=0:03:26
[05/08 08:53:31] d2.evaluation.evaluator INFO: Inference done 1243/2562. 0.1513 s / img. ETA=0:03:21
[05/08 08:53:36] d2.evaluation.evaluator INFO: Inference done 1275/2562. 0.1514 s / img. ETA=0:03:16
[05/08 08:53:41] d2.evaluation.evaluator INFO: Inference done 1308/2562. 0.1515 s / img. ETA=0:03:11
[05/08 08:53:47] d2.evaluation.evaluator INFO: Inference done 1339/2562. 0.1517 s / img. ETA=0:03:07
[05/08 08:53:52] d2.evaluation.evaluator INFO: Inference done 1369/2562. 0.1520 s / img. ETA=0:03:03
[05/08 08:53:57] d2.evaluation.evaluator INFO: Inference done 1397/2562. 0.1526 s / img. ETA=0:02:59
[05/08 08:54:02] d2.evaluation.evaluator INFO: Inference done 1432/2562. 0.1524 s / img. ETA=0:02:53
[05/08 08:54:07] d2.evaluation.evaluator INFO: Inference done 1466/2562. 0.1523 s / img. ETA=0:02:48
[05/08 08:54:12] d2.evaluation.evaluator INFO: Inference done 1499/2562. 0.1524 s / img. ETA=0:02:43
[05/08 08:54:17] d2.evaluation.evaluator INFO: Inference done 1534/2562. 0.1522 s / img. ETA=0:02:38
[05/08 08:54:22] d2.evaluation.evaluator INFO: Inference done 1567/2562. 0.1523 s / img. ETA=0:02:33
[05/08 08:54:27] d2.evaluation.evaluator INFO: Inference done 1602/2562. 0.1521 s / img. ETA=0:02:27
[05/08 08:54:33] d2.evaluation.evaluator INFO: Inference done 1638/2562. 0.1519 s / img. ETA=0:02:21
[05/08 08:54:38] d2.evaluation.evaluator INFO: Inference done 1670/2562. 0.1520 s / img. ETA=0:02:16
[05/08 08:54:43] d2.evaluation.evaluator INFO: Inference done 1704/2562. 0.1519 s / img. ETA=0:02:11
[05/08 08:54:48] d2.evaluation.evaluator INFO: Inference done 1737/2562. 0.1519 s / img. ETA=0:02:06
[05/08 08:54:53] d2.evaluation.evaluator INFO: Inference done 1766/2562. 0.1523 s / img. ETA=0:02:02
[05/08 08:54:58] d2.evaluation.evaluator INFO: Inference done 1799/2562. 0.1522 s / img. ETA=0:01:57
[05/08 08:55:03] d2.evaluation.evaluator INFO: Inference done 1829/2562. 0.1526 s / img. ETA=0:01:52
[05/08 08:55:08] d2.evaluation.evaluator INFO: Inference done 1863/2562. 0.1525 s / img. ETA=0:01:47
[05/08 08:55:13] d2.evaluation.evaluator INFO: Inference done 1898/2562. 0.1524 s / img. ETA=0:01:42
[05/08 08:55:19] d2.evaluation.evaluator INFO: Inference done 1931/2562. 0.1524 s / img. ETA=0:01:37
[05/08 08:55:24] d2.evaluation.evaluator INFO: Inference done 1962/2562. 0.1525 s / img. ETA=0:01:32
[05/08 08:55:29] d2.evaluation.evaluator INFO: Inference done 1997/2562. 0.1524 s / img. ETA=0:01:26
[05/08 08:55:34] d2.evaluation.evaluator INFO: Inference done 2033/2562. 0.1521 s / img. ETA=0:01:21
[05/08 08:55:39] d2.evaluation.evaluator INFO: Inference done 2065/2562. 0.1522 s / img. ETA=0:01:16
[05/08 08:55:44] d2.evaluation.evaluator INFO: Inference done 2098/2562. 0.1522 s / img. ETA=0:01:11
[05/08 08:55:49] d2.evaluation.evaluator INFO: Inference done 2128/2562. 0.1524 s / img. ETA=0:01:06
[05/08 08:55:54] d2.evaluation.evaluator INFO: Inference done 2157/2562. 0.1526 s / img. ETA=0:01:02
[05/08 08:55:59] d2.evaluation.evaluator INFO: Inference done 2190/2562. 0.1526 s / img. ETA=0:00:57
[05/08 08:56:04] d2.evaluation.evaluator INFO: Inference done 2222/2562. 0.1527 s / img. ETA=0:00:52
[05/08 08:56:09] d2.evaluation.evaluator INFO: Inference done 2257/2562. 0.1525 s / img. ETA=0:00:46
[05/08 08:56:14] d2.evaluation.evaluator INFO: Inference done 2289/2562. 0.1526 s / img. ETA=0:00:42
[05/08 08:56:19] d2.evaluation.evaluator INFO: Inference done 2321/2562. 0.1526 s / img. ETA=0:00:37
[05/08 08:56:24] d2.evaluation.evaluator INFO: Inference done 2351/2562. 0.1528 s / img. ETA=0:00:32
[05/08 08:56:29] d2.evaluation.evaluator INFO: Inference done 2384/2562. 0.1529 s / img. ETA=0:00:27
[05/08 08:56:34] d2.evaluation.evaluator INFO: Inference done 2416/2562. 0.1529 s / img. ETA=0:00:22
[05/08 08:56:39] d2.evaluation.evaluator INFO: Inference done 2449/2562. 0.1529 s / img. ETA=0:00:17
[05/08 08:56:45] d2.evaluation.evaluator INFO: Inference done 2483/2562. 0.1528 s / img. ETA=0:00:12
[05/08 08:56:50] d2.evaluation.evaluator INFO: Inference done 2513/2562. 0.1530 s / img. ETA=0:00:07
[05/08 08:56:55] d2.evaluation.evaluator INFO: Inference done 2546/2562. 0.1530 s / img. ETA=0:00:02
[05/08 08:56:58] d2.evaluation.evaluator INFO: Total inference time: 0:06:35.546713 (0.154692 s / img per device, on 4 devices)
[05/08 08:56:58] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:31 (0.153050 s / img per device, on 4 devices)
[05/08 08:57:34] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 08:57:34] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 968 predictions.
[05/08 08:57:35] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 1269 predictions.
[05/08 08:57:36] d2.evaluation.pascal_voc_evaluation INFO: bird has 1235 predictions.
[05/08 08:57:36] d2.evaluation.pascal_voc_evaluation INFO: boat has 1201 predictions.
[05/08 08:57:36] d2.evaluation.pascal_voc_evaluation INFO: bottle has 3749 predictions.
[05/08 08:57:36] d2.evaluation.pascal_voc_evaluation INFO: bus has 812 predictions.
[05/08 08:57:37] d2.evaluation.pascal_voc_evaluation INFO: car has 6041 predictions.
[05/08 08:57:37] d2.evaluation.pascal_voc_evaluation INFO: cat has 1462 predictions.
[05/08 08:57:37] d2.evaluation.pascal_voc_evaluation INFO: chair has 4636 predictions.
[05/08 08:57:37] d2.evaluation.pascal_voc_evaluation INFO: cow has 1019 predictions.
[05/08 08:57:38] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 2898 predictions.
[05/08 08:57:38] d2.evaluation.pascal_voc_evaluation INFO: dog has 1661 predictions.
[05/08 08:57:38] d2.evaluation.pascal_voc_evaluation INFO: horse has 1261 predictions.
[05/08 08:57:38] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 1020 predictions.
[05/08 08:57:39] d2.evaluation.pascal_voc_evaluation INFO: person has 27631 predictions.
[05/08 08:57:40] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 2515 predictions.
[05/08 08:57:40] d2.evaluation.pascal_voc_evaluation INFO: sheep has 584 predictions.
[05/08 08:57:40] d2.evaluation.pascal_voc_evaluation INFO: sofa has 1490 predictions.
[05/08 08:57:41] d2.evaluation.pascal_voc_evaluation INFO: train has 1279 predictions.
[05/08 08:57:41] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 1633 predictions.
[05/08 08:57:41] d2.evaluation.pascal_voc_evaluation INFO: truck has 1749 predictions.
[05/08 08:57:41] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 617 predictions.
[05/08 08:57:41] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 298 predictions.
[05/08 08:57:42] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 410 predictions.
[05/08 08:57:42] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 255 predictions.
[05/08 08:57:42] d2.evaluation.pascal_voc_evaluation INFO: bench has 1017 predictions.
[05/08 08:57:42] d2.evaluation.pascal_voc_evaluation INFO: elephant has 794 predictions.
[05/08 08:57:42] d2.evaluation.pascal_voc_evaluation INFO: bear has 1036 predictions.
[05/08 08:57:43] d2.evaluation.pascal_voc_evaluation INFO: zebra has 599 predictions.
[05/08 08:57:43] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 626 predictions.
[05/08 08:57:43] d2.evaluation.pascal_voc_evaluation INFO: backpack has 609 predictions.
[05/08 08:57:43] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 499 predictions.
[05/08 08:57:44] d2.evaluation.pascal_voc_evaluation INFO: handbag has 489 predictions.
[05/08 08:57:44] d2.evaluation.pascal_voc_evaluation INFO: tie has 124 predictions.
[05/08 08:57:44] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 433 predictions.
[05/08 08:57:44] d2.evaluation.pascal_voc_evaluation INFO: microwave has 366 predictions.
[05/08 08:57:44] d2.evaluation.pascal_voc_evaluation INFO: oven has 634 predictions.
[05/08 08:57:45] d2.evaluation.pascal_voc_evaluation INFO: toaster has 306 predictions.
[05/08 08:57:45] d2.evaluation.pascal_voc_evaluation INFO: sink has 1323 predictions.
[05/08 08:57:45] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 1058 predictions.
[05/08 08:57:45] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 483 predictions.
[05/08 08:57:45] d2.evaluation.pascal_voc_evaluation INFO: skis has 276 predictions.
[05/08 08:57:46] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 362 predictions.
[05/08 08:57:46] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 509 predictions.
[05/08 08:57:46] d2.evaluation.pascal_voc_evaluation INFO: kite has 474 predictions.
[05/08 08:57:46] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 400 predictions.
[05/08 08:57:46] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 286 predictions.
[05/08 08:57:47] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 452 predictions.
[05/08 08:57:47] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 834 predictions.
[05/08 08:57:47] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 437 predictions.
[05/08 08:57:47] d2.evaluation.pascal_voc_evaluation INFO: banana has 354 predictions.
[05/08 08:57:47] d2.evaluation.pascal_voc_evaluation INFO: apple has 163 predictions.
[05/08 08:57:48] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 673 predictions.
[05/08 08:57:48] d2.evaluation.pascal_voc_evaluation INFO: orange has 395 predictions.
[05/08 08:57:48] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 702 predictions.
[05/08 08:57:48] d2.evaluation.pascal_voc_evaluation INFO: carrot has 303 predictions.
[05/08 08:57:48] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 135 predictions.
[05/08 08:57:49] d2.evaluation.pascal_voc_evaluation INFO: pizza has 561 predictions.
[05/08 08:57:49] d2.evaluation.pascal_voc_evaluation INFO: donut has 311 predictions.
[05/08 08:57:49] d2.evaluation.pascal_voc_evaluation INFO: cake has 389 predictions.
[05/08 08:57:49] d2.evaluation.pascal_voc_evaluation INFO: bed has 1056 predictions.
[05/08 08:57:49] d2.evaluation.pascal_voc_evaluation INFO: toilet has 537 predictions.
[05/08 08:57:50] d2.evaluation.pascal_voc_evaluation INFO: laptop has 497 predictions.
[05/08 08:57:50] d2.evaluation.pascal_voc_evaluation INFO: mouse has 344 predictions.
[05/08 08:57:50] d2.evaluation.pascal_voc_evaluation INFO: remote has 159 predictions.
[05/08 08:57:50] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 384 predictions.
[05/08 08:57:51] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 528 predictions.
[05/08 08:57:51] d2.evaluation.pascal_voc_evaluation INFO: book has 1745 predictions.
[05/08 08:57:51] d2.evaluation.pascal_voc_evaluation INFO: clock has 877 predictions.
[05/08 08:57:51] d2.evaluation.pascal_voc_evaluation INFO: vase has 481 predictions.
[05/08 08:57:51] d2.evaluation.pascal_voc_evaluation INFO: scissors has 223 predictions.
[05/08 08:57:52] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 887 predictions.
[05/08 08:57:52] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 58 predictions.
[05/08 08:57:52] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 147 predictions.
[05/08 08:57:52] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 380 predictions.
[05/08 08:57:52] d2.evaluation.pascal_voc_evaluation INFO: cup has 2233 predictions.
[05/08 08:57:53] d2.evaluation.pascal_voc_evaluation INFO: fork has 185 predictions.
[05/08 08:57:53] d2.evaluation.pascal_voc_evaluation INFO: knife has 371 predictions.
[05/08 08:57:53] d2.evaluation.pascal_voc_evaluation INFO: spoon has 310 predictions.
[05/08 08:57:53] d2.evaluation.pascal_voc_evaluation INFO: bowl has 1795 predictions.
[05/08 08:57:53] d2.evaluation.pascal_voc_evaluation INFO: unknown has 1708 predictions.
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['63.8', '48.6', '47.2', '31.0', '18.2', '54.3', '44.2', '71.0', '16.4', '64.3', '13.1', '70.4', '75.9', '56.1', '41.8', '21.5', '54.7', '40.1', '65.9', '50.8', '9.2', '7.2', '49.0', '47.6', '41.7', '7.9', '48.2', '58.0', '69.2', '68.7', '1.5', '10.3', '0.7', '4.8', '6.6', '8.4', '4.6', '10.6', '7.9', '11.9', '29.8', '5.2', '8.1', '19.8', '9.7', '6.3', '7.9', '16.4', '12.7', '25.7', '6.3', '1.7', '8.9', '5.8', '7.2', '1.6', '5.2', '13.4', '9.9', '4.0', '17.9', '24.7', '28.0', '26.4', '6.1', '20.8', '9.8', '1.1', '28.8', '8.1', '10.3', '24.1', '0.0', '1.0', '3.1', '6.1', '1.9', '0.5', '1.3', '5.9', 'nan']
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['28.3', '30.8', '33.3', '21.7', '19.0', '33.8', '31.1', '30.3', '20.0', '24.9', '15.7', '34.2', '28.1', '36.2', '35.9', '17.7', '36.3', '22.4', '24.5', '26.0', '6.9', '18.8', '20.5', '11.2', '12.2', '9.4', '20.0', '5.8', '35.1', '29.6', '5.9', '20.2', '4.3', '31.5', '12.2', '7.4', '8.4', '1.3', '8.6', '6.2', '13.9', '15.2', '6.6', '17.7', '18.6', '7.0', '9.8', '15.7', '11.5', '22.7', '24.0', '17.2', '12.2', '20.8', '16.1', '14.2', '19.3', '26.0', '25.1', '17.5', '8.0', '22.2', '25.8', '16.0', '22.0', '21.9', '13.3', '6.9', '17.7', '15.2', '4.9', '12.1', '0.0', '3.4', '18.2', '14.4', '13.5', '4.9', '4.8', '13.9', '0.0']
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['81.2', '59.9', '59.4', '52.6', '32.9', '69.6', '58.2', '86.7', '26.2', '78.5', '32.5', '85.8', '85.5', '67.2', '55.3', '47.2', '64.5', '59.0', '84.9', '66.3', '25.5', '15.9', '56.5', '59.7', '49.2', '15.2', '61.4', '82.2', '77.8', '79.1', '6.4', '19.6', '2.7', '10.6', '14.8', '25.2', '18.0', '23.5', '26.6', '30.8', '48.6', '13.3', '28.9', '28.0', '18.6', '14.4', '15.7', '30.5', '31.1', '37.2', '14.5', '7.1', '24.5', '16.9', '20.9', '6.0', '12.4', '28.2', '15.0', '10.4', '45.0', '46.5', '44.0', '45.5', '10.6', '47.7', '18.3', '8.0', '43.5', '19.2', '23.9', '43.1', '0.0', '5.7', '12.4', '20.2', '6.1', '2.6', '3.3', '20.4', 'nan']
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 27.15302655366081
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 19.27720522058165
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 39.6068871334215
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 11.290387537005454
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 12.94433979334438
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 23.30525539764763
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 23.18736679949697
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 17.69398886377233
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 35.53147919947803
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/08 08:57:54] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/08 08:57:54] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 08:57:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 08:57:54] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 08:57:54] d2.evaluation.testing INFO: copypaste: nan,nan
[05/08 09:08:03] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 09:08:04] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:08:04] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:08:04] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 200
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:08:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:08:04] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/08 09:08:04] d2.utils.env INFO: Using a generated random seed 4625925
[05/08 09:08:05] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:08:05] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:08:05] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:08:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:08:07] d2.data.build INFO: Known classes: range(0, 80)
[05/08 09:08:07] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:08:07] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:08:07] d2.data.build INFO: Number of datapoints: 10246
[05/08 09:08:07] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:08:07] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:08:07] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:08:07] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:08:07] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:08:16] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1479 s / img. ETA=0:06:20
[05/08 09:08:22] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1424 s / img. ETA=0:06:02
[05/08 09:08:27] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1443 s / img. ETA=0:06:02
[05/08 09:08:32] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1474 s / img. ETA=0:06:04
[05/08 09:08:37] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1486 s / img. ETA=0:06:02
[05/08 09:08:42] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1500 s / img. ETA=0:06:01
[05/08 09:08:47] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1505 s / img. ETA=0:05:57
[05/08 09:08:52] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1496 s / img. ETA=0:05:50
[05/08 09:08:57] d2.evaluation.evaluator INFO: Inference done 281/2562. 0.1504 s / img. ETA=0:05:47
[05/08 09:09:03] d2.evaluation.evaluator INFO: Inference done 314/2562. 0.1505 s / img. ETA=0:05:42
[05/08 09:09:08] d2.evaluation.evaluator INFO: Inference done 347/2562. 0.1508 s / img. ETA=0:05:37
[05/08 09:09:13] d2.evaluation.evaluator INFO: Inference done 379/2562. 0.1512 s / img. ETA=0:05:34
[05/08 09:09:18] d2.evaluation.evaluator INFO: Inference done 414/2562. 0.1507 s / img. ETA=0:05:27
[05/08 09:09:23] d2.evaluation.evaluator INFO: Inference done 447/2562. 0.1508 s / img. ETA=0:05:22
[05/08 09:09:28] d2.evaluation.evaluator INFO: Inference done 482/2562. 0.1502 s / img. ETA=0:05:16
[05/08 09:09:33] d2.evaluation.evaluator INFO: Inference done 518/2562. 0.1493 s / img. ETA=0:05:08
[05/08 09:09:38] d2.evaluation.evaluator INFO: Inference done 553/2562. 0.1489 s / img. ETA=0:05:02
[05/08 09:09:43] d2.evaluation.evaluator INFO: Inference done 587/2562. 0.1489 s / img. ETA=0:04:57
[05/08 09:09:48] d2.evaluation.evaluator INFO: Inference done 620/2562. 0.1492 s / img. ETA=0:04:53
[05/08 09:09:53] d2.evaluation.evaluator INFO: Inference done 654/2562. 0.1491 s / img. ETA=0:04:47
[05/08 09:09:58] d2.evaluation.evaluator INFO: Inference done 687/2562. 0.1492 s / img. ETA=0:04:43
[05/08 09:10:04] d2.evaluation.evaluator INFO: Inference done 718/2562. 0.1498 s / img. ETA=0:04:39
[05/08 09:10:09] d2.evaluation.evaluator INFO: Inference done 748/2562. 0.1505 s / img. ETA=0:04:36
[05/08 09:10:14] d2.evaluation.evaluator INFO: Inference done 780/2562. 0.1507 s / img. ETA=0:04:31
[05/08 09:10:19] d2.evaluation.evaluator INFO: Inference done 813/2562. 0.1507 s / img. ETA=0:04:26
[05/08 09:10:24] d2.evaluation.evaluator INFO: Inference done 844/2562. 0.1511 s / img. ETA=0:04:22
[05/08 09:10:29] d2.evaluation.evaluator INFO: Inference done 876/2562. 0.1513 s / img. ETA=0:04:18
[05/08 09:10:34] d2.evaluation.evaluator INFO: Inference done 909/2562. 0.1515 s / img. ETA=0:04:13
[05/08 09:10:39] d2.evaluation.evaluator INFO: Inference done 941/2562. 0.1516 s / img. ETA=0:04:08
[05/08 09:10:44] d2.evaluation.evaluator INFO: Inference done 973/2562. 0.1519 s / img. ETA=0:04:04
[05/08 09:10:49] d2.evaluation.evaluator INFO: Inference done 1007/2562. 0.1517 s / img. ETA=0:03:58
[05/08 09:10:54] d2.evaluation.evaluator INFO: Inference done 1040/2562. 0.1517 s / img. ETA=0:03:53
[05/08 09:11:00] d2.evaluation.evaluator INFO: Inference done 1073/2562. 0.1518 s / img. ETA=0:03:48
[05/08 09:11:05] d2.evaluation.evaluator INFO: Inference done 1106/2562. 0.1519 s / img. ETA=0:03:43
[05/08 09:11:10] d2.evaluation.evaluator INFO: Inference done 1139/2562. 0.1519 s / img. ETA=0:03:38
[05/08 09:11:15] d2.evaluation.evaluator INFO: Inference done 1174/2562. 0.1517 s / img. ETA=0:03:33
[05/08 09:11:20] d2.evaluation.evaluator INFO: Inference done 1204/2562. 0.1521 s / img. ETA=0:03:29
[05/08 09:11:25] d2.evaluation.evaluator INFO: Inference done 1237/2562. 0.1521 s / img. ETA=0:03:23
[05/08 09:11:30] d2.evaluation.evaluator INFO: Inference done 1269/2562. 0.1522 s / img. ETA=0:03:19
[05/08 09:11:35] d2.evaluation.evaluator INFO: Inference done 1303/2562. 0.1521 s / img. ETA=0:03:13
[05/08 09:11:40] d2.evaluation.evaluator INFO: Inference done 1334/2562. 0.1523 s / img. ETA=0:03:09
[05/08 09:11:45] d2.evaluation.evaluator INFO: Inference done 1366/2562. 0.1523 s / img. ETA=0:03:04
[05/08 09:11:50] d2.evaluation.evaluator INFO: Inference done 1393/2562. 0.1530 s / img. ETA=0:03:00
[05/08 09:11:56] d2.evaluation.evaluator INFO: Inference done 1428/2562. 0.1528 s / img. ETA=0:02:55
[05/08 09:12:01] d2.evaluation.evaluator INFO: Inference done 1463/2562. 0.1525 s / img. ETA=0:02:49
[05/08 09:12:06] d2.evaluation.evaluator INFO: Inference done 1496/2562. 0.1525 s / img. ETA=0:02:44
[05/08 09:12:11] d2.evaluation.evaluator INFO: Inference done 1530/2562. 0.1524 s / img. ETA=0:02:39
[05/08 09:12:16] d2.evaluation.evaluator INFO: Inference done 1563/2562. 0.1524 s / img. ETA=0:02:34
[05/08 09:12:21] d2.evaluation.evaluator INFO: Inference done 1599/2562. 0.1521 s / img. ETA=0:02:28
[05/08 09:12:26] d2.evaluation.evaluator INFO: Inference done 1636/2562. 0.1518 s / img. ETA=0:02:22
[05/08 09:12:31] d2.evaluation.evaluator INFO: Inference done 1669/2562. 0.1518 s / img. ETA=0:02:17
[05/08 09:12:36] d2.evaluation.evaluator INFO: Inference done 1703/2562. 0.1517 s / img. ETA=0:02:11
[05/08 09:12:41] d2.evaluation.evaluator INFO: Inference done 1736/2562. 0.1517 s / img. ETA=0:02:06
[05/08 09:12:46] d2.evaluation.evaluator INFO: Inference done 1765/2562. 0.1521 s / img. ETA=0:02:02
[05/08 09:12:51] d2.evaluation.evaluator INFO: Inference done 1798/2562. 0.1521 s / img. ETA=0:01:57
[05/08 09:12:57] d2.evaluation.evaluator INFO: Inference done 1828/2562. 0.1524 s / img. ETA=0:01:53
[05/08 09:13:02] d2.evaluation.evaluator INFO: Inference done 1861/2562. 0.1524 s / img. ETA=0:01:48
[05/08 09:13:07] d2.evaluation.evaluator INFO: Inference done 1894/2562. 0.1524 s / img. ETA=0:01:43
[05/08 09:13:12] d2.evaluation.evaluator INFO: Inference done 1928/2562. 0.1523 s / img. ETA=0:01:37
[05/08 09:13:17] d2.evaluation.evaluator INFO: Inference done 1959/2562. 0.1524 s / img. ETA=0:01:33
[05/08 09:13:22] d2.evaluation.evaluator INFO: Inference done 1993/2562. 0.1523 s / img. ETA=0:01:27
[05/08 09:13:27] d2.evaluation.evaluator INFO: Inference done 2028/2562. 0.1522 s / img. ETA=0:01:22
[05/08 09:13:32] d2.evaluation.evaluator INFO: Inference done 2059/2562. 0.1523 s / img. ETA=0:01:17
[05/08 09:13:37] d2.evaluation.evaluator INFO: Inference done 2093/2562. 0.1522 s / img. ETA=0:01:12
[05/08 09:13:42] d2.evaluation.evaluator INFO: Inference done 2123/2562. 0.1523 s / img. ETA=0:01:07
[05/08 09:13:47] d2.evaluation.evaluator INFO: Inference done 2153/2562. 0.1526 s / img. ETA=0:01:03
[05/08 09:13:52] d2.evaluation.evaluator INFO: Inference done 2186/2562. 0.1526 s / img. ETA=0:00:58
[05/08 09:13:57] d2.evaluation.evaluator INFO: Inference done 2220/2562. 0.1525 s / img. ETA=0:00:52
[05/08 09:14:02] d2.evaluation.evaluator INFO: Inference done 2256/2562. 0.1523 s / img. ETA=0:00:47
[05/08 09:14:08] d2.evaluation.evaluator INFO: Inference done 2288/2562. 0.1524 s / img. ETA=0:00:42
[05/08 09:14:13] d2.evaluation.evaluator INFO: Inference done 2320/2562. 0.1524 s / img. ETA=0:00:37
[05/08 09:14:18] d2.evaluation.evaluator INFO: Inference done 2350/2562. 0.1526 s / img. ETA=0:00:32
[05/08 09:14:23] d2.evaluation.evaluator INFO: Inference done 2384/2562. 0.1525 s / img. ETA=0:00:27
[05/08 09:14:28] d2.evaluation.evaluator INFO: Inference done 2417/2562. 0.1526 s / img. ETA=0:00:22
[05/08 09:14:33] d2.evaluation.evaluator INFO: Inference done 2450/2562. 0.1526 s / img. ETA=0:00:17
[05/08 09:14:38] d2.evaluation.evaluator INFO: Inference done 2484/2562. 0.1525 s / img. ETA=0:00:12
[05/08 09:14:43] d2.evaluation.evaluator INFO: Inference done 2514/2562. 0.1527 s / img. ETA=0:00:07
[05/08 09:14:48] d2.evaluation.evaluator INFO: Inference done 2546/2562. 0.1527 s / img. ETA=0:00:02
[05/08 09:14:51] d2.evaluation.evaluator INFO: Total inference time: 0:06:35.688438 (0.154747 s / img per device, on 4 devices)
[05/08 09:14:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:30 (0.152773 s / img per device, on 4 devices)
[05/08 09:15:30] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 09:15:30] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 2534 predictions.
[05/08 09:15:31] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 3688 predictions.
[05/08 09:15:31] d2.evaluation.pascal_voc_evaluation INFO: bird has 2522 predictions.
[05/08 09:15:32] d2.evaluation.pascal_voc_evaluation INFO: boat has 4787 predictions.
[05/08 09:15:32] d2.evaluation.pascal_voc_evaluation INFO: bottle has 25449 predictions.
[05/08 09:15:33] d2.evaluation.pascal_voc_evaluation INFO: bus has 3381 predictions.
[05/08 09:15:33] d2.evaluation.pascal_voc_evaluation INFO: car has 31536 predictions.
[05/08 09:15:34] d2.evaluation.pascal_voc_evaluation INFO: cat has 2415 predictions.
[05/08 09:15:34] d2.evaluation.pascal_voc_evaluation INFO: chair has 33120 predictions.
[05/08 09:15:35] d2.evaluation.pascal_voc_evaluation INFO: cow has 2390 predictions.
[05/08 09:15:36] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 16067 predictions.
[05/08 09:15:36] d2.evaluation.pascal_voc_evaluation INFO: dog has 3498 predictions.
[05/08 09:15:36] d2.evaluation.pascal_voc_evaluation INFO: horse has 2888 predictions.
[05/08 09:15:37] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 3723 predictions.
[05/08 09:15:37] d2.evaluation.pascal_voc_evaluation INFO: person has 128547 predictions.
[05/08 09:15:42] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 9205 predictions.
[05/08 09:15:42] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1680 predictions.
[05/08 09:15:42] d2.evaluation.pascal_voc_evaluation INFO: sofa has 7158 predictions.
[05/08 09:15:43] d2.evaluation.pascal_voc_evaluation INFO: train has 3506 predictions.
[05/08 09:15:43] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 6136 predictions.
[05/08 09:15:43] d2.evaluation.pascal_voc_evaluation INFO: truck has 13270 predictions.
[05/08 09:15:44] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 4459 predictions.
[05/08 09:15:44] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 2119 predictions.
[05/08 09:15:44] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1969 predictions.
[05/08 09:15:44] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 2233 predictions.
[05/08 09:15:44] d2.evaluation.pascal_voc_evaluation INFO: bench has 10354 predictions.
[05/08 09:15:45] d2.evaluation.pascal_voc_evaluation INFO: elephant has 3126 predictions.
[05/08 09:15:45] d2.evaluation.pascal_voc_evaluation INFO: bear has 2868 predictions.
[05/08 09:15:45] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1559 predictions.
[05/08 09:15:45] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1462 predictions.
[05/08 09:15:46] d2.evaluation.pascal_voc_evaluation INFO: backpack has 7952 predictions.
[05/08 09:15:46] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 4024 predictions.
[05/08 09:15:46] d2.evaluation.pascal_voc_evaluation INFO: handbag has 10459 predictions.
[05/08 09:15:47] d2.evaluation.pascal_voc_evaluation INFO: tie has 983 predictions.
[05/08 09:15:47] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 5867 predictions.
[05/08 09:15:47] d2.evaluation.pascal_voc_evaluation INFO: microwave has 3907 predictions.
[05/08 09:15:47] d2.evaluation.pascal_voc_evaluation INFO: oven has 6046 predictions.
[05/08 09:15:47] d2.evaluation.pascal_voc_evaluation INFO: toaster has 4399 predictions.
[05/08 09:15:48] d2.evaluation.pascal_voc_evaluation INFO: sink has 9994 predictions.
[05/08 09:15:48] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 8075 predictions.
[05/08 09:15:48] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2835 predictions.
[05/08 09:15:49] d2.evaluation.pascal_voc_evaluation INFO: skis has 2139 predictions.
[05/08 09:15:49] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2906 predictions.
[05/08 09:15:49] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 2358 predictions.
[05/08 09:15:49] d2.evaluation.pascal_voc_evaluation INFO: kite has 2881 predictions.
[05/08 09:15:50] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 2587 predictions.
[05/08 09:15:50] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 3189 predictions.
[05/08 09:15:50] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 4796 predictions.
[05/08 09:15:50] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 4563 predictions.
[05/08 09:15:50] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 2620 predictions.
[05/08 09:15:51] d2.evaluation.pascal_voc_evaluation INFO: banana has 2216 predictions.
[05/08 09:15:51] d2.evaluation.pascal_voc_evaluation INFO: apple has 1751 predictions.
[05/08 09:15:51] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 3758 predictions.
[05/08 09:15:51] d2.evaluation.pascal_voc_evaluation INFO: orange has 2077 predictions.
[05/08 09:15:52] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 3059 predictions.
[05/08 09:15:52] d2.evaluation.pascal_voc_evaluation INFO: carrot has 2064 predictions.
[05/08 09:15:52] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 1100 predictions.
[05/08 09:15:52] d2.evaluation.pascal_voc_evaluation INFO: pizza has 2528 predictions.
[05/08 09:15:52] d2.evaluation.pascal_voc_evaluation INFO: donut has 2422 predictions.
[05/08 09:15:53] d2.evaluation.pascal_voc_evaluation INFO: cake has 4095 predictions.
[05/08 09:15:53] d2.evaluation.pascal_voc_evaluation INFO: bed has 6840 predictions.
[05/08 09:15:53] d2.evaluation.pascal_voc_evaluation INFO: toilet has 2595 predictions.
[05/08 09:15:53] d2.evaluation.pascal_voc_evaluation INFO: laptop has 4023 predictions.
[05/08 09:15:54] d2.evaluation.pascal_voc_evaluation INFO: mouse has 2089 predictions.
[05/08 09:15:54] d2.evaluation.pascal_voc_evaluation INFO: remote has 1706 predictions.
[05/08 09:15:54] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1848 predictions.
[05/08 09:15:54] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 4455 predictions.
[05/08 09:15:55] d2.evaluation.pascal_voc_evaluation INFO: book has 22887 predictions.
[05/08 09:15:55] d2.evaluation.pascal_voc_evaluation INFO: clock has 3746 predictions.
[05/08 09:15:55] d2.evaluation.pascal_voc_evaluation INFO: vase has 5885 predictions.
[05/08 09:15:56] d2.evaluation.pascal_voc_evaluation INFO: scissors has 2903 predictions.
[05/08 09:15:56] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 5273 predictions.
[05/08 09:15:56] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 2198 predictions.
[05/08 09:15:56] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1918 predictions.
[05/08 09:15:57] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 4328 predictions.
[05/08 09:15:57] d2.evaluation.pascal_voc_evaluation INFO: cup has 17525 predictions.
[05/08 09:15:57] d2.evaluation.pascal_voc_evaluation INFO: fork has 2143 predictions.
[05/08 09:15:58] d2.evaluation.pascal_voc_evaluation INFO: knife has 5520 predictions.
[05/08 09:15:58] d2.evaluation.pascal_voc_evaluation INFO: spoon has 5113 predictions.
[05/08 09:15:58] d2.evaluation.pascal_voc_evaluation INFO: bowl has 13989 predictions.
[05/08 09:15:59] d2.evaluation.pascal_voc_evaluation INFO: unknown has 17700 predictions.
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['65.4', '52.1', '50.4', '33.3', '21.8', '58.7', '48.2', '72.4', '19.8', '65.9', '14.4', '71.9', '77.8', '61.6', '46.6', '24.5', '59.4', '43.1', '67.5', '53.5', '13.8', '10.2', '50.8', '49.4', '44.5', '8.7', '56.7', '58.0', '73.2', '72.2', '2.7', '15.2', '1.5', '5.2', '8.9', '10.1', '5.4', '10.8', '8.2', '12.6', '31.8', '6.3', '9.2', '21.8', '15.4', '10.0', '11.1', '17.9', '15.0', '29.0', '8.3', '3.9', '9.8', '7.4', '8.4', '2.6', '7.0', '15.5', '11.3', '6.5', '18.8', '26.0', '31.4', '28.2', '7.5', '23.2', '11.1', '2.7', '30.2', '12.0', '10.4', '27.0', '0.0', '1.1', '5.3', '8.1', '3.0', '1.1', '1.9', '7.8', 'nan']
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['11.7', '12.5', '19.2', '6.8', '4.1', '9.9', '7.4', '19.2', '4.7', '11.3', '3.9', '17.3', '13.2', '12.1', '9.7', '6.6', '15.6', '5.8', '9.6', '8.2', '2.4', '5.5', '3.4', '2.7', '1.9', '1.7', '7.1', '2.2', '15.5', '14.0', '1.9', '5.3', '1.5', '5.7', '2.5', '1.2', '1.6', '0.1', '1.6', '1.2', '3.0', '4.2', '1.2', '5.2', '6.8', '2.6', '2.2', '2.4', '3.4', '5.1', '7.4', '4.9', '3.2', '6.6', '5.4', '5.2', '5.4', '8.1', '5.6', '4.6', '1.9', '5.4', '4.3', '3.5', '4.4', '6.2', '2.7', '2.3', '4.8', '3.1', '0.6', '2.8', '0.0', '0.6', '4.3', '3.4', '3.6', '1.6', '1.4', '3.4', '0.0']
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['87.8', '70.7', '69.5', '67.5', '48.2', '85.1', '73.5', '90.8', '45.6', '85.3', '44.9', '91.6', '92.6', '82.5', '69.9', '65.2', '80.5', '76.0', '91.2', '79.2', '68.1', '33.9', '67.6', '70.1', '66.7', '28.7', '86.1', '84.9', '89.3', '87.2', '26.4', '41.7', '19.8', '15.3', '41.1', '43.9', '33.6', '35.3', '36.4', '44.9', '62.3', '28.3', '42.2', '38.3', '41.4', '34.9', '39.9', '48.5', '50.8', '50.0', '28.0', '21.6', '35.5', '28.3', '30.5', '14.9', '28.1', '39.4', '26.2', '29.1', '67.7', '54.7', '59.8', '60.3', '22.7', '65.3', '31.4', '34.2', '50.6', '48.7', '34.8', '60.1', '5.9', '12.5', '33.3', '37.3', '19.2', '12.9', '15.8', '38.6', 'nan']
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 29.576622309744792
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 6.339498454557008
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 53.94343034848574
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 12.84018730996964
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 3.0145593710534624
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 38.29352425421128
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 25.392513559801007
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 5.508263683681122
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 50.03095382491712
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/08 09:16:01] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/08 09:16:01] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 09:16:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 09:16:01] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 09:16:01] d2.evaluation.testing INFO: copypaste: nan,nan
[05/08 09:23:00] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 09:23:01] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:23:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:23:01] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:23:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.3
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:23:01] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/08 09:23:01] d2.utils.env INFO: Using a generated random seed 1710877
[05/08 09:23:02] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:23:02] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:23:02] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:23:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:23:04] d2.data.build INFO: Known classes: range(0, 80)
[05/08 09:23:04] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:23:04] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:23:04] d2.data.build INFO: Number of datapoints: 10246
[05/08 09:23:04] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:23:04] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:23:04] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:23:04] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:23:04] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:23:13] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1492 s / img. ETA=0:06:24
[05/08 09:23:18] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1428 s / img. ETA=0:06:03
[05/08 09:23:24] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1446 s / img. ETA=0:06:02
[05/08 09:23:29] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1476 s / img. ETA=0:06:05
[05/08 09:23:34] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1489 s / img. ETA=0:06:03
[05/08 09:23:39] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1502 s / img. ETA=0:06:02
[05/08 09:23:44] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1506 s / img. ETA=0:05:57
[05/08 09:23:49] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1496 s / img. ETA=0:05:50
[05/08 09:23:54] d2.evaluation.evaluator INFO: Inference done 281/2562. 0.1504 s / img. ETA=0:05:47
[05/08 09:23:59] d2.evaluation.evaluator INFO: Inference done 314/2562. 0.1505 s / img. ETA=0:05:42
[05/08 09:24:05] d2.evaluation.evaluator INFO: Inference done 347/2562. 0.1508 s / img. ETA=0:05:37
[05/08 09:24:10] d2.evaluation.evaluator INFO: Inference done 379/2562. 0.1513 s / img. ETA=0:05:34
[05/08 09:24:15] d2.evaluation.evaluator INFO: Inference done 414/2562. 0.1507 s / img. ETA=0:05:27
[05/08 09:24:20] d2.evaluation.evaluator INFO: Inference done 447/2562. 0.1508 s / img. ETA=0:05:22
[05/08 09:24:25] d2.evaluation.evaluator INFO: Inference done 482/2562. 0.1501 s / img. ETA=0:05:15
[05/08 09:24:30] d2.evaluation.evaluator INFO: Inference done 518/2562. 0.1492 s / img. ETA=0:05:08
[05/08 09:24:35] d2.evaluation.evaluator INFO: Inference done 553/2562. 0.1487 s / img. ETA=0:05:02
[05/08 09:24:40] d2.evaluation.evaluator INFO: Inference done 587/2562. 0.1487 s / img. ETA=0:04:57
[05/08 09:24:45] d2.evaluation.evaluator INFO: Inference done 620/2562. 0.1490 s / img. ETA=0:04:52
[05/08 09:24:50] d2.evaluation.evaluator INFO: Inference done 654/2562. 0.1488 s / img. ETA=0:04:47
[05/08 09:24:55] d2.evaluation.evaluator INFO: Inference done 688/2562. 0.1489 s / img. ETA=0:04:42
[05/08 09:25:00] d2.evaluation.evaluator INFO: Inference done 719/2562. 0.1495 s / img. ETA=0:04:38
[05/08 09:25:05] d2.evaluation.evaluator INFO: Inference done 749/2562. 0.1501 s / img. ETA=0:04:35
[05/08 09:25:10] d2.evaluation.evaluator INFO: Inference done 782/2562. 0.1501 s / img. ETA=0:04:30
[05/08 09:25:15] d2.evaluation.evaluator INFO: Inference done 815/2562. 0.1501 s / img. ETA=0:04:25
[05/08 09:25:20] d2.evaluation.evaluator INFO: Inference done 846/2562. 0.1505 s / img. ETA=0:04:21
[05/08 09:25:26] d2.evaluation.evaluator INFO: Inference done 879/2562. 0.1506 s / img. ETA=0:04:16
[05/08 09:25:31] d2.evaluation.evaluator INFO: Inference done 912/2562. 0.1506 s / img. ETA=0:04:11
[05/08 09:25:36] d2.evaluation.evaluator INFO: Inference done 944/2562. 0.1508 s / img. ETA=0:04:06
[05/08 09:25:41] d2.evaluation.evaluator INFO: Inference done 976/2562. 0.1511 s / img. ETA=0:04:02
[05/08 09:25:46] d2.evaluation.evaluator INFO: Inference done 1011/2562. 0.1509 s / img. ETA=0:03:56
[05/08 09:25:51] d2.evaluation.evaluator INFO: Inference done 1046/2562. 0.1507 s / img. ETA=0:03:51
[05/08 09:25:56] d2.evaluation.evaluator INFO: Inference done 1078/2562. 0.1510 s / img. ETA=0:03:46
[05/08 09:26:01] d2.evaluation.evaluator INFO: Inference done 1112/2562. 0.1509 s / img. ETA=0:03:41
[05/08 09:26:06] d2.evaluation.evaluator INFO: Inference done 1145/2562. 0.1510 s / img. ETA=0:03:36
[05/08 09:26:12] d2.evaluation.evaluator INFO: Inference done 1180/2562. 0.1508 s / img. ETA=0:03:30
[05/08 09:26:17] d2.evaluation.evaluator INFO: Inference done 1210/2562. 0.1512 s / img. ETA=0:03:26
[05/08 09:26:22] d2.evaluation.evaluator INFO: Inference done 1242/2562. 0.1513 s / img. ETA=0:03:22
[05/08 09:26:27] d2.evaluation.evaluator INFO: Inference done 1275/2562. 0.1513 s / img. ETA=0:03:16
[05/08 09:26:32] d2.evaluation.evaluator INFO: Inference done 1307/2562. 0.1514 s / img. ETA=0:03:12
[05/08 09:26:37] d2.evaluation.evaluator INFO: Inference done 1338/2562. 0.1516 s / img. ETA=0:03:07
[05/08 09:26:42] d2.evaluation.evaluator INFO: Inference done 1369/2562. 0.1518 s / img. ETA=0:03:03
[05/08 09:26:47] d2.evaluation.evaluator INFO: Inference done 1397/2562. 0.1525 s / img. ETA=0:02:59
[05/08 09:26:52] d2.evaluation.evaluator INFO: Inference done 1432/2562. 0.1522 s / img. ETA=0:02:54
[05/08 09:26:57] d2.evaluation.evaluator INFO: Inference done 1466/2562. 0.1522 s / img. ETA=0:02:48
[05/08 09:27:02] d2.evaluation.evaluator INFO: Inference done 1499/2562. 0.1522 s / img. ETA=0:02:43
[05/08 09:27:07] d2.evaluation.evaluator INFO: Inference done 1534/2562. 0.1520 s / img. ETA=0:02:38
[05/08 09:27:12] d2.evaluation.evaluator INFO: Inference done 1567/2562. 0.1520 s / img. ETA=0:02:32
[05/08 09:27:18] d2.evaluation.evaluator INFO: Inference done 1603/2562. 0.1518 s / img. ETA=0:02:27
[05/08 09:27:23] d2.evaluation.evaluator INFO: Inference done 1639/2562. 0.1515 s / img. ETA=0:02:21
[05/08 09:27:28] d2.evaluation.evaluator INFO: Inference done 1671/2562. 0.1516 s / img. ETA=0:02:16
[05/08 09:27:33] d2.evaluation.evaluator INFO: Inference done 1706/2562. 0.1514 s / img. ETA=0:02:11
[05/08 09:27:38] d2.evaluation.evaluator INFO: Inference done 1739/2562. 0.1514 s / img. ETA=0:02:06
[05/08 09:27:43] d2.evaluation.evaluator INFO: Inference done 1770/2562. 0.1516 s / img. ETA=0:02:01
[05/08 09:27:48] d2.evaluation.evaluator INFO: Inference done 1802/2562. 0.1517 s / img. ETA=0:01:56
[05/08 09:27:53] d2.evaluation.evaluator INFO: Inference done 1831/2562. 0.1520 s / img. ETA=0:01:52
[05/08 09:27:58] d2.evaluation.evaluator INFO: Inference done 1864/2562. 0.1521 s / img. ETA=0:01:47
[05/08 09:28:03] d2.evaluation.evaluator INFO: Inference done 1898/2562. 0.1520 s / img. ETA=0:01:42
[05/08 09:28:08] d2.evaluation.evaluator INFO: Inference done 1931/2562. 0.1520 s / img. ETA=0:01:37
[05/08 09:28:14] d2.evaluation.evaluator INFO: Inference done 1962/2562. 0.1521 s / img. ETA=0:01:32
[05/08 09:28:19] d2.evaluation.evaluator INFO: Inference done 1996/2562. 0.1520 s / img. ETA=0:01:27
[05/08 09:28:24] d2.evaluation.evaluator INFO: Inference done 2031/2562. 0.1518 s / img. ETA=0:01:21
[05/08 09:28:29] d2.evaluation.evaluator INFO: Inference done 2062/2562. 0.1519 s / img. ETA=0:01:16
[05/08 09:28:34] d2.evaluation.evaluator INFO: Inference done 2096/2562. 0.1519 s / img. ETA=0:01:11
[05/08 09:28:39] d2.evaluation.evaluator INFO: Inference done 2126/2562. 0.1521 s / img. ETA=0:01:07
[05/08 09:28:44] d2.evaluation.evaluator INFO: Inference done 2155/2562. 0.1524 s / img. ETA=0:01:02
[05/08 09:28:49] d2.evaluation.evaluator INFO: Inference done 2188/2562. 0.1524 s / img. ETA=0:00:57
[05/08 09:28:54] d2.evaluation.evaluator INFO: Inference done 2220/2562. 0.1524 s / img. ETA=0:00:52
[05/08 09:28:59] d2.evaluation.evaluator INFO: Inference done 2256/2562. 0.1522 s / img. ETA=0:00:47
[05/08 09:29:04] d2.evaluation.evaluator INFO: Inference done 2287/2562. 0.1523 s / img. ETA=0:00:42
[05/08 09:29:09] d2.evaluation.evaluator INFO: Inference done 2318/2562. 0.1524 s / img. ETA=0:00:37
[05/08 09:29:14] d2.evaluation.evaluator INFO: Inference done 2349/2562. 0.1525 s / img. ETA=0:00:32
[05/08 09:29:19] d2.evaluation.evaluator INFO: Inference done 2382/2562. 0.1525 s / img. ETA=0:00:27
[05/08 09:29:24] d2.evaluation.evaluator INFO: Inference done 2415/2562. 0.1525 s / img. ETA=0:00:22
[05/08 09:29:29] d2.evaluation.evaluator INFO: Inference done 2447/2562. 0.1525 s / img. ETA=0:00:17
[05/08 09:29:34] d2.evaluation.evaluator INFO: Inference done 2481/2562. 0.1525 s / img. ETA=0:00:12
[05/08 09:29:39] d2.evaluation.evaluator INFO: Inference done 2511/2562. 0.1527 s / img. ETA=0:00:07
[05/08 09:29:45] d2.evaluation.evaluator INFO: Inference done 2544/2562. 0.1527 s / img. ETA=0:00:02
[05/08 09:29:48] d2.evaluation.evaluator INFO: Total inference time: 0:06:35.375225 (0.154625 s / img per device, on 4 devices)
[05/08 09:29:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:30 (0.152746 s / img per device, on 4 devices)
[05/08 09:30:23] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 09:30:23] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 1587 predictions.
[05/08 09:30:25] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 2248 predictions.
[05/08 09:30:25] d2.evaluation.pascal_voc_evaluation INFO: bird has 1985 predictions.
[05/08 09:30:25] d2.evaluation.pascal_voc_evaluation INFO: boat has 3287 predictions.
[05/08 09:30:25] d2.evaluation.pascal_voc_evaluation INFO: bottle has 18376 predictions.
[05/08 09:30:26] d2.evaluation.pascal_voc_evaluation INFO: bus has 2415 predictions.
[05/08 09:30:26] d2.evaluation.pascal_voc_evaluation INFO: car has 18739 predictions.
[05/08 09:30:27] d2.evaluation.pascal_voc_evaluation INFO: cat has 1612 predictions.
[05/08 09:30:27] d2.evaluation.pascal_voc_evaluation INFO: chair has 22068 predictions.
[05/08 09:30:28] d2.evaluation.pascal_voc_evaluation INFO: cow has 1737 predictions.
[05/08 09:30:28] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 8747 predictions.
[05/08 09:30:28] d2.evaluation.pascal_voc_evaluation INFO: dog has 2524 predictions.
[05/08 09:30:28] d2.evaluation.pascal_voc_evaluation INFO: horse has 1886 predictions.
[05/08 09:30:29] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 2351 predictions.
[05/08 09:30:29] d2.evaluation.pascal_voc_evaluation INFO: person has 71134 predictions.
[05/08 09:30:31] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 5870 predictions.
[05/08 09:30:32] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1165 predictions.
[05/08 09:30:32] d2.evaluation.pascal_voc_evaluation INFO: sofa has 4668 predictions.
[05/08 09:30:32] d2.evaluation.pascal_voc_evaluation INFO: train has 2369 predictions.
[05/08 09:30:32] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 4840 predictions.
[05/08 09:30:33] d2.evaluation.pascal_voc_evaluation INFO: truck has 8757 predictions.
[05/08 09:30:33] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 3491 predictions.
[05/08 09:30:33] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1785 predictions.
[05/08 09:30:33] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1806 predictions.
[05/08 09:30:34] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1904 predictions.
[05/08 09:30:34] d2.evaluation.pascal_voc_evaluation INFO: bench has 6844 predictions.
[05/08 09:30:34] d2.evaluation.pascal_voc_evaluation INFO: elephant has 2178 predictions.
[05/08 09:30:34] d2.evaluation.pascal_voc_evaluation INFO: bear has 2292 predictions.
[05/08 09:30:35] d2.evaluation.pascal_voc_evaluation INFO: zebra has 972 predictions.
[05/08 09:30:35] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1055 predictions.
[05/08 09:30:35] d2.evaluation.pascal_voc_evaluation INFO: backpack has 5806 predictions.
[05/08 09:30:35] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 2774 predictions.
[05/08 09:30:36] d2.evaluation.pascal_voc_evaluation INFO: handbag has 8479 predictions.
[05/08 09:30:36] d2.evaluation.pascal_voc_evaluation INFO: tie has 787 predictions.
[05/08 09:30:36] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 4740 predictions.
[05/08 09:30:36] d2.evaluation.pascal_voc_evaluation INFO: microwave has 3276 predictions.
[05/08 09:30:37] d2.evaluation.pascal_voc_evaluation INFO: oven has 4253 predictions.
[05/08 09:30:37] d2.evaluation.pascal_voc_evaluation INFO: toaster has 4002 predictions.
[05/08 09:30:37] d2.evaluation.pascal_voc_evaluation INFO: sink has 6962 predictions.
[05/08 09:30:37] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 5594 predictions.
[05/08 09:30:38] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2722 predictions.
[05/08 09:30:38] d2.evaluation.pascal_voc_evaluation INFO: skis has 1270 predictions.
[05/08 09:30:38] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2155 predictions.
[05/08 09:30:38] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 2217 predictions.
[05/08 09:30:38] d2.evaluation.pascal_voc_evaluation INFO: kite has 2089 predictions.
[05/08 09:30:39] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 2035 predictions.
[05/08 09:30:39] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 2811 predictions.
[05/08 09:30:39] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 3776 predictions.
[05/08 09:30:39] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 3250 predictions.
[05/08 09:30:39] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 2142 predictions.
[05/08 09:30:40] d2.evaluation.pascal_voc_evaluation INFO: banana has 1456 predictions.
[05/08 09:30:40] d2.evaluation.pascal_voc_evaluation INFO: apple has 1253 predictions.
[05/08 09:30:40] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 2572 predictions.
[05/08 09:30:40] d2.evaluation.pascal_voc_evaluation INFO: orange has 1484 predictions.
[05/08 09:30:41] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 1858 predictions.
[05/08 09:30:41] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1444 predictions.
[05/08 09:30:41] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 873 predictions.
[05/08 09:30:41] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1730 predictions.
[05/08 09:30:41] d2.evaluation.pascal_voc_evaluation INFO: donut has 2053 predictions.
[05/08 09:30:42] d2.evaluation.pascal_voc_evaluation INFO: cake has 3239 predictions.
[05/08 09:30:42] d2.evaluation.pascal_voc_evaluation INFO: bed has 4405 predictions.
[05/08 09:30:42] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1975 predictions.
[05/08 09:30:42] d2.evaluation.pascal_voc_evaluation INFO: laptop has 3031 predictions.
[05/08 09:30:42] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1981 predictions.
[05/08 09:30:43] d2.evaluation.pascal_voc_evaluation INFO: remote has 1430 predictions.
[05/08 09:30:43] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1289 predictions.
[05/08 09:30:43] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 3820 predictions.
[05/08 09:30:43] d2.evaluation.pascal_voc_evaluation INFO: book has 14635 predictions.
[05/08 09:30:44] d2.evaluation.pascal_voc_evaluation INFO: clock has 3361 predictions.
[05/08 09:30:44] d2.evaluation.pascal_voc_evaluation INFO: vase has 4716 predictions.
[05/08 09:30:44] d2.evaluation.pascal_voc_evaluation INFO: scissors has 2136 predictions.
[05/08 09:30:44] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 3888 predictions.
[05/08 09:30:45] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1921 predictions.
[05/08 09:30:45] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1481 predictions.
[05/08 09:30:45] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 2659 predictions.
[05/08 09:30:45] d2.evaluation.pascal_voc_evaluation INFO: cup has 13115 predictions.
[05/08 09:30:46] d2.evaluation.pascal_voc_evaluation INFO: fork has 1549 predictions.
[05/08 09:30:46] d2.evaluation.pascal_voc_evaluation INFO: knife has 4229 predictions.
[05/08 09:30:46] d2.evaluation.pascal_voc_evaluation INFO: spoon has 3873 predictions.
[05/08 09:30:46] d2.evaluation.pascal_voc_evaluation INFO: bowl has 10586 predictions.
[05/08 09:30:47] d2.evaluation.pascal_voc_evaluation INFO: unknown has 14533 predictions.
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['69.9', '52.4', '51.1', '34.0', '21.3', '61.4', '48.3', '72.9', '19.5', '67.5', '15.2', '72.9', '80.2', '62.5', '45.8', '24.5', '59.5', '44.5', '69.5', '53.6', '14.2', '10.4', '52.2', '49.2', '46.1', '8.8', '57.0', '56.1', '71.8', '74.1', '2.7', '15.3', '1.4', '5.2', '8.7', '10.1', '5.1', '10.8', '8.0', '12.9', '31.8', '5.4', '9.3', '21.8', '15.5', '10.2', '10.7', '18.4', '13.8', '30.1', '7.7', '4.0', '9.2', '7.7', '8.7', '2.4', '7.6', '15.8', '11.5', '6.2', '19.0', '27.3', '31.9', '28.5', '7.3', '23.9', '11.2', '2.4', '30.1', '12.0', '10.2', '27.5', '0.0', '1.1', '5.4', '8.1', '3.0', '1.0', '1.8', '7.8', 'nan']
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['17.7', '18.9', '22.9', '9.2', '5.2', '13.0', '11.4', '27.7', '6.3', '15.0', '6.4', '23.0', '19.6', '18.0', '16.1', '9.5', '20.8', '8.2', '13.3', '9.9', '3.3', '6.3', '4.0', '3.0', '2.2', '2.3', '9.3', '2.6', '21.8', '18.0', '2.3', '6.8', '1.5', '6.5', '2.7', '1.4', '1.9', '0.1', '2.0', '1.5', '3.2', '4.7', '1.5', '5.5', '8.7', '3.0', '2.4', '2.9', '4.1', '6.0', '9.3', '6.0', '4.0', '8.2', '7.9', '6.1', '6.4', '11.1', '6.5', '5.4', '2.5', '6.7', '5.4', '3.7', '4.5', '8.4', '3.1', '2.7', '5.3', '3.6', '0.6', '3.5', '0.1', '0.7', '6.2', '4.3', '4.2', '1.7', '1.7', '4.2', '0.0']
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['83.3', '65.0', '65.2', '62.1', '44.6', '80.4', '67.4', '87.3', '40.5', '81.8', '40.5', '87.8', '89.5', '77.3', '64.4', '59.6', '74.5', '70.3', '86.0', '75.7', '61.8', '30.2', '66.7', '70.1', '65.1', '24.9', '78.0', '80.8', '78.5', '81.2', '23.6', '36.4', '16.3', '13.9', '35.8', '42.1', '27.8', '35.3', '32.0', '40.2', '62.3', '19.0', '39.8', '38.0', '38.2', '31.8', '38.2', '46.8', '42.7', '48.1', '23.0', '19.0', '31.0', '25.0', '27.2', '12.3', '26.7', '37.1', '25.6', '27.0', '59.3', '52.0', '56.4', '60.3', '19.7', '61.4', '30.9', '26.5', '50.0', '45.0', '28.3', '55.6', '5.9', '11.4', '29.6', '35.5', '16.0', '10.7', '14.3', '36.4', 'nan']
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 29.910900202837745
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 8.409885801656802
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 50.04177163799064
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 12.97858328616762
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 3.6615564086313155
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 35.24656987379621
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 25.67782097367022
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 7.222803453400431
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 46.34297119694204
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/08 09:30:49] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/08 09:30:49] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 09:30:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 09:30:49] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 09:30:49] d2.evaluation.testing INFO: copypaste: nan,nan
[05/08 09:32:23] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 09:32:24] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:32:24] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:32:24] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.2
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:32:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:32:24] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/08 09:32:24] d2.utils.env INFO: Using a generated random seed 24316561
[05/08 09:32:24] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:32:24] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:32:25] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:32:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:32:26] d2.data.build INFO: Known classes: range(0, 80)
[05/08 09:32:26] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:32:27] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:32:27] d2.data.build INFO: Number of datapoints: 10246
[05/08 09:32:27] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:32:27] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:32:27] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:32:27] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:32:27] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:32:36] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1484 s / img. ETA=0:06:21
[05/08 09:32:41] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1431 s / img. ETA=0:06:03
[05/08 09:32:46] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1450 s / img. ETA=0:06:03
[05/08 09:32:52] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1481 s / img. ETA=0:06:06
[05/08 09:32:57] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1493 s / img. ETA=0:06:04
[05/08 09:33:02] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1507 s / img. ETA=0:06:02
[05/08 09:33:07] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1512 s / img. ETA=0:05:58
[05/08 09:33:12] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1501 s / img. ETA=0:05:51
[05/08 09:33:17] d2.evaluation.evaluator INFO: Inference done 281/2562. 0.1509 s / img. ETA=0:05:47
[05/08 09:33:22] d2.evaluation.evaluator INFO: Inference done 314/2562. 0.1510 s / img. ETA=0:05:42
[05/08 09:33:27] d2.evaluation.evaluator INFO: Inference done 347/2562. 0.1512 s / img. ETA=0:05:38
[05/08 09:33:32] d2.evaluation.evaluator INFO: Inference done 379/2562. 0.1517 s / img. ETA=0:05:34
[05/08 09:33:38] d2.evaluation.evaluator INFO: Inference done 414/2562. 0.1511 s / img. ETA=0:05:28
[05/08 09:33:43] d2.evaluation.evaluator INFO: Inference done 447/2562. 0.1513 s / img. ETA=0:05:23
[05/08 09:33:48] d2.evaluation.evaluator INFO: Inference done 482/2562. 0.1507 s / img. ETA=0:05:16
[05/08 09:33:53] d2.evaluation.evaluator INFO: Inference done 518/2562. 0.1498 s / img. ETA=0:05:09
[05/08 09:33:58] d2.evaluation.evaluator INFO: Inference done 553/2562. 0.1493 s / img. ETA=0:05:03
[05/08 09:34:03] d2.evaluation.evaluator INFO: Inference done 587/2562. 0.1494 s / img. ETA=0:04:58
[05/08 09:34:08] d2.evaluation.evaluator INFO: Inference done 620/2562. 0.1497 s / img. ETA=0:04:53
[05/08 09:34:13] d2.evaluation.evaluator INFO: Inference done 654/2562. 0.1497 s / img. ETA=0:04:48
[05/08 09:34:18] d2.evaluation.evaluator INFO: Inference done 687/2562. 0.1498 s / img. ETA=0:04:43
[05/08 09:34:23] d2.evaluation.evaluator INFO: Inference done 717/2562. 0.1505 s / img. ETA=0:04:40
[05/08 09:34:28] d2.evaluation.evaluator INFO: Inference done 747/2562. 0.1511 s / img. ETA=0:04:37
[05/08 09:34:34] d2.evaluation.evaluator INFO: Inference done 779/2562. 0.1514 s / img. ETA=0:04:32
[05/08 09:34:39] d2.evaluation.evaluator INFO: Inference done 813/2562. 0.1513 s / img. ETA=0:04:27
[05/08 09:34:44] d2.evaluation.evaluator INFO: Inference done 844/2562. 0.1518 s / img. ETA=0:04:23
[05/08 09:34:49] d2.evaluation.evaluator INFO: Inference done 876/2562. 0.1521 s / img. ETA=0:04:19
[05/08 09:34:54] d2.evaluation.evaluator INFO: Inference done 909/2562. 0.1521 s / img. ETA=0:04:14
[05/08 09:34:59] d2.evaluation.evaluator INFO: Inference done 941/2562. 0.1522 s / img. ETA=0:04:09
[05/08 09:35:04] d2.evaluation.evaluator INFO: Inference done 973/2562. 0.1525 s / img. ETA=0:04:04
[05/08 09:35:09] d2.evaluation.evaluator INFO: Inference done 1007/2562. 0.1522 s / img. ETA=0:03:59
[05/08 09:35:14] d2.evaluation.evaluator INFO: Inference done 1041/2562. 0.1520 s / img. ETA=0:03:53
[05/08 09:35:19] d2.evaluation.evaluator INFO: Inference done 1073/2562. 0.1521 s / img. ETA=0:03:49
[05/08 09:35:24] d2.evaluation.evaluator INFO: Inference done 1106/2562. 0.1521 s / img. ETA=0:03:43
[05/08 09:35:30] d2.evaluation.evaluator INFO: Inference done 1140/2562. 0.1520 s / img. ETA=0:03:38
[05/08 09:35:35] d2.evaluation.evaluator INFO: Inference done 1176/2562. 0.1515 s / img. ETA=0:03:32
[05/08 09:35:40] d2.evaluation.evaluator INFO: Inference done 1205/2562. 0.1520 s / img. ETA=0:03:28
[05/08 09:35:45] d2.evaluation.evaluator INFO: Inference done 1238/2562. 0.1521 s / img. ETA=0:03:23
[05/08 09:35:50] d2.evaluation.evaluator INFO: Inference done 1271/2562. 0.1521 s / img. ETA=0:03:18
[05/08 09:35:55] d2.evaluation.evaluator INFO: Inference done 1304/2562. 0.1521 s / img. ETA=0:03:13
[05/08 09:36:00] d2.evaluation.evaluator INFO: Inference done 1335/2562. 0.1524 s / img. ETA=0:03:09
[05/08 09:36:05] d2.evaluation.evaluator INFO: Inference done 1367/2562. 0.1525 s / img. ETA=0:03:04
[05/08 09:36:10] d2.evaluation.evaluator INFO: Inference done 1395/2562. 0.1532 s / img. ETA=0:03:00
[05/08 09:36:15] d2.evaluation.evaluator INFO: Inference done 1429/2562. 0.1530 s / img. ETA=0:02:55
[05/08 09:36:20] d2.evaluation.evaluator INFO: Inference done 1463/2562. 0.1529 s / img. ETA=0:02:49
[05/08 09:36:26] d2.evaluation.evaluator INFO: Inference done 1496/2562. 0.1529 s / img. ETA=0:02:44
[05/08 09:36:31] d2.evaluation.evaluator INFO: Inference done 1530/2562. 0.1529 s / img. ETA=0:02:39
[05/08 09:36:36] d2.evaluation.evaluator INFO: Inference done 1562/2562. 0.1529 s / img. ETA=0:02:34
[05/08 09:36:41] d2.evaluation.evaluator INFO: Inference done 1597/2562. 0.1527 s / img. ETA=0:02:29
[05/08 09:36:46] d2.evaluation.evaluator INFO: Inference done 1634/2562. 0.1524 s / img. ETA=0:02:22
[05/08 09:36:51] d2.evaluation.evaluator INFO: Inference done 1667/2562. 0.1524 s / img. ETA=0:02:17
[05/08 09:36:56] d2.evaluation.evaluator INFO: Inference done 1702/2562. 0.1523 s / img. ETA=0:02:12
[05/08 09:37:01] d2.evaluation.evaluator INFO: Inference done 1736/2562. 0.1522 s / img. ETA=0:02:07
[05/08 09:37:07] d2.evaluation.evaluator INFO: Inference done 1765/2562. 0.1525 s / img. ETA=0:02:02
[05/08 09:37:12] d2.evaluation.evaluator INFO: Inference done 1799/2562. 0.1524 s / img. ETA=0:01:57
[05/08 09:37:17] d2.evaluation.evaluator INFO: Inference done 1828/2562. 0.1527 s / img. ETA=0:01:53
[05/08 09:37:22] d2.evaluation.evaluator INFO: Inference done 1861/2562. 0.1527 s / img. ETA=0:01:48
[05/08 09:37:27] d2.evaluation.evaluator INFO: Inference done 1895/2562. 0.1526 s / img. ETA=0:01:42
[05/08 09:37:32] d2.evaluation.evaluator INFO: Inference done 1928/2562. 0.1526 s / img. ETA=0:01:37
[05/08 09:37:37] d2.evaluation.evaluator INFO: Inference done 1959/2562. 0.1527 s / img. ETA=0:01:33
[05/08 09:37:42] d2.evaluation.evaluator INFO: Inference done 1993/2562. 0.1526 s / img. ETA=0:01:27
[05/08 09:37:47] d2.evaluation.evaluator INFO: Inference done 2029/2562. 0.1524 s / img. ETA=0:01:22
[05/08 09:37:52] d2.evaluation.evaluator INFO: Inference done 2060/2562. 0.1525 s / img. ETA=0:01:17
[05/08 09:37:57] d2.evaluation.evaluator INFO: Inference done 2094/2562. 0.1524 s / img. ETA=0:01:12
[05/08 09:38:02] d2.evaluation.evaluator INFO: Inference done 2124/2562. 0.1527 s / img. ETA=0:01:07
[05/08 09:38:07] d2.evaluation.evaluator INFO: Inference done 2153/2562. 0.1529 s / img. ETA=0:01:03
[05/08 09:38:12] d2.evaluation.evaluator INFO: Inference done 2185/2562. 0.1529 s / img. ETA=0:00:58
[05/08 09:38:17] d2.evaluation.evaluator INFO: Inference done 2219/2562. 0.1529 s / img. ETA=0:00:53
[05/08 09:38:22] d2.evaluation.evaluator INFO: Inference done 2254/2562. 0.1527 s / img. ETA=0:00:47
[05/08 09:38:28] d2.evaluation.evaluator INFO: Inference done 2287/2562. 0.1527 s / img. ETA=0:00:42
[05/08 09:38:33] d2.evaluation.evaluator INFO: Inference done 2320/2562. 0.1528 s / img. ETA=0:00:37
[05/08 09:38:38] d2.evaluation.evaluator INFO: Inference done 2351/2562. 0.1529 s / img. ETA=0:00:32
[05/08 09:38:43] d2.evaluation.evaluator INFO: Inference done 2384/2562. 0.1529 s / img. ETA=0:00:27
[05/08 09:38:48] d2.evaluation.evaluator INFO: Inference done 2417/2562. 0.1529 s / img. ETA=0:00:22
[05/08 09:38:53] d2.evaluation.evaluator INFO: Inference done 2451/2562. 0.1528 s / img. ETA=0:00:17
[05/08 09:38:58] d2.evaluation.evaluator INFO: Inference done 2485/2562. 0.1527 s / img. ETA=0:00:11
[05/08 09:39:03] d2.evaluation.evaluator INFO: Inference done 2515/2562. 0.1529 s / img. ETA=0:00:07
[05/08 09:39:08] d2.evaluation.evaluator INFO: Inference done 2547/2562. 0.1529 s / img. ETA=0:00:02
[05/08 09:39:11] d2.evaluation.evaluator INFO: Total inference time: 0:06:35.667096 (0.154739 s / img per device, on 4 devices)
[05/08 09:39:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:31 (0.152917 s / img per device, on 4 devices)
[05/08 09:39:51] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 09:39:51] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 1343 predictions.
[05/08 09:39:52] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 1895 predictions.
[05/08 09:39:52] d2.evaluation.pascal_voc_evaluation INFO: bird has 1842 predictions.
[05/08 09:39:52] d2.evaluation.pascal_voc_evaluation INFO: boat has 2868 predictions.
[05/08 09:39:53] d2.evaluation.pascal_voc_evaluation INFO: bottle has 16779 predictions.
[05/08 09:39:53] d2.evaluation.pascal_voc_evaluation INFO: bus has 2201 predictions.
[05/08 09:39:53] d2.evaluation.pascal_voc_evaluation INFO: car has 15184 predictions.
[05/08 09:39:54] d2.evaluation.pascal_voc_evaluation INFO: cat has 1410 predictions.
[05/08 09:39:54] d2.evaluation.pascal_voc_evaluation INFO: chair has 19348 predictions.
[05/08 09:39:55] d2.evaluation.pascal_voc_evaluation INFO: cow has 1573 predictions.
[05/08 09:39:55] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 7005 predictions.
[05/08 09:39:55] d2.evaluation.pascal_voc_evaluation INFO: dog has 2281 predictions.
[05/08 09:39:56] d2.evaluation.pascal_voc_evaluation INFO: horse has 1673 predictions.
[05/08 09:39:56] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 1991 predictions.
[05/08 09:39:56] d2.evaluation.pascal_voc_evaluation INFO: person has 57827 predictions.
[05/08 09:39:58] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 4981 predictions.
[05/08 09:39:59] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1048 predictions.
[05/08 09:39:59] d2.evaluation.pascal_voc_evaluation INFO: sofa has 4030 predictions.
[05/08 09:39:59] d2.evaluation.pascal_voc_evaluation INFO: train has 2087 predictions.
[05/08 09:39:59] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 4607 predictions.
[05/08 09:40:00] d2.evaluation.pascal_voc_evaluation INFO: truck has 7697 predictions.
[05/08 09:40:00] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 3283 predictions.
[05/08 09:40:00] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1742 predictions.
[05/08 09:40:00] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1798 predictions.
[05/08 09:40:01] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1868 predictions.
[05/08 09:40:01] d2.evaluation.pascal_voc_evaluation INFO: bench has 6053 predictions.
[05/08 09:40:01] d2.evaluation.pascal_voc_evaluation INFO: elephant has 1963 predictions.
[05/08 09:40:01] d2.evaluation.pascal_voc_evaluation INFO: bear has 2190 predictions.
[05/08 09:40:01] d2.evaluation.pascal_voc_evaluation INFO: zebra has 844 predictions.
[05/08 09:40:02] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 965 predictions.
[05/08 09:40:02] d2.evaluation.pascal_voc_evaluation INFO: backpack has 5449 predictions.
[05/08 09:40:02] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 2512 predictions.
[05/08 09:40:02] d2.evaluation.pascal_voc_evaluation INFO: handbag has 8197 predictions.
[05/08 09:40:03] d2.evaluation.pascal_voc_evaluation INFO: tie has 737 predictions.
[05/08 09:40:03] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 4570 predictions.
[05/08 09:40:03] d2.evaluation.pascal_voc_evaluation INFO: microwave has 3210 predictions.
[05/08 09:40:03] d2.evaluation.pascal_voc_evaluation INFO: oven has 3868 predictions.
[05/08 09:40:03] d2.evaluation.pascal_voc_evaluation INFO: toaster has 4020 predictions.
[05/08 09:40:04] d2.evaluation.pascal_voc_evaluation INFO: sink has 6258 predictions.
[05/08 09:40:04] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 5010 predictions.
[05/08 09:40:04] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2735 predictions.
[05/08 09:40:04] d2.evaluation.pascal_voc_evaluation INFO: skis has 1062 predictions.
[05/08 09:40:05] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2008 predictions.
[05/08 09:40:05] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 2226 predictions.
[05/08 09:40:05] d2.evaluation.pascal_voc_evaluation INFO: kite has 1947 predictions.
[05/08 09:40:05] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1944 predictions.
[05/08 09:40:05] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 2801 predictions.
[05/08 09:40:06] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 3608 predictions.
[05/08 09:40:06] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 2961 predictions.
[05/08 09:40:06] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 2072 predictions.
[05/08 09:40:06] d2.evaluation.pascal_voc_evaluation INFO: banana has 1274 predictions.
[05/08 09:40:06] d2.evaluation.pascal_voc_evaluation INFO: apple has 1106 predictions.
[05/08 09:40:07] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 2293 predictions.
[05/08 09:40:07] d2.evaluation.pascal_voc_evaluation INFO: orange has 1335 predictions.
[05/08 09:40:07] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 1552 predictions.
[05/08 09:40:07] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1263 predictions.
[05/08 09:40:08] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 818 predictions.
[05/08 09:40:08] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1556 predictions.
[05/08 09:40:08] d2.evaluation.pascal_voc_evaluation INFO: donut has 1994 predictions.
[05/08 09:40:08] d2.evaluation.pascal_voc_evaluation INFO: cake has 3120 predictions.
[05/08 09:40:08] d2.evaluation.pascal_voc_evaluation INFO: bed has 3888 predictions.
[05/08 09:40:09] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1867 predictions.
[05/08 09:40:09] d2.evaluation.pascal_voc_evaluation INFO: laptop has 2882 predictions.
[05/08 09:40:09] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1992 predictions.
[05/08 09:40:09] d2.evaluation.pascal_voc_evaluation INFO: remote has 1396 predictions.
[05/08 09:40:10] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1204 predictions.
[05/08 09:40:10] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 3740 predictions.
[05/08 09:40:10] d2.evaluation.pascal_voc_evaluation INFO: book has 12845 predictions.
[05/08 09:40:10] d2.evaluation.pascal_voc_evaluation INFO: clock has 3323 predictions.
[05/08 09:40:11] d2.evaluation.pascal_voc_evaluation INFO: vase has 4598 predictions.
[05/08 09:40:11] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1984 predictions.
[05/08 09:40:11] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 3572 predictions.
[05/08 09:40:11] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1899 predictions.
[05/08 09:40:11] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1400 predictions.
[05/08 09:40:12] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 2404 predictions.
[05/08 09:40:12] d2.evaluation.pascal_voc_evaluation INFO: cup has 12478 predictions.
[05/08 09:40:12] d2.evaluation.pascal_voc_evaluation INFO: fork has 1435 predictions.
[05/08 09:40:13] d2.evaluation.pascal_voc_evaluation INFO: knife has 3987 predictions.
[05/08 09:40:13] d2.evaluation.pascal_voc_evaluation INFO: spoon has 3648 predictions.
[05/08 09:40:13] d2.evaluation.pascal_voc_evaluation INFO: bowl has 10046 predictions.
[05/08 09:40:13] d2.evaluation.pascal_voc_evaluation INFO: unknown has 13872 predictions.
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['70.5', '51.3', '50.6', '33.0', '21.1', '60.1', '47.1', '72.7', '19.0', '66.9', '15.2', '71.6', '79.5', '59.8', '44.0', '23.6', '57.0', '44.8', '69.7', '53.5', '13.5', '10.4', '51.9', '49.4', '46.1', '8.7', '54.4', '56.7', '68.1', '70.2', '2.7', '14.5', '1.4', '5.2', '7.9', '10.1', '5.2', '10.8', '8.0', '12.2', '31.8', '4.8', '9.1', '21.8', '15.2', '10.1', '10.7', '18.2', '12.4', '29.9', '7.7', '3.8', '8.9', '7.8', '7.8', '2.0', '7.3', '15.5', '11.2', '6.0', '19.1', '26.9', '31.5', '28.8', '7.1', '23.9', '11.1', '1.9', '30.1', '11.8', '9.8', '27.3', '0.0', '1.1', '5.3', '8.0', '3.0', '1.0', '1.7', '7.8', 'nan']
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['20.4', '21.2', '23.8', '9.7', '5.5', '13.8', '13.3', '30.8', '6.7', '16.2', '7.7', '24.8', '21.8', '19.5', '18.6', '10.5', '21.8', '9.2', '14.6', '10.4', '3.6', '6.4', '4.1', '3.0', '2.2', '2.4', '9.7', '2.6', '23.5', '18.5', '2.3', '6.8', '1.5', '6.8', '2.6', '1.4', '2.0', '0.1', '2.1', '1.5', '3.1', '4.3', '1.6', '5.5', '8.9', '3.1', '2.4', '2.9', '3.7', '6.0', '9.5', '6.2', '4.3', '9.1', '8.1', '5.7', '6.6', '12.0', '6.5', '5.3', '2.8', '6.8', '5.5', '3.7', '4.4', '8.8', '3.0', '2.6', '5.3', '3.6', '0.6', '3.8', '0.1', '0.6', '6.5', '4.4', '4.4', '1.8', '1.5', '4.4', '0.0']
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['81.5', '61.4', '63.0', '57.4', '43.1', '77.8', '63.7', '84.7', '37.8', '80.1', '38.5', '85.4', '88.0', '71.1', '60.5', '55.4', '70.1', '67.7', '83.0', '75.2', '58.0', '28.9', '65.7', '70.1', '65.1', '23.0', '73.4', '79.5', '73.3', '76.5', '22.5', '33.3', '16.3', '13.6', '33.8', '41.1', '26.1', '35.3', '30.4', '36.0', '62.3', '14.6', '39.8', '38.0', '36.7', '31.3', '37.6', '45.1', '35.6', '47.0', '20.6', '17.5', '29.6', '25.0', '23.1', '10.0', '25.7', '36.1', '25.0', '25.5', '57.1', '49.6', '54.3', '60.3', '18.5', '60.2', '29.8', '22.0', '49.7', '43.9', '26.1', '54.8', '5.9', '9.1', '28.1', '35.0', '15.5', '10.3', '12.3', '35.8', 'nan']
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 29.337869595237013
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 8.978424318634412
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 47.89247172584872
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 12.851658787100899
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 3.7275053826896425
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 33.92477004709251
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 25.216316893202983
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 7.665694584648222
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 44.400546306159676
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/08 09:40:15] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/08 09:40:15] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 09:40:15] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 09:40:15] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 09:40:15] d2.evaluation.testing INFO: copypaste: nan,nan
[05/08 09:44:52] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 09:44:53] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:44:53] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:44:53] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4 # 0.2, 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:44:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:44:53] detectron2 INFO: Full config saved to ./output/t4_final/config.yaml
[05/08 09:44:53] d2.utils.env INFO: Using a generated random seed 53653470
[05/08 09:44:54] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:44:54] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:44:54] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:44:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:44:56] d2.data.build INFO: Known classes: range(0, 80)
[05/08 09:44:56] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:44:56] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:44:56] d2.data.build INFO: Number of datapoints: 10246
[05/08 09:44:56] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:44:56] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:44:56] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:44:56] d2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:44:56] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:45:05] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1482 s / img. ETA=0:06:21
[05/08 09:45:10] d2.evaluation.evaluator INFO: Inference done 47/2562. 0.1427 s / img. ETA=0:06:02
[05/08 09:45:15] d2.evaluation.evaluator INFO: Inference done 82/2562. 0.1447 s / img. ETA=0:06:02
[05/08 09:45:20] d2.evaluation.evaluator INFO: Inference done 115/2562. 0.1478 s / img. ETA=0:06:05
[05/08 09:45:26] d2.evaluation.evaluator INFO: Inference done 148/2562. 0.1491 s / img. ETA=0:06:03
[05/08 09:45:31] d2.evaluation.evaluator INFO: Inference done 180/2562. 0.1505 s / img. ETA=0:06:02
[05/08 09:45:36] d2.evaluation.evaluator INFO: Inference done 213/2562. 0.1509 s / img. ETA=0:05:58
[05/08 09:45:41] d2.evaluation.evaluator INFO: Inference done 248/2562. 0.1499 s / img. ETA=0:05:50
[05/08 09:45:46] d2.evaluation.evaluator INFO: Inference done 280/2562. 0.1504 s / img. ETA=0:05:47
[05/08 09:45:51] d2.evaluation.evaluator INFO: Inference done 312/2562. 0.1509 s / img. ETA=0:05:43
[05/08 09:45:56] d2.evaluation.evaluator INFO: Inference done 345/2562. 0.1508 s / img. ETA=0:05:38
[05/08 09:46:01] d2.evaluation.evaluator INFO: Inference done 377/2562. 0.1514 s / img. ETA=0:05:34
[05/08 09:46:06] d2.evaluation.evaluator INFO: Inference done 412/2562. 0.1506 s / img. ETA=0:05:27
[05/08 09:46:11] d2.evaluation.evaluator INFO: Inference done 444/2562. 0.1513 s / img. ETA=0:05:24
[05/08 09:46:16] d2.evaluation.evaluator INFO: Inference done 480/2562. 0.1504 s / img. ETA=0:05:16
[05/08 09:46:21] d2.evaluation.evaluator INFO: Inference done 516/2562. 0.1496 s / img. ETA=0:05:09
[05/08 09:46:26] d2.evaluation.evaluator INFO: Inference done 552/2562. 0.1491 s / img. ETA=0:05:03
[05/08 09:46:32] d2.evaluation.evaluator INFO: Inference done 586/2562. 0.1490 s / img. ETA=0:04:57
[05/08 09:46:37] d2.evaluation.evaluator INFO: Inference done 619/2562. 0.1492 s / img. ETA=0:04:53
[05/08 09:46:42] d2.evaluation.evaluator INFO: Inference done 653/2562. 0.1492 s / img. ETA=0:04:48
[05/08 09:46:47] d2.evaluation.evaluator INFO: Inference done 686/2562. 0.1493 s / img. ETA=0:04:43
[05/08 09:46:52] d2.evaluation.evaluator INFO: Inference done 716/2562. 0.1501 s / img. ETA=0:04:40
[05/08 09:46:57] d2.evaluation.evaluator INFO: Inference done 746/2562. 0.1507 s / img. ETA=0:04:36
[05/08 09:47:02] d2.evaluation.evaluator INFO: Inference done 778/2562. 0.1511 s / img. ETA=0:04:32
[05/08 09:47:07] d2.evaluation.evaluator INFO: Inference done 812/2562. 0.1509 s / img. ETA=0:04:27
[05/08 09:47:12] d2.evaluation.evaluator INFO: Inference done 843/2562. 0.1514 s / img. ETA=0:04:23
[05/08 09:47:17] d2.evaluation.evaluator INFO: Inference done 875/2562. 0.1516 s / img. ETA=0:04:18
[05/08 09:47:22] d2.evaluation.evaluator INFO: Inference done 908/2562. 0.1516 s / img. ETA=0:04:13
[05/08 09:47:27] d2.evaluation.evaluator INFO: Inference done 938/2562. 0.1520 s / img. ETA=0:04:09
[05/08 09:47:32] d2.evaluation.evaluator INFO: Inference done 970/2562. 0.1521 s / img. ETA=0:04:04
[05/08 09:47:38] d2.evaluation.evaluator INFO: Inference done 1004/2562. 0.1520 s / img. ETA=0:03:59
[05/08 09:47:43] d2.evaluation.evaluator INFO: Inference done 1038/2562. 0.1519 s / img. ETA=0:03:54
[05/08 09:47:48] d2.evaluation.evaluator INFO: Inference done 1070/2562. 0.1521 s / img. ETA=0:03:49
[05/08 09:47:53] d2.evaluation.evaluator INFO: Inference done 1102/2562. 0.1522 s / img. ETA=0:03:44
[05/08 09:47:58] d2.evaluation.evaluator INFO: Inference done 1135/2562. 0.1523 s / img. ETA=0:03:39
[05/08 09:48:03] d2.evaluation.evaluator INFO: Inference done 1171/2562. 0.1519 s / img. ETA=0:03:33
[05/08 09:48:08] d2.evaluation.evaluator INFO: Inference done 1200/2562. 0.1524 s / img. ETA=0:03:29
[05/08 09:48:13] d2.evaluation.evaluator INFO: Inference done 1235/2562. 0.1522 s / img. ETA=0:03:24
[05/08 09:48:18] d2.evaluation.evaluator INFO: Inference done 1266/2562. 0.1524 s / img. ETA=0:03:19
[05/08 09:48:23] d2.evaluation.evaluator INFO: Inference done 1300/2562. 0.1523 s / img. ETA=0:03:14
[05/08 09:48:28] d2.evaluation.evaluator INFO: Inference done 1332/2562. 0.1523 s / img. ETA=0:03:09
[05/08 09:48:34] d2.evaluation.evaluator INFO: Inference done 1363/2562. 0.1526 s / img. ETA=0:03:05
[05/08 09:48:39] d2.evaluation.evaluator INFO: Inference done 1391/2562. 0.1532 s / img. ETA=0:03:01
[05/08 09:48:44] d2.evaluation.evaluator INFO: Inference done 1426/2562. 0.1529 s / img. ETA=0:02:55
[05/08 09:48:49] d2.evaluation.evaluator INFO: Inference done 1460/2562. 0.1528 s / img. ETA=0:02:50
[05/08 09:48:54] d2.evaluation.evaluator INFO: Inference done 1494/2562. 0.1527 s / img. ETA=0:02:44
[05/08 09:48:59] d2.evaluation.evaluator INFO: Inference done 1527/2562. 0.1527 s / img. ETA=0:02:39
[05/08 09:49:04] d2.evaluation.evaluator INFO: Inference done 1559/2562. 0.1527 s / img. ETA=0:02:34
[05/08 09:49:09] d2.evaluation.evaluator INFO: Inference done 1594/2562. 0.1525 s / img. ETA=0:02:29
[05/08 09:49:14] d2.evaluation.evaluator INFO: Inference done 1630/2562. 0.1522 s / img. ETA=0:02:23
[05/08 09:49:19] d2.evaluation.evaluator INFO: Inference done 1663/2562. 0.1523 s / img. ETA=0:02:18
[05/08 09:49:24] d2.evaluation.evaluator INFO: Inference done 1697/2562. 0.1522 s / img. ETA=0:02:13
[05/08 09:49:29] d2.evaluation.evaluator INFO: Inference done 1730/2562. 0.1522 s / img. ETA=0:02:08
[05/08 09:49:35] d2.evaluation.evaluator INFO: Inference done 1760/2562. 0.1525 s / img. ETA=0:02:03
[05/08 09:49:40] d2.evaluation.evaluator INFO: Inference done 1791/2562. 0.1527 s / img. ETA=0:01:59
[05/08 09:49:45] d2.evaluation.evaluator INFO: Inference done 1823/2562. 0.1528 s / img. ETA=0:01:54
[05/08 09:49:50] d2.evaluation.evaluator INFO: Inference done 1857/2562. 0.1527 s / img. ETA=0:01:48
[05/08 09:49:55] d2.evaluation.evaluator INFO: Inference done 1889/2562. 0.1528 s / img. ETA=0:01:44
[05/08 09:50:00] d2.evaluation.evaluator INFO: Inference done 1924/2562. 0.1526 s / img. ETA=0:01:38
[05/08 09:50:05] d2.evaluation.evaluator INFO: Inference done 1956/2562. 0.1527 s / img. ETA=0:01:33
[05/08 09:50:10] d2.evaluation.evaluator INFO: Inference done 1990/2562. 0.1526 s / img. ETA=0:01:28
[05/08 09:50:15] d2.evaluation.evaluator INFO: Inference done 2025/2562. 0.1524 s / img. ETA=0:01:22
[05/08 09:50:20] d2.evaluation.evaluator INFO: Inference done 2058/2562. 0.1524 s / img. ETA=0:01:17
[05/08 09:50:26] d2.evaluation.evaluator INFO: Inference done 2093/2562. 0.1523 s / img. ETA=0:01:12
[05/08 09:50:31] d2.evaluation.evaluator INFO: Inference done 2124/2562. 0.1525 s / img. ETA=0:01:07
[05/08 09:50:36] d2.evaluation.evaluator INFO: Inference done 2154/2562. 0.1527 s / img. ETA=0:01:03
[05/08 09:50:41] d2.evaluation.evaluator INFO: Inference done 2187/2562. 0.1527 s / img. ETA=0:00:57
[05/08 09:50:46] d2.evaluation.evaluator INFO: Inference done 2220/2562. 0.1527 s / img. ETA=0:00:52
[05/08 09:50:51] d2.evaluation.evaluator INFO: Inference done 2257/2562. 0.1524 s / img. ETA=0:00:47
[05/08 09:50:56] d2.evaluation.evaluator INFO: Inference done 2289/2562. 0.1524 s / img. ETA=0:00:42
[05/08 09:51:01] d2.evaluation.evaluator INFO: Inference done 2321/2562. 0.1525 s / img. ETA=0:00:37
[05/08 09:51:06] d2.evaluation.evaluator INFO: Inference done 2351/2562. 0.1527 s / img. ETA=0:00:32
[05/08 09:51:11] d2.evaluation.evaluator INFO: Inference done 2384/2562. 0.1527 s / img. ETA=0:00:27
[05/08 09:51:17] d2.evaluation.evaluator INFO: Inference done 2417/2562. 0.1527 s / img. ETA=0:00:22
[05/08 09:51:22] d2.evaluation.evaluator INFO: Inference done 2451/2562. 0.1526 s / img. ETA=0:00:17
[05/08 09:51:27] d2.evaluation.evaluator INFO: Inference done 2485/2562. 0.1526 s / img. ETA=0:00:11
[05/08 09:51:32] d2.evaluation.evaluator INFO: Inference done 2515/2562. 0.1528 s / img. ETA=0:00:07
[05/08 09:51:37] d2.evaluation.evaluator INFO: Inference done 2547/2562. 0.1529 s / img. ETA=0:00:02
[05/08 09:51:40] d2.evaluation.evaluator INFO: Total inference time: 0:06:35.714010 (0.154757 s / img per device, on 4 devices)
[05/08 09:51:40] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:30 (0.152883 s / img per device, on 4 devices)
[05/08 09:52:18] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 09:52:18] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 1929 predictions.
[05/08 09:52:20] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 2786 predictions.
[05/08 09:52:20] d2.evaluation.pascal_voc_evaluation INFO: bird has 2166 predictions.
[05/08 09:52:20] d2.evaluation.pascal_voc_evaluation INFO: boat has 3795 predictions.
[05/08 09:52:20] d2.evaluation.pascal_voc_evaluation INFO: bottle has 20190 predictions.
[05/08 09:52:21] d2.evaluation.pascal_voc_evaluation INFO: bus has 2687 predictions.
[05/08 09:52:21] d2.evaluation.pascal_voc_evaluation INFO: car has 23346 predictions.
[05/08 09:52:22] d2.evaluation.pascal_voc_evaluation INFO: cat has 1905 predictions.
[05/08 09:52:22] d2.evaluation.pascal_voc_evaluation INFO: chair has 25532 predictions.
[05/08 09:52:23] d2.evaluation.pascal_voc_evaluation INFO: cow has 1964 predictions.
[05/08 09:52:23] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 11246 predictions.
[05/08 09:52:24] d2.evaluation.pascal_voc_evaluation INFO: dog has 2856 predictions.
[05/08 09:52:24] d2.evaluation.pascal_voc_evaluation INFO: horse has 2234 predictions.
[05/08 09:52:24] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 2825 predictions.
[05/08 09:52:25] d2.evaluation.pascal_voc_evaluation INFO: person has 89438 predictions.
[05/08 09:52:28] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 7124 predictions.
[05/08 09:52:28] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1340 predictions.
[05/08 09:52:29] d2.evaluation.pascal_voc_evaluation INFO: sofa has 5507 predictions.
[05/08 09:52:29] d2.evaluation.pascal_voc_evaluation INFO: train has 2764 predictions.
[05/08 09:52:29] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 5261 predictions.
[05/08 09:52:29] d2.evaluation.pascal_voc_evaluation INFO: truck has 10183 predictions.
[05/08 09:52:30] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 3760 predictions.
[05/08 09:52:30] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1837 predictions.
[05/08 09:52:30] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1824 predictions.
[05/08 09:52:31] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1984 predictions.
[05/08 09:52:31] d2.evaluation.pascal_voc_evaluation INFO: bench has 7935 predictions.
[05/08 09:52:31] d2.evaluation.pascal_voc_evaluation INFO: elephant has 2507 predictions.
[05/08 09:52:31] d2.evaluation.pascal_voc_evaluation INFO: bear has 2470 predictions.
[05/08 09:52:32] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1184 predictions.
[05/08 09:52:32] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1200 predictions.
[05/08 09:52:32] d2.evaluation.pascal_voc_evaluation INFO: backpack has 6356 predictions.
[05/08 09:52:32] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 3120 predictions.
[05/08 09:52:33] d2.evaluation.pascal_voc_evaluation INFO: handbag has 8827 predictions.
[05/08 09:52:33] d2.evaluation.pascal_voc_evaluation INFO: tie has 842 predictions.
[05/08 09:52:33] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 4979 predictions.
[05/08 09:52:33] d2.evaluation.pascal_voc_evaluation INFO: microwave has 3392 predictions.
[05/08 09:52:34] d2.evaluation.pascal_voc_evaluation INFO: oven has 4764 predictions.
[05/08 09:52:34] d2.evaluation.pascal_voc_evaluation INFO: toaster has 3953 predictions.
[05/08 09:52:34] d2.evaluation.pascal_voc_evaluation INFO: sink has 7839 predictions.
[05/08 09:52:34] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 6325 predictions.
[05/08 09:52:35] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2700 predictions.
[05/08 09:52:35] d2.evaluation.pascal_voc_evaluation INFO: skis has 1561 predictions.
[05/08 09:52:35] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2348 predictions.
[05/08 09:52:35] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 2204 predictions.
[05/08 09:52:36] d2.evaluation.pascal_voc_evaluation INFO: kite has 2309 predictions.
[05/08 09:52:36] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 2221 predictions.
[05/08 09:52:36] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 2854 predictions.
[05/08 09:52:36] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 3989 predictions.
[05/08 09:52:37] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 3670 predictions.
[05/08 09:52:37] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 2257 predictions.
[05/08 09:52:37] d2.evaluation.pascal_voc_evaluation INFO: banana has 1723 predictions.
[05/08 09:52:37] d2.evaluation.pascal_voc_evaluation INFO: apple has 1361 predictions.
[05/08 09:52:38] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 2938 predictions.
[05/08 09:52:38] d2.evaluation.pascal_voc_evaluation INFO: orange has 1647 predictions.
[05/08 09:52:38] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 2342 predictions.
[05/08 09:52:38] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1647 predictions.
[05/08 09:52:39] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 939 predictions.
[05/08 09:52:39] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1968 predictions.
[05/08 09:52:39] d2.evaluation.pascal_voc_evaluation INFO: donut has 2124 predictions.
[05/08 09:52:39] d2.evaluation.pascal_voc_evaluation INFO: cake has 3379 predictions.
[05/08 09:52:39] d2.evaluation.pascal_voc_evaluation INFO: bed has 5218 predictions.
[05/08 09:52:40] d2.evaluation.pascal_voc_evaluation INFO: toilet has 2171 predictions.
[05/08 09:52:40] d2.evaluation.pascal_voc_evaluation INFO: laptop has 3279 predictions.
[05/08 09:52:40] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1960 predictions.
[05/08 09:52:40] d2.evaluation.pascal_voc_evaluation INFO: remote has 1475 predictions.
[05/08 09:52:41] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1463 predictions.
[05/08 09:52:41] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 3950 predictions.
[05/08 09:52:41] d2.evaluation.pascal_voc_evaluation INFO: book has 16957 predictions.
[05/08 09:52:42] d2.evaluation.pascal_voc_evaluation INFO: clock has 3423 predictions.
[05/08 09:52:42] d2.evaluation.pascal_voc_evaluation INFO: vase has 4871 predictions.
[05/08 09:52:42] d2.evaluation.pascal_voc_evaluation INFO: scissors has 2354 predictions.
[05/08 09:52:42] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 4306 predictions.
[05/08 09:52:43] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1938 predictions.
[05/08 09:52:43] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1598 predictions.
[05/08 09:52:43] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 3053 predictions.
[05/08 09:52:43] d2.evaluation.pascal_voc_evaluation INFO: cup has 14016 predictions.
[05/08 09:52:44] d2.evaluation.pascal_voc_evaluation INFO: fork has 1701 predictions.
[05/08 09:52:44] d2.evaluation.pascal_voc_evaluation INFO: knife has 4561 predictions.
[05/08 09:52:44] d2.evaluation.pascal_voc_evaluation INFO: spoon has 4168 predictions.
[05/08 09:52:45] d2.evaluation.pascal_voc_evaluation INFO: bowl has 11383 predictions.
[05/08 09:52:45] d2.evaluation.pascal_voc_evaluation INFO: unknown has 15331 predictions.
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.0}, 0.2: {50: 0.0}, 0.3: {50: 0.0}, 0.4: {50: 0.0}, 0.5: {50: 0.0}, 0.6: {50: 0.0}, 0.7: {50: 0.0}, 0.8: {50: 0.0}, 0.9: {50: 0.0}}
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 0.0}
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 0
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['69.1', '52.6', '51.4', '34.1', '21.8', '61.0', '48.7', '72.7', '19.8', '67.2', '14.9', '72.4', '79.4', '62.9', '46.6', '24.8', '60.8', '44.7', '69.9', '53.6', '14.1', '10.4', '51.6', '49.2', '46.7', '8.9', '56.3', '56.2', '73.9', '75.3', '2.7', '15.8', '1.5', '5.4', '9.0', '10.1', '5.4', '10.8', '8.4', '13.3', '31.8', '6.2', '9.5', '21.9', '15.5', '10.3', '10.8', '18.3', '15.3', '30.1', '8.4', '4.1', '9.8', '7.8', '8.4', '2.5', '7.8', '15.7', '11.5', '6.3', '19.1', '27.6', '31.9', '28.6', '7.6', '23.7', '11.2', '2.7', '30.1', '12.0', '10.7', '28.1', '0.0', '1.1', '5.3', '8.1', '3.0', '1.0', '1.9', '7.8', 'nan']
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['15.0', '15.9', '21.6', '8.3', '5.0', '12.0', '9.6', '23.9', '5.8', '13.5', '5.3', '20.6', '16.7', '15.4', '13.4', '8.3', '18.8', '7.3', '11.9', '9.4', '3.0', '6.3', '3.9', '3.0', '2.1', '2.1', '8.3', '2.4', '19.4', '16.8', '2.1', '6.5', '1.5', '6.4', '2.6', '1.4', '2.0', '0.2', '1.9', '1.5', '3.2', '4.8', '1.4', '5.5', '8.1', '2.8', '2.5', '2.8', '4.0', '5.8', '9.2', '5.7', '3.9', '8.0', '6.6', '5.7', '6.3', '9.9', '6.3', '5.3', '2.3', '6.4', '5.2', '3.7', '4.7', '7.6', '3.0', '2.7', '5.2', '3.5', '0.6', '3.3', '0.1', '0.7', '5.6', '4.1', '4.2', '1.8', '1.7', '4.0', '0.0']
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['86.0', '67.7', '67.2', '64.6', '46.5', '82.5', '71.0', '88.8', '42.7', '83.7', '42.8', '89.2', '90.2', '79.6', '67.4', '63.3', '77.4', '74.1', '89.9', '77.8', '63.7', '32.6', '66.7', '70.1', '65.1', '26.0', '80.3', '80.8', '85.2', '85.9', '24.1', '39.5', '17.2', '14.7', '36.3', '43.9', '31.9', '35.3', '34.8', '43.9', '62.3', '23.8', '41.0', '38.0', '39.5', '32.3', '39.3', '47.6', '47.6', '49.2', '27.0', '19.8', '34.3', '27.3', '28.7', '13.1', '28.1', '37.6', '25.8', '27.6', '62.4', '54.3', '58.4', '60.3', '21.2', '63.1', '31.2', '30.1', '50.3', '45.0', '28.3', '58.1', '5.9', '12.5', '30.6', '36.1', '17.4', '11.7', '15.6', '37.6', 'nan']
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 30.092713235637518
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 7.648980416888491
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 52.006459634996375
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 13.079249070476767
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 3.516344030605773
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 36.50428550021822
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 25.83934719434733
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 6.615821320317812
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 48.13091610130183
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: nan
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 0.0
[05/08 09:52:47] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: nan
[05/08 09:52:47] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 09:52:47] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 09:52:47] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 09:52:47] d2.evaluation.testing INFO: copypaste: nan,nan
