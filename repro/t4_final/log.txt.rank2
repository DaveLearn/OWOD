[05/07 16:05:54] detectron2 INFO: Rank of current process: 2. World size: 4
[05/07 16:05:55] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 16:05:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 16:05:55] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 16:05:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 16:05:55] detectron2.utils.env INFO: Using a generated random seed 55603917
[05/07 16:05:56] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 16:05:56] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 16:05:56] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 16:05:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 16:05:57] detectron2.data.build INFO: Known classes: range(0, 80)
[05/07 16:05:57] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 16:05:58] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 16:05:58] detectron2.data.build INFO: Number of datapoints: 10246
[05/07 16:05:58] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 16:05:58] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 16:05:58] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 16:05:58] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 16:05:58] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/07 16:06:08] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1889 s / img. ETA=0:08:05
[05/07 16:06:13] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1915 s / img. ETA=0:08:07
[05/07 16:06:18] detectron2.evaluation.evaluator INFO: Inference done 66/2562. 0.1822 s / img. ETA=0:07:39
[05/07 16:06:23] detectron2.evaluation.evaluator INFO: Inference done 98/2562. 0.1732 s / img. ETA=0:07:11
[05/07 16:06:28] detectron2.evaluation.evaluator INFO: Inference done 132/2562. 0.1659 s / img. ETA=0:06:47
[05/07 16:06:33] detectron2.evaluation.evaluator INFO: Inference done 163/2562. 0.1649 s / img. ETA=0:06:39
[05/07 16:06:38] detectron2.evaluation.evaluator INFO: Inference done 190/2562. 0.1677 s / img. ETA=0:06:41
[05/07 16:06:43] detectron2.evaluation.evaluator INFO: Inference done 215/2562. 0.1720 s / img. ETA=0:06:47
[05/07 16:06:48] detectron2.evaluation.evaluator INFO: Inference done 240/2562. 0.1749 s / img. ETA=0:06:50
[05/07 16:06:53] detectron2.evaluation.evaluator INFO: Inference done 265/2562. 0.1776 s / img. ETA=0:06:52
[05/07 16:06:58] detectron2.evaluation.evaluator INFO: Inference done 292/2562. 0.1782 s / img. ETA=0:06:48
[05/07 16:07:03] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1801 s / img. ETA=0:06:48
[05/07 16:07:08] detectron2.evaluation.evaluator INFO: Inference done 344/2562. 0.1808 s / img. ETA=0:06:45
[05/07 16:07:13] detectron2.evaluation.evaluator INFO: Inference done 372/2562. 0.1809 s / img. ETA=0:06:40
[05/07 16:07:19] detectron2.evaluation.evaluator INFO: Inference done 400/2562. 0.1810 s / img. ETA=0:06:35
[05/07 16:07:24] detectron2.evaluation.evaluator INFO: Inference done 428/2562. 0.1811 s / img. ETA=0:06:30
[05/07 16:07:29] detectron2.evaluation.evaluator INFO: Inference done 460/2562. 0.1795 s / img. ETA=0:06:21
[05/07 16:07:34] detectron2.evaluation.evaluator INFO: Inference done 491/2562. 0.1784 s / img. ETA=0:06:13
[05/07 16:07:39] detectron2.evaluation.evaluator INFO: Inference done 521/2562. 0.1779 s / img. ETA=0:06:06
[05/07 16:07:44] detectron2.evaluation.evaluator INFO: Inference done 545/2562. 0.1793 s / img. ETA=0:06:05
[05/07 16:07:49] detectron2.evaluation.evaluator INFO: Inference done 572/2562. 0.1798 s / img. ETA=0:06:01
[05/07 16:07:54] detectron2.evaluation.evaluator INFO: Inference done 596/2562. 0.1811 s / img. ETA=0:05:59
[05/07 16:07:59] detectron2.evaluation.evaluator INFO: Inference done 623/2562. 0.1812 s / img. ETA=0:05:54
[05/07 16:08:05] detectron2.evaluation.evaluator INFO: Inference done 654/2562. 0.1804 s / img. ETA=0:05:47
[05/07 16:08:10] detectron2.evaluation.evaluator INFO: Inference done 682/2562. 0.1805 s / img. ETA=0:05:42
[05/07 16:08:15] detectron2.evaluation.evaluator INFO: Inference done 707/2562. 0.1814 s / img. ETA=0:05:39
[05/07 16:08:20] detectron2.evaluation.evaluator INFO: Inference done 730/2562. 0.1826 s / img. ETA=0:05:37
[05/07 16:08:25] detectron2.evaluation.evaluator INFO: Inference done 755/2562. 0.1832 s / img. ETA=0:05:34
[05/07 16:08:30] detectron2.evaluation.evaluator INFO: Inference done 786/2562. 0.1824 s / img. ETA=0:05:27
[05/07 16:08:35] detectron2.evaluation.evaluator INFO: Inference done 815/2562. 0.1820 s / img. ETA=0:05:21
[05/07 16:08:40] detectron2.evaluation.evaluator INFO: Inference done 843/2562. 0.1819 s / img. ETA=0:05:15
[05/07 16:08:45] detectron2.evaluation.evaluator INFO: Inference done 875/2562. 0.1809 s / img. ETA=0:05:08
[05/07 16:08:50] detectron2.evaluation.evaluator INFO: Inference done 903/2562. 0.1809 s / img. ETA=0:05:03
[05/07 16:08:56] detectron2.evaluation.evaluator INFO: Inference done 933/2562. 0.1805 s / img. ETA=0:04:57
[05/07 16:09:01] detectron2.evaluation.evaluator INFO: Inference done 963/2562. 0.1802 s / img. ETA=0:04:51
[05/07 16:09:06] detectron2.evaluation.evaluator INFO: Inference done 996/2562. 0.1792 s / img. ETA=0:04:43
[05/07 16:09:11] detectron2.evaluation.evaluator INFO: Inference done 1036/2562. 0.1772 s / img. ETA=0:04:33
[05/07 16:09:16] detectron2.evaluation.evaluator INFO: Inference done 1064/2562. 0.1772 s / img. ETA=0:04:28
[05/07 16:09:21] detectron2.evaluation.evaluator INFO: Inference done 1093/2562. 0.1770 s / img. ETA=0:04:22
[05/07 16:09:26] detectron2.evaluation.evaluator INFO: Inference done 1129/2562. 0.1758 s / img. ETA=0:04:14
[05/07 16:09:31] detectron2.evaluation.evaluator INFO: Inference done 1165/2562. 0.1746 s / img. ETA=0:04:06
[05/07 16:09:36] detectron2.evaluation.evaluator INFO: Inference done 1206/2562. 0.1730 s / img. ETA=0:03:56
[05/07 16:09:41] detectron2.evaluation.evaluator INFO: Inference done 1239/2562. 0.1724 s / img. ETA=0:03:50
[05/07 16:09:46] detectron2.evaluation.evaluator INFO: Inference done 1265/2562. 0.1728 s / img. ETA=0:03:46
[05/07 16:09:51] detectron2.evaluation.evaluator INFO: Inference done 1291/2562. 0.1732 s / img. ETA=0:03:42
[05/07 16:09:57] detectron2.evaluation.evaluator INFO: Inference done 1324/2562. 0.1727 s / img. ETA=0:03:36
[05/07 16:10:02] detectron2.evaluation.evaluator INFO: Inference done 1360/2562. 0.1718 s / img. ETA=0:03:28
[05/07 16:10:07] detectron2.evaluation.evaluator INFO: Inference done 1392/2562. 0.1715 s / img. ETA=0:03:22
[05/07 16:10:12] detectron2.evaluation.evaluator INFO: Inference done 1419/2562. 0.1718 s / img. ETA=0:03:18
[05/07 16:10:17] detectron2.evaluation.evaluator INFO: Inference done 1446/2562. 0.1720 s / img. ETA=0:03:13
[05/07 16:10:22] detectron2.evaluation.evaluator INFO: Inference done 1475/2562. 0.1720 s / img. ETA=0:03:08
[05/07 16:10:27] detectron2.evaluation.evaluator INFO: Inference done 1503/2562. 0.1721 s / img. ETA=0:03:04
[05/07 16:10:32] detectron2.evaluation.evaluator INFO: Inference done 1531/2562. 0.1722 s / img. ETA=0:02:59
[05/07 16:10:37] detectron2.evaluation.evaluator INFO: Inference done 1558/2562. 0.1724 s / img. ETA=0:02:54
[05/07 16:10:42] detectron2.evaluation.evaluator INFO: Inference done 1582/2562. 0.1730 s / img. ETA=0:02:51
[05/07 16:10:47] detectron2.evaluation.evaluator INFO: Inference done 1609/2562. 0.1732 s / img. ETA=0:02:46
[05/07 16:10:52] detectron2.evaluation.evaluator INFO: Inference done 1640/2562. 0.1731 s / img. ETA=0:02:41
[05/07 16:10:57] detectron2.evaluation.evaluator INFO: Inference done 1671/2562. 0.1729 s / img. ETA=0:02:35
[05/07 16:11:02] detectron2.evaluation.evaluator INFO: Inference done 1700/2562. 0.1728 s / img. ETA=0:02:30
[05/07 16:11:07] detectron2.evaluation.evaluator INFO: Inference done 1729/2562. 0.1728 s / img. ETA=0:02:25
[05/07 16:11:13] detectron2.evaluation.evaluator INFO: Inference done 1758/2562. 0.1729 s / img. ETA=0:02:20
[05/07 16:11:18] detectron2.evaluation.evaluator INFO: Inference done 1785/2562. 0.1732 s / img. ETA=0:02:15
[05/07 16:11:23] detectron2.evaluation.evaluator INFO: Inference done 1820/2562. 0.1726 s / img. ETA=0:02:09
[05/07 16:11:28] detectron2.evaluation.evaluator INFO: Inference done 1860/2562. 0.1715 s / img. ETA=0:02:01
[05/07 16:11:33] detectron2.evaluation.evaluator INFO: Inference done 1888/2562. 0.1716 s / img. ETA=0:01:56
[05/07 16:11:38] detectron2.evaluation.evaluator INFO: Inference done 1917/2562. 0.1716 s / img. ETA=0:01:51
[05/07 16:11:43] detectron2.evaluation.evaluator INFO: Inference done 1949/2562. 0.1713 s / img. ETA=0:01:46
[05/07 16:11:48] detectron2.evaluation.evaluator INFO: Inference done 1979/2562. 0.1713 s / img. ETA=0:01:40
[05/07 16:11:53] detectron2.evaluation.evaluator INFO: Inference done 2008/2562. 0.1713 s / img. ETA=0:01:35
[05/07 16:11:58] detectron2.evaluation.evaluator INFO: Inference done 2036/2562. 0.1714 s / img. ETA=0:01:31
[05/07 16:12:03] detectron2.evaluation.evaluator INFO: Inference done 2064/2562. 0.1715 s / img. ETA=0:01:26
[05/07 16:12:08] detectron2.evaluation.evaluator INFO: Inference done 2094/2562. 0.1714 s / img. ETA=0:01:21
[05/07 16:12:13] detectron2.evaluation.evaluator INFO: Inference done 2122/2562. 0.1715 s / img. ETA=0:01:16
[05/07 16:12:19] detectron2.evaluation.evaluator INFO: Inference done 2150/2562. 0.1717 s / img. ETA=0:01:11
[05/07 16:12:24] detectron2.evaluation.evaluator INFO: Inference done 2187/2562. 0.1711 s / img. ETA=0:01:04
[05/07 16:12:29] detectron2.evaluation.evaluator INFO: Inference done 2232/2562. 0.1698 s / img. ETA=0:00:56
[05/07 16:12:34] detectron2.evaluation.evaluator INFO: Inference done 2272/2562. 0.1690 s / img. ETA=0:00:49
[05/07 16:12:39] detectron2.evaluation.evaluator INFO: Inference done 2309/2562. 0.1685 s / img. ETA=0:00:43
[05/07 16:12:44] detectron2.evaluation.evaluator INFO: Inference done 2339/2562. 0.1685 s / img. ETA=0:00:37
[05/07 16:12:49] detectron2.evaluation.evaluator INFO: Inference done 2379/2562. 0.1677 s / img. ETA=0:00:31
[05/07 16:12:54] detectron2.evaluation.evaluator INFO: Inference done 2409/2562. 0.1677 s / img. ETA=0:00:25
[05/07 16:12:59] detectron2.evaluation.evaluator INFO: Inference done 2443/2562. 0.1675 s / img. ETA=0:00:20
[05/07 16:13:04] detectron2.evaluation.evaluator INFO: Inference done 2472/2562. 0.1675 s / img. ETA=0:00:15
[05/07 16:13:09] detectron2.evaluation.evaluator INFO: Inference done 2500/2562. 0.1677 s / img. ETA=0:00:10
[05/07 16:13:14] detectron2.evaluation.evaluator INFO: Inference done 2530/2562. 0.1677 s / img. ETA=0:00:05
[05/07 16:13:19] detectron2.evaluation.evaluator INFO: Inference done 2560/2562. 0.1677 s / img. ETA=0:00:00
[05/07 16:13:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:13.695746 (0.169611 s / img per device, on 4 devices)
[05/07 16:13:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:08 (0.167689 s / img per device, on 4 devices)
[05/07 17:04:24] detectron2 INFO: Rank of current process: 2. World size: 4
[05/07 17:04:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 17:04:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 17:04:25] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 17:04:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 17:04:25] detectron2.utils.env INFO: Using a generated random seed 25174903
[05/07 17:04:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 17:04:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 17:04:25] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 17:04:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 17:04:27] detectron2.data.build INFO: Known classes: range(0, 80)
[05/07 17:04:27] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 17:04:27] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 17:04:27] detectron2.data.build INFO: Number of datapoints: 10246
[05/07 17:04:27] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 17:04:28] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 17:04:28] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 17:04:28] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 17:04:28] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/07 17:04:37] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1896 s / img. ETA=0:08:07
[05/07 17:04:42] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1922 s / img. ETA=0:08:10
[05/07 17:04:47] detectron2.evaluation.evaluator INFO: Inference done 66/2562. 0.1826 s / img. ETA=0:07:40
[05/07 17:04:52] detectron2.evaluation.evaluator INFO: Inference done 98/2562. 0.1735 s / img. ETA=0:07:12
[05/07 17:04:57] detectron2.evaluation.evaluator INFO: Inference done 132/2562. 0.1661 s / img. ETA=0:06:48
[05/07 17:05:02] detectron2.evaluation.evaluator INFO: Inference done 163/2562. 0.1652 s / img. ETA=0:06:40
[05/07 17:05:07] detectron2.evaluation.evaluator INFO: Inference done 190/2562. 0.1680 s / img. ETA=0:06:42
[05/07 17:05:13] detectron2.evaluation.evaluator INFO: Inference done 215/2562. 0.1723 s / img. ETA=0:06:48
[05/07 17:05:18] detectron2.evaluation.evaluator INFO: Inference done 240/2562. 0.1752 s / img. ETA=0:06:51
[05/07 17:05:23] detectron2.evaluation.evaluator INFO: Inference done 265/2562. 0.1779 s / img. ETA=0:06:52
[05/07 17:05:28] detectron2.evaluation.evaluator INFO: Inference done 292/2562. 0.1785 s / img. ETA=0:06:49
[05/07 17:05:33] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1805 s / img. ETA=0:06:49
[05/07 17:05:38] detectron2.evaluation.evaluator INFO: Inference done 344/2562. 0.1812 s / img. ETA=0:06:45
[05/07 17:05:43] detectron2.evaluation.evaluator INFO: Inference done 372/2562. 0.1812 s / img. ETA=0:06:40
[05/07 17:05:48] detectron2.evaluation.evaluator INFO: Inference done 400/2562. 0.1813 s / img. ETA=0:06:35
[05/07 17:05:53] detectron2.evaluation.evaluator INFO: Inference done 428/2562. 0.1814 s / img. ETA=0:06:30
[05/07 17:05:59] detectron2.evaluation.evaluator INFO: Inference done 460/2562. 0.1797 s / img. ETA=0:06:21
[05/07 17:06:04] detectron2.evaluation.evaluator INFO: Inference done 491/2562. 0.1786 s / img. ETA=0:06:13
[05/07 17:06:09] detectron2.evaluation.evaluator INFO: Inference done 521/2562. 0.1781 s / img. ETA=0:06:07
[05/07 17:06:14] detectron2.evaluation.evaluator INFO: Inference done 545/2562. 0.1795 s / img. ETA=0:06:05
[05/07 17:06:19] detectron2.evaluation.evaluator INFO: Inference done 572/2562. 0.1799 s / img. ETA=0:06:01
[05/07 17:06:24] detectron2.evaluation.evaluator INFO: Inference done 596/2562. 0.1813 s / img. ETA=0:05:59
[05/07 17:06:29] detectron2.evaluation.evaluator INFO: Inference done 623/2562. 0.1814 s / img. ETA=0:05:55
[05/07 17:06:34] detectron2.evaluation.evaluator INFO: Inference done 654/2562. 0.1805 s / img. ETA=0:05:47
[05/07 17:06:39] detectron2.evaluation.evaluator INFO: Inference done 682/2562. 0.1806 s / img. ETA=0:05:42
[05/07 17:06:45] detectron2.evaluation.evaluator INFO: Inference done 707/2562. 0.1814 s / img. ETA=0:05:39
[05/07 17:06:50] detectron2.evaluation.evaluator INFO: Inference done 730/2562. 0.1825 s / img. ETA=0:05:37
[05/07 17:06:55] detectron2.evaluation.evaluator INFO: Inference done 755/2562. 0.1831 s / img. ETA=0:05:34
[05/07 17:07:00] detectron2.evaluation.evaluator INFO: Inference done 786/2562. 0.1822 s / img. ETA=0:05:26
[05/07 17:07:05] detectron2.evaluation.evaluator INFO: Inference done 815/2562. 0.1818 s / img. ETA=0:05:20
[05/07 17:07:10] detectron2.evaluation.evaluator INFO: Inference done 844/2562. 0.1816 s / img. ETA=0:05:15
[05/07 17:07:15] detectron2.evaluation.evaluator INFO: Inference done 876/2562. 0.1806 s / img. ETA=0:05:07
[05/07 17:07:20] detectron2.evaluation.evaluator INFO: Inference done 904/2562. 0.1806 s / img. ETA=0:05:02
[05/07 17:07:25] detectron2.evaluation.evaluator INFO: Inference done 934/2562. 0.1801 s / img. ETA=0:04:56
[05/07 17:07:30] detectron2.evaluation.evaluator INFO: Inference done 963/2562. 0.1800 s / img. ETA=0:04:50
[05/07 17:07:35] detectron2.evaluation.evaluator INFO: Inference done 996/2562. 0.1790 s / img. ETA=0:04:43
[05/07 17:07:40] detectron2.evaluation.evaluator INFO: Inference done 1036/2562. 0.1769 s / img. ETA=0:04:32
[05/07 17:07:45] detectron2.evaluation.evaluator INFO: Inference done 1065/2562. 0.1768 s / img. ETA=0:04:27
[05/07 17:07:50] detectron2.evaluation.evaluator INFO: Inference done 1095/2562. 0.1765 s / img. ETA=0:04:21
[05/07 17:07:55] detectron2.evaluation.evaluator INFO: Inference done 1130/2562. 0.1754 s / img. ETA=0:04:13
[05/07 17:08:00] detectron2.evaluation.evaluator INFO: Inference done 1166/2562. 0.1743 s / img. ETA=0:04:05
[05/07 17:08:05] detectron2.evaluation.evaluator INFO: Inference done 1206/2562. 0.1726 s / img. ETA=0:03:56
[05/07 17:08:11] detectron2.evaluation.evaluator INFO: Inference done 1240/2562. 0.1720 s / img. ETA=0:03:49
[05/07 17:08:16] detectron2.evaluation.evaluator INFO: Inference done 1266/2562. 0.1724 s / img. ETA=0:03:45
[05/07 17:08:21] detectron2.evaluation.evaluator INFO: Inference done 1291/2562. 0.1730 s / img. ETA=0:03:42
[05/07 17:08:26] detectron2.evaluation.evaluator INFO: Inference done 1324/2562. 0.1725 s / img. ETA=0:03:35
[05/07 17:08:31] detectron2.evaluation.evaluator INFO: Inference done 1360/2562. 0.1716 s / img. ETA=0:03:28
[05/07 17:08:36] detectron2.evaluation.evaluator INFO: Inference done 1392/2562. 0.1713 s / img. ETA=0:03:22
[05/07 17:08:41] detectron2.evaluation.evaluator INFO: Inference done 1419/2562. 0.1716 s / img. ETA=0:03:18
[05/07 17:08:46] detectron2.evaluation.evaluator INFO: Inference done 1446/2562. 0.1719 s / img. ETA=0:03:13
[05/07 17:08:51] detectron2.evaluation.evaluator INFO: Inference done 1476/2562. 0.1719 s / img. ETA=0:03:08
[05/07 17:08:56] detectron2.evaluation.evaluator INFO: Inference done 1504/2562. 0.1720 s / img. ETA=0:03:03
[05/07 17:09:01] detectron2.evaluation.evaluator INFO: Inference done 1532/2562. 0.1721 s / img. ETA=0:02:59
[05/07 17:09:07] detectron2.evaluation.evaluator INFO: Inference done 1560/2562. 0.1722 s / img. ETA=0:02:54
[05/07 17:09:12] detectron2.evaluation.evaluator INFO: Inference done 1585/2562. 0.1727 s / img. ETA=0:02:50
[05/07 17:09:17] detectron2.evaluation.evaluator INFO: Inference done 1612/2562. 0.1729 s / img. ETA=0:02:46
[05/07 17:09:22] detectron2.evaluation.evaluator INFO: Inference done 1642/2562. 0.1728 s / img. ETA=0:02:40
[05/07 17:09:27] detectron2.evaluation.evaluator INFO: Inference done 1673/2562. 0.1726 s / img. ETA=0:02:35
[05/07 17:09:32] detectron2.evaluation.evaluator INFO: Inference done 1702/2562. 0.1727 s / img. ETA=0:02:30
[05/07 17:09:37] detectron2.evaluation.evaluator INFO: Inference done 1732/2562. 0.1726 s / img. ETA=0:02:24
[05/07 17:09:42] detectron2.evaluation.evaluator INFO: Inference done 1760/2562. 0.1727 s / img. ETA=0:02:19
[05/07 17:09:47] detectron2.evaluation.evaluator INFO: Inference done 1787/2562. 0.1729 s / img. ETA=0:02:15
[05/07 17:09:53] detectron2.evaluation.evaluator INFO: Inference done 1823/2562. 0.1723 s / img. ETA=0:02:08
[05/07 17:09:58] detectron2.evaluation.evaluator INFO: Inference done 1863/2562. 0.1713 s / img. ETA=0:02:01
[05/07 17:10:03] detectron2.evaluation.evaluator INFO: Inference done 1890/2562. 0.1715 s / img. ETA=0:01:56
[05/07 17:10:08] detectron2.evaluation.evaluator INFO: Inference done 1920/2562. 0.1714 s / img. ETA=0:01:51
[05/07 17:10:13] detectron2.evaluation.evaluator INFO: Inference done 1952/2562. 0.1712 s / img. ETA=0:01:45
[05/07 17:10:18] detectron2.evaluation.evaluator INFO: Inference done 1983/2562. 0.1711 s / img. ETA=0:01:40
[05/07 17:10:23] detectron2.evaluation.evaluator INFO: Inference done 2012/2562. 0.1711 s / img. ETA=0:01:35
[05/07 17:10:28] detectron2.evaluation.evaluator INFO: Inference done 2039/2562. 0.1714 s / img. ETA=0:01:30
[05/07 17:10:33] detectron2.evaluation.evaluator INFO: Inference done 2068/2562. 0.1714 s / img. ETA=0:01:25
[05/07 17:10:38] detectron2.evaluation.evaluator INFO: Inference done 2098/2562. 0.1714 s / img. ETA=0:01:20
[05/07 17:10:44] detectron2.evaluation.evaluator INFO: Inference done 2128/2562. 0.1713 s / img. ETA=0:01:15
[05/07 17:10:49] detectron2.evaluation.evaluator INFO: Inference done 2154/2562. 0.1716 s / img. ETA=0:01:10
[05/07 17:10:54] detectron2.evaluation.evaluator INFO: Inference done 2194/2562. 0.1707 s / img. ETA=0:01:03
[05/07 17:10:59] detectron2.evaluation.evaluator INFO: Inference done 2240/2562. 0.1695 s / img. ETA=0:00:55
[05/07 17:11:04] detectron2.evaluation.evaluator INFO: Inference done 2281/2562. 0.1686 s / img. ETA=0:00:47
[05/07 17:11:09] detectron2.evaluation.evaluator INFO: Inference done 2316/2562. 0.1682 s / img. ETA=0:00:41
[05/07 17:11:14] detectron2.evaluation.evaluator INFO: Inference done 2344/2562. 0.1683 s / img. ETA=0:00:37
[05/07 17:11:19] detectron2.evaluation.evaluator INFO: Inference done 2387/2562. 0.1674 s / img. ETA=0:00:29
[05/07 17:11:24] detectron2.evaluation.evaluator INFO: Inference done 2416/2562. 0.1674 s / img. ETA=0:00:24
[05/07 17:11:29] detectron2.evaluation.evaluator INFO: Inference done 2448/2562. 0.1673 s / img. ETA=0:00:19
[05/07 17:11:34] detectron2.evaluation.evaluator INFO: Inference done 2478/2562. 0.1674 s / img. ETA=0:00:14
[05/07 17:11:40] detectron2.evaluation.evaluator INFO: Inference done 2507/2562. 0.1675 s / img. ETA=0:00:09
[05/07 17:11:45] detectron2.evaluation.evaluator INFO: Inference done 2537/2562. 0.1675 s / img. ETA=0:00:04
[05/07 17:11:49] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:13.040112 (0.169355 s / img per device, on 4 devices)
[05/07 17:11:49] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:08 (0.167425 s / img per device, on 4 devices)
[05/08 08:50:10] detectron2 INFO: Rank of current process: 2. World size: 4
[05/08 08:50:11] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 08:50:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 08:50:11] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 10
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 08:50:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 10
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 08:50:11] detectron2.utils.env INFO: Using a generated random seed 11454480
[05/08 08:50:12] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 08:50:12] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 08:50:12] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 08:50:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 08:50:14] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 08:50:14] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 08:50:14] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 08:50:14] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 08:50:14] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 08:50:14] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 08:50:14] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 08:50:14] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 08:50:14] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 08:50:23] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1880 s / img. ETA=0:08:02
[05/08 08:50:28] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1908 s / img. ETA=0:08:05
[05/08 08:50:33] detectron2.evaluation.evaluator INFO: Inference done 66/2562. 0.1815 s / img. ETA=0:07:36
[05/08 08:50:38] detectron2.evaluation.evaluator INFO: Inference done 98/2562. 0.1726 s / img. ETA=0:07:08
[05/08 08:50:43] detectron2.evaluation.evaluator INFO: Inference done 133/2562. 0.1651 s / img. ETA=0:06:44
[05/08 08:50:48] detectron2.evaluation.evaluator INFO: Inference done 164/2562. 0.1647 s / img. ETA=0:06:38
[05/08 08:50:54] detectron2.evaluation.evaluator INFO: Inference done 192/2562. 0.1671 s / img. ETA=0:06:39
[05/08 08:50:59] detectron2.evaluation.evaluator INFO: Inference done 217/2562. 0.1713 s / img. ETA=0:06:44
[05/08 08:51:04] detectron2.evaluation.evaluator INFO: Inference done 242/2562. 0.1746 s / img. ETA=0:06:48
[05/08 08:51:09] detectron2.evaluation.evaluator INFO: Inference done 268/2562. 0.1764 s / img. ETA=0:06:48
[05/08 08:51:14] detectron2.evaluation.evaluator INFO: Inference done 294/2562. 0.1779 s / img. ETA=0:06:46
[05/08 08:51:19] detectron2.evaluation.evaluator INFO: Inference done 319/2562. 0.1796 s / img. ETA=0:06:46
[05/08 08:51:24] detectron2.evaluation.evaluator INFO: Inference done 346/2562. 0.1803 s / img. ETA=0:06:42
[05/08 08:51:29] detectron2.evaluation.evaluator INFO: Inference done 374/2562. 0.1801 s / img. ETA=0:06:37
[05/08 08:51:34] detectron2.evaluation.evaluator INFO: Inference done 402/2562. 0.1804 s / img. ETA=0:06:32
[05/08 08:51:39] detectron2.evaluation.evaluator INFO: Inference done 430/2562. 0.1804 s / img. ETA=0:06:27
[05/08 08:51:44] detectron2.evaluation.evaluator INFO: Inference done 462/2562. 0.1787 s / img. ETA=0:06:18
[05/08 08:51:50] detectron2.evaluation.evaluator INFO: Inference done 493/2562. 0.1778 s / img. ETA=0:06:10
[05/08 08:51:55] detectron2.evaluation.evaluator INFO: Inference done 523/2562. 0.1772 s / img. ETA=0:06:04
[05/08 08:52:00] detectron2.evaluation.evaluator INFO: Inference done 547/2562. 0.1785 s / img. ETA=0:06:02
[05/08 08:52:05] detectron2.evaluation.evaluator INFO: Inference done 573/2562. 0.1791 s / img. ETA=0:05:59
[05/08 08:52:10] detectron2.evaluation.evaluator INFO: Inference done 597/2562. 0.1804 s / img. ETA=0:05:57
[05/08 08:52:15] detectron2.evaluation.evaluator INFO: Inference done 625/2562. 0.1806 s / img. ETA=0:05:52
[05/08 08:52:20] detectron2.evaluation.evaluator INFO: Inference done 657/2562. 0.1794 s / img. ETA=0:05:44
[05/08 08:52:25] detectron2.evaluation.evaluator INFO: Inference done 684/2562. 0.1798 s / img. ETA=0:05:40
[05/08 08:52:30] detectron2.evaluation.evaluator INFO: Inference done 709/2562. 0.1807 s / img. ETA=0:05:37
[05/08 08:52:35] detectron2.evaluation.evaluator INFO: Inference done 733/2562. 0.1817 s / img. ETA=0:05:34
[05/08 08:52:40] detectron2.evaluation.evaluator INFO: Inference done 758/2562. 0.1823 s / img. ETA=0:05:31
[05/08 08:52:45] detectron2.evaluation.evaluator INFO: Inference done 790/2562. 0.1812 s / img. ETA=0:05:23
[05/08 08:52:50] detectron2.evaluation.evaluator INFO: Inference done 819/2562. 0.1808 s / img. ETA=0:05:17
[05/08 08:52:56] detectron2.evaluation.evaluator INFO: Inference done 849/2562. 0.1805 s / img. ETA=0:05:11
[05/08 08:53:01] detectron2.evaluation.evaluator INFO: Inference done 883/2562. 0.1794 s / img. ETA=0:05:03
[05/08 08:53:06] detectron2.evaluation.evaluator INFO: Inference done 909/2562. 0.1800 s / img. ETA=0:04:59
[05/08 08:53:11] detectron2.evaluation.evaluator INFO: Inference done 940/2562. 0.1793 s / img. ETA=0:04:53
[05/08 08:53:16] detectron2.evaluation.evaluator INFO: Inference done 970/2562. 0.1790 s / img. ETA=0:04:47
[05/08 08:53:21] detectron2.evaluation.evaluator INFO: Inference done 1006/2562. 0.1776 s / img. ETA=0:04:38
[05/08 08:53:27] detectron2.evaluation.evaluator INFO: Inference done 1046/2562. 0.1757 s / img. ETA=0:04:28
[05/08 08:53:32] detectron2.evaluation.evaluator INFO: Inference done 1073/2562. 0.1760 s / img. ETA=0:04:24
[05/08 08:53:37] detectron2.evaluation.evaluator INFO: Inference done 1102/2562. 0.1758 s / img. ETA=0:04:18
[05/08 08:53:42] detectron2.evaluation.evaluator INFO: Inference done 1141/2562. 0.1742 s / img. ETA=0:04:09
[05/08 08:53:47] detectron2.evaluation.evaluator INFO: Inference done 1179/2562. 0.1729 s / img. ETA=0:04:01
[05/08 08:53:52] detectron2.evaluation.evaluator INFO: Inference done 1217/2562. 0.1716 s / img. ETA=0:03:52
[05/08 08:53:57] detectron2.evaluation.evaluator INFO: Inference done 1248/2562. 0.1714 s / img. ETA=0:03:47
[05/08 08:54:02] detectron2.evaluation.evaluator INFO: Inference done 1273/2562. 0.1720 s / img. ETA=0:03:43
[05/08 08:54:07] detectron2.evaluation.evaluator INFO: Inference done 1300/2562. 0.1722 s / img. ETA=0:03:39
[05/08 08:54:12] detectron2.evaluation.evaluator INFO: Inference done 1335/2562. 0.1715 s / img. ETA=0:03:32
[05/08 08:54:17] detectron2.evaluation.evaluator INFO: Inference done 1371/2562. 0.1707 s / img. ETA=0:03:25
[05/08 08:54:22] detectron2.evaluation.evaluator INFO: Inference done 1401/2562. 0.1707 s / img. ETA=0:03:19
[05/08 08:54:28] detectron2.evaluation.evaluator INFO: Inference done 1429/2562. 0.1710 s / img. ETA=0:03:15
[05/08 08:54:33] detectron2.evaluation.evaluator INFO: Inference done 1456/2562. 0.1713 s / img. ETA=0:03:11
[05/08 08:54:38] detectron2.evaluation.evaluator INFO: Inference done 1485/2562. 0.1713 s / img. ETA=0:03:06
[05/08 08:54:43] detectron2.evaluation.evaluator INFO: Inference done 1514/2562. 0.1713 s / img. ETA=0:03:01
[05/08 08:54:48] detectron2.evaluation.evaluator INFO: Inference done 1543/2562. 0.1714 s / img. ETA=0:02:56
[05/08 08:54:53] detectron2.evaluation.evaluator INFO: Inference done 1569/2562. 0.1718 s / img. ETA=0:02:52
[05/08 08:54:58] detectron2.evaluation.evaluator INFO: Inference done 1594/2562. 0.1722 s / img. ETA=0:02:48
[05/08 08:55:03] detectron2.evaluation.evaluator INFO: Inference done 1623/2562. 0.1723 s / img. ETA=0:02:43
[05/08 08:55:08] detectron2.evaluation.evaluator INFO: Inference done 1653/2562. 0.1722 s / img. ETA=0:02:37
[05/08 08:55:13] detectron2.evaluation.evaluator INFO: Inference done 1684/2562. 0.1720 s / img. ETA=0:02:32
[05/08 08:55:18] detectron2.evaluation.evaluator INFO: Inference done 1711/2562. 0.1722 s / img. ETA=0:02:27
[05/08 08:55:23] detectron2.evaluation.evaluator INFO: Inference done 1743/2562. 0.1719 s / img. ETA=0:02:22
[05/08 08:55:28] detectron2.evaluation.evaluator INFO: Inference done 1768/2562. 0.1723 s / img. ETA=0:02:18
[05/08 08:55:34] detectron2.evaluation.evaluator INFO: Inference done 1797/2562. 0.1723 s / img. ETA=0:02:12
[05/08 08:55:39] detectron2.evaluation.evaluator INFO: Inference done 1833/2562. 0.1717 s / img. ETA=0:02:06
[05/08 08:55:44] detectron2.evaluation.evaluator INFO: Inference done 1870/2562. 0.1710 s / img. ETA=0:01:59
[05/08 08:55:49] detectron2.evaluation.evaluator INFO: Inference done 1898/2562. 0.1711 s / img. ETA=0:01:54
[05/08 08:55:54] detectron2.evaluation.evaluator INFO: Inference done 1930/2562. 0.1709 s / img. ETA=0:01:48
[05/08 08:55:59] detectron2.evaluation.evaluator INFO: Inference done 1958/2562. 0.1710 s / img. ETA=0:01:44
[05/08 08:56:04] detectron2.evaluation.evaluator INFO: Inference done 1990/2562. 0.1707 s / img. ETA=0:01:38
[05/08 08:56:09] detectron2.evaluation.evaluator INFO: Inference done 2019/2562. 0.1708 s / img. ETA=0:01:33
[05/08 08:56:14] detectron2.evaluation.evaluator INFO: Inference done 2046/2562. 0.1710 s / img. ETA=0:01:29
[05/08 08:56:19] detectron2.evaluation.evaluator INFO: Inference done 2076/2562. 0.1710 s / img. ETA=0:01:23
[05/08 08:56:24] detectron2.evaluation.evaluator INFO: Inference done 2104/2562. 0.1711 s / img. ETA=0:01:19
[05/08 08:56:29] detectron2.evaluation.evaluator INFO: Inference done 2134/2562. 0.1711 s / img. ETA=0:01:13
[05/08 08:56:34] detectron2.evaluation.evaluator INFO: Inference done 2160/2562. 0.1713 s / img. ETA=0:01:09
[05/08 08:56:40] detectron2.evaluation.evaluator INFO: Inference done 2205/2562. 0.1701 s / img. ETA=0:01:01
[05/08 08:56:45] detectron2.evaluation.evaluator INFO: Inference done 2250/2562. 0.1689 s / img. ETA=0:00:53
[05/08 08:56:50] detectron2.evaluation.evaluator INFO: Inference done 2287/2562. 0.1683 s / img. ETA=0:00:46
[05/08 08:56:55] detectron2.evaluation.evaluator INFO: Inference done 2322/2562. 0.1680 s / img. ETA=0:00:40
[05/08 08:57:00] detectron2.evaluation.evaluator INFO: Inference done 2352/2562. 0.1680 s / img. ETA=0:00:35
[05/08 08:57:05] detectron2.evaluation.evaluator INFO: Inference done 2392/2562. 0.1673 s / img. ETA=0:00:28
[05/08 08:57:10] detectron2.evaluation.evaluator INFO: Inference done 2425/2562. 0.1671 s / img. ETA=0:00:23
[05/08 08:57:15] detectron2.evaluation.evaluator INFO: Inference done 2454/2562. 0.1672 s / img. ETA=0:00:18
[05/08 08:57:20] detectron2.evaluation.evaluator INFO: Inference done 2485/2562. 0.1671 s / img. ETA=0:00:12
[05/08 08:57:25] detectron2.evaluation.evaluator INFO: Inference done 2515/2562. 0.1672 s / img. ETA=0:00:07
[05/08 08:57:31] detectron2.evaluation.evaluator INFO: Inference done 2544/2562. 0.1673 s / img. ETA=0:00:03
[05/08 08:57:34] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:11.751180 (0.168851 s / img per device, on 4 devices)
[05/08 08:57:34] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:07 (0.167246 s / img per device, on 4 devices)
[05/08 09:08:03] detectron2 INFO: Rank of current process: 2. World size: 4
[05/08 09:08:04] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:08:04] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:08:04] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 200
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:08:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:08:04] detectron2.utils.env INFO: Using a generated random seed 4686595
[05/08 09:08:05] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:08:05] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:08:05] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:08:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:08:07] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:08:07] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:08:07] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:08:07] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:08:07] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:08:07] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:08:07] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:08:07] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:08:07] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:08:17] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1904 s / img. ETA=0:08:10
[05/08 09:08:22] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1932 s / img. ETA=0:08:14
[05/08 09:08:27] detectron2.evaluation.evaluator INFO: Inference done 66/2562. 0.1833 s / img. ETA=0:07:43
[05/08 09:08:32] detectron2.evaluation.evaluator INFO: Inference done 98/2562. 0.1742 s / img. ETA=0:07:15
[05/08 09:08:37] detectron2.evaluation.evaluator INFO: Inference done 132/2562. 0.1667 s / img. ETA=0:06:50
[05/08 09:08:42] detectron2.evaluation.evaluator INFO: Inference done 163/2562. 0.1658 s / img. ETA=0:06:43
[05/08 09:08:47] detectron2.evaluation.evaluator INFO: Inference done 190/2562. 0.1685 s / img. ETA=0:06:44
[05/08 09:08:52] detectron2.evaluation.evaluator INFO: Inference done 215/2562. 0.1727 s / img. ETA=0:06:50
[05/08 09:08:57] detectron2.evaluation.evaluator INFO: Inference done 240/2562. 0.1755 s / img. ETA=0:06:52
[05/08 09:09:02] detectron2.evaluation.evaluator INFO: Inference done 265/2562. 0.1782 s / img. ETA=0:06:54
[05/08 09:09:07] detectron2.evaluation.evaluator INFO: Inference done 292/2562. 0.1788 s / img. ETA=0:06:51
[05/08 09:09:13] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1807 s / img. ETA=0:06:50
[05/08 09:09:18] detectron2.evaluation.evaluator INFO: Inference done 344/2562. 0.1813 s / img. ETA=0:06:47
[05/08 09:09:23] detectron2.evaluation.evaluator INFO: Inference done 372/2562. 0.1813 s / img. ETA=0:06:41
[05/08 09:09:28] detectron2.evaluation.evaluator INFO: Inference done 400/2562. 0.1813 s / img. ETA=0:06:36
[05/08 09:09:33] detectron2.evaluation.evaluator INFO: Inference done 428/2562. 0.1814 s / img. ETA=0:06:31
[05/08 09:09:38] detectron2.evaluation.evaluator INFO: Inference done 460/2562. 0.1798 s / img. ETA=0:06:22
[05/08 09:09:43] detectron2.evaluation.evaluator INFO: Inference done 491/2562. 0.1787 s / img. ETA=0:06:14
[05/08 09:09:48] detectron2.evaluation.evaluator INFO: Inference done 521/2562. 0.1782 s / img. ETA=0:06:07
[05/08 09:09:54] detectron2.evaluation.evaluator INFO: Inference done 545/2562. 0.1796 s / img. ETA=0:06:06
[05/08 09:09:59] detectron2.evaluation.evaluator INFO: Inference done 572/2562. 0.1800 s / img. ETA=0:06:02
[05/08 09:10:04] detectron2.evaluation.evaluator INFO: Inference done 596/2562. 0.1813 s / img. ETA=0:06:00
[05/08 09:10:09] detectron2.evaluation.evaluator INFO: Inference done 624/2562. 0.1813 s / img. ETA=0:05:55
[05/08 09:10:14] detectron2.evaluation.evaluator INFO: Inference done 655/2562. 0.1804 s / img. ETA=0:05:47
[05/08 09:10:19] detectron2.evaluation.evaluator INFO: Inference done 682/2562. 0.1807 s / img. ETA=0:05:43
[05/08 09:10:24] detectron2.evaluation.evaluator INFO: Inference done 706/2562. 0.1816 s / img. ETA=0:05:40
[05/08 09:10:29] detectron2.evaluation.evaluator INFO: Inference done 729/2562. 0.1827 s / img. ETA=0:05:38
[05/08 09:10:34] detectron2.evaluation.evaluator INFO: Inference done 754/2562. 0.1832 s / img. ETA=0:05:35
[05/08 09:10:39] detectron2.evaluation.evaluator INFO: Inference done 786/2562. 0.1824 s / img. ETA=0:05:27
[05/08 09:10:45] detectron2.evaluation.evaluator INFO: Inference done 815/2562. 0.1820 s / img. ETA=0:05:21
[05/08 09:10:50] detectron2.evaluation.evaluator INFO: Inference done 844/2562. 0.1819 s / img. ETA=0:05:16
[05/08 09:10:55] detectron2.evaluation.evaluator INFO: Inference done 877/2562. 0.1807 s / img. ETA=0:05:07
[05/08 09:11:00] detectron2.evaluation.evaluator INFO: Inference done 904/2562. 0.1809 s / img. ETA=0:05:03
[05/08 09:11:05] detectron2.evaluation.evaluator INFO: Inference done 934/2562. 0.1805 s / img. ETA=0:04:57
[05/08 09:11:10] detectron2.evaluation.evaluator INFO: Inference done 963/2562. 0.1804 s / img. ETA=0:04:51
[05/08 09:11:15] detectron2.evaluation.evaluator INFO: Inference done 997/2562. 0.1793 s / img. ETA=0:04:43
[05/08 09:11:20] detectron2.evaluation.evaluator INFO: Inference done 1037/2562. 0.1772 s / img. ETA=0:04:33
[05/08 09:11:26] detectron2.evaluation.evaluator INFO: Inference done 1066/2562. 0.1772 s / img. ETA=0:04:28
[05/08 09:11:31] detectron2.evaluation.evaluator INFO: Inference done 1097/2562. 0.1769 s / img. ETA=0:04:22
[05/08 09:11:36] detectron2.evaluation.evaluator INFO: Inference done 1133/2562. 0.1756 s / img. ETA=0:04:13
[05/08 09:11:41] detectron2.evaluation.evaluator INFO: Inference done 1171/2562. 0.1742 s / img. ETA=0:04:05
[05/08 09:11:46] detectron2.evaluation.evaluator INFO: Inference done 1209/2562. 0.1728 s / img. ETA=0:03:56
[05/08 09:11:51] detectron2.evaluation.evaluator INFO: Inference done 1243/2562. 0.1722 s / img. ETA=0:03:49
[05/08 09:11:56] detectron2.evaluation.evaluator INFO: Inference done 1268/2562. 0.1728 s / img. ETA=0:03:46
[05/08 09:12:01] detectron2.evaluation.evaluator INFO: Inference done 1294/2562. 0.1732 s / img. ETA=0:03:42
[05/08 09:12:06] detectron2.evaluation.evaluator INFO: Inference done 1328/2562. 0.1726 s / img. ETA=0:03:35
[05/08 09:12:11] detectron2.evaluation.evaluator INFO: Inference done 1363/2562. 0.1718 s / img. ETA=0:03:28
[05/08 09:12:17] detectron2.evaluation.evaluator INFO: Inference done 1394/2562. 0.1716 s / img. ETA=0:03:22
[05/08 09:12:22] detectron2.evaluation.evaluator INFO: Inference done 1421/2562. 0.1718 s / img. ETA=0:03:18
[05/08 09:12:27] detectron2.evaluation.evaluator INFO: Inference done 1448/2562. 0.1721 s / img. ETA=0:03:13
[05/08 09:12:32] detectron2.evaluation.evaluator INFO: Inference done 1477/2562. 0.1721 s / img. ETA=0:03:08
[05/08 09:12:37] detectron2.evaluation.evaluator INFO: Inference done 1505/2562. 0.1722 s / img. ETA=0:03:04
[05/08 09:12:42] detectron2.evaluation.evaluator INFO: Inference done 1534/2562. 0.1722 s / img. ETA=0:02:59
[05/08 09:12:47] detectron2.evaluation.evaluator INFO: Inference done 1561/2562. 0.1725 s / img. ETA=0:02:54
[05/08 09:12:52] detectron2.evaluation.evaluator INFO: Inference done 1586/2562. 0.1730 s / img. ETA=0:02:50
[05/08 09:12:57] detectron2.evaluation.evaluator INFO: Inference done 1614/2562. 0.1732 s / img. ETA=0:02:46
[05/08 09:13:02] detectron2.evaluation.evaluator INFO: Inference done 1644/2562. 0.1731 s / img. ETA=0:02:40
[05/08 09:13:07] detectron2.evaluation.evaluator INFO: Inference done 1674/2562. 0.1729 s / img. ETA=0:02:35
[05/08 09:13:13] detectron2.evaluation.evaluator INFO: Inference done 1703/2562. 0.1730 s / img. ETA=0:02:30
[05/08 09:13:18] detectron2.evaluation.evaluator INFO: Inference done 1734/2562. 0.1728 s / img. ETA=0:02:24
[05/08 09:13:23] detectron2.evaluation.evaluator INFO: Inference done 1762/2562. 0.1730 s / img. ETA=0:02:20
[05/08 09:13:28] detectron2.evaluation.evaluator INFO: Inference done 1788/2562. 0.1733 s / img. ETA=0:02:15
[05/08 09:13:33] detectron2.evaluation.evaluator INFO: Inference done 1824/2562. 0.1726 s / img. ETA=0:02:08
[05/08 09:13:38] detectron2.evaluation.evaluator INFO: Inference done 1864/2562. 0.1716 s / img. ETA=0:02:01
[05/08 09:13:43] detectron2.evaluation.evaluator INFO: Inference done 1890/2562. 0.1718 s / img. ETA=0:01:56
[05/08 09:13:48] detectron2.evaluation.evaluator INFO: Inference done 1921/2562. 0.1716 s / img. ETA=0:01:51
[05/08 09:13:53] detectron2.evaluation.evaluator INFO: Inference done 1952/2562. 0.1715 s / img. ETA=0:01:45
[05/08 09:13:58] detectron2.evaluation.evaluator INFO: Inference done 1983/2562. 0.1713 s / img. ETA=0:01:40
[05/08 09:14:03] detectron2.evaluation.evaluator INFO: Inference done 2012/2562. 0.1713 s / img. ETA=0:01:35
[05/08 09:14:09] detectron2.evaluation.evaluator INFO: Inference done 2039/2562. 0.1715 s / img. ETA=0:01:30
[05/08 09:14:14] detectron2.evaluation.evaluator INFO: Inference done 2068/2562. 0.1716 s / img. ETA=0:01:25
[05/08 09:14:19] detectron2.evaluation.evaluator INFO: Inference done 2098/2562. 0.1716 s / img. ETA=0:01:20
[05/08 09:14:24] detectron2.evaluation.evaluator INFO: Inference done 2128/2562. 0.1715 s / img. ETA=0:01:15
[05/08 09:14:29] detectron2.evaluation.evaluator INFO: Inference done 2155/2562. 0.1718 s / img. ETA=0:01:10
[05/08 09:14:34] detectron2.evaluation.evaluator INFO: Inference done 2196/2562. 0.1708 s / img. ETA=0:01:03
[05/08 09:14:39] detectron2.evaluation.evaluator INFO: Inference done 2241/2562. 0.1696 s / img. ETA=0:00:55
[05/08 09:14:44] detectron2.evaluation.evaluator INFO: Inference done 2282/2562. 0.1687 s / img. ETA=0:00:47
[05/08 09:14:49] detectron2.evaluation.evaluator INFO: Inference done 2317/2562. 0.1683 s / img. ETA=0:00:41
[05/08 09:14:54] detectron2.evaluation.evaluator INFO: Inference done 2345/2562. 0.1684 s / img. ETA=0:00:36
[05/08 09:15:00] detectron2.evaluation.evaluator INFO: Inference done 2388/2562. 0.1675 s / img. ETA=0:00:29
[05/08 09:15:05] detectron2.evaluation.evaluator INFO: Inference done 2418/2562. 0.1675 s / img. ETA=0:00:24
[05/08 09:15:10] detectron2.evaluation.evaluator INFO: Inference done 2449/2562. 0.1675 s / img. ETA=0:00:19
[05/08 09:15:15] detectron2.evaluation.evaluator INFO: Inference done 2479/2562. 0.1675 s / img. ETA=0:00:14
[05/08 09:15:20] detectron2.evaluation.evaluator INFO: Inference done 2509/2562. 0.1675 s / img. ETA=0:00:08
[05/08 09:15:25] detectron2.evaluation.evaluator INFO: Inference done 2539/2562. 0.1676 s / img. ETA=0:00:03
[05/08 09:15:29] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:13.931895 (0.169704 s / img per device, on 4 devices)
[05/08 09:15:29] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:08 (0.167532 s / img per device, on 4 devices)
[05/08 09:23:00] detectron2 INFO: Rank of current process: 2. World size: 4
[05/08 09:23:01] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:23:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:23:01] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:23:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.3
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:23:01] detectron2.utils.env INFO: Using a generated random seed 1791217
[05/08 09:23:02] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:23:02] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:23:02] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:23:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:23:04] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:23:04] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:23:04] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:23:04] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:23:04] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:23:04] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:23:04] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:23:05] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:23:05] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:23:14] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1895 s / img. ETA=0:08:07
[05/08 09:23:19] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1927 s / img. ETA=0:08:11
[05/08 09:23:24] detectron2.evaluation.evaluator INFO: Inference done 66/2562. 0.1830 s / img. ETA=0:07:42
[05/08 09:23:29] detectron2.evaluation.evaluator INFO: Inference done 98/2562. 0.1736 s / img. ETA=0:07:12
[05/08 09:23:34] detectron2.evaluation.evaluator INFO: Inference done 132/2562. 0.1661 s / img. ETA=0:06:48
[05/08 09:23:39] detectron2.evaluation.evaluator INFO: Inference done 163/2562. 0.1651 s / img. ETA=0:06:40
[05/08 09:23:44] detectron2.evaluation.evaluator INFO: Inference done 190/2562. 0.1680 s / img. ETA=0:06:43
[05/08 09:23:49] detectron2.evaluation.evaluator INFO: Inference done 215/2562. 0.1721 s / img. ETA=0:06:48
[05/08 09:23:54] detectron2.evaluation.evaluator INFO: Inference done 240/2562. 0.1750 s / img. ETA=0:06:50
[05/08 09:23:59] detectron2.evaluation.evaluator INFO: Inference done 265/2562. 0.1777 s / img. ETA=0:06:52
[05/08 09:24:04] detectron2.evaluation.evaluator INFO: Inference done 292/2562. 0.1783 s / img. ETA=0:06:49
[05/08 09:24:09] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1803 s / img. ETA=0:06:49
[05/08 09:24:15] detectron2.evaluation.evaluator INFO: Inference done 344/2562. 0.1809 s / img. ETA=0:06:45
[05/08 09:24:20] detectron2.evaluation.evaluator INFO: Inference done 372/2562. 0.1810 s / img. ETA=0:06:40
[05/08 09:24:25] detectron2.evaluation.evaluator INFO: Inference done 400/2562. 0.1811 s / img. ETA=0:06:35
[05/08 09:24:30] detectron2.evaluation.evaluator INFO: Inference done 428/2562. 0.1812 s / img. ETA=0:06:30
[05/08 09:24:35] detectron2.evaluation.evaluator INFO: Inference done 460/2562. 0.1795 s / img. ETA=0:06:21
[05/08 09:24:40] detectron2.evaluation.evaluator INFO: Inference done 491/2562. 0.1784 s / img. ETA=0:06:13
[05/08 09:24:45] detectron2.evaluation.evaluator INFO: Inference done 521/2562. 0.1779 s / img. ETA=0:06:06
[05/08 09:24:50] detectron2.evaluation.evaluator INFO: Inference done 545/2562. 0.1792 s / img. ETA=0:06:05
[05/08 09:24:55] detectron2.evaluation.evaluator INFO: Inference done 572/2562. 0.1796 s / img. ETA=0:06:01
[05/08 09:25:01] detectron2.evaluation.evaluator INFO: Inference done 596/2562. 0.1809 s / img. ETA=0:05:59
[05/08 09:25:06] detectron2.evaluation.evaluator INFO: Inference done 624/2562. 0.1809 s / img. ETA=0:05:54
[05/08 09:25:11] detectron2.evaluation.evaluator INFO: Inference done 655/2562. 0.1799 s / img. ETA=0:05:46
[05/08 09:25:16] detectron2.evaluation.evaluator INFO: Inference done 682/2562. 0.1801 s / img. ETA=0:05:42
[05/08 09:25:21] detectron2.evaluation.evaluator INFO: Inference done 707/2562. 0.1809 s / img. ETA=0:05:39
[05/08 09:25:26] detectron2.evaluation.evaluator INFO: Inference done 730/2562. 0.1820 s / img. ETA=0:05:36
[05/08 09:25:31] detectron2.evaluation.evaluator INFO: Inference done 756/2562. 0.1826 s / img. ETA=0:05:33
[05/08 09:25:36] detectron2.evaluation.evaluator INFO: Inference done 789/2562. 0.1814 s / img. ETA=0:05:24
[05/08 09:25:41] detectron2.evaluation.evaluator INFO: Inference done 818/2562. 0.1810 s / img. ETA=0:05:18
[05/08 09:25:46] detectron2.evaluation.evaluator INFO: Inference done 847/2562. 0.1807 s / img. ETA=0:05:13
[05/08 09:25:51] detectron2.evaluation.evaluator INFO: Inference done 881/2562. 0.1795 s / img. ETA=0:05:04
[05/08 09:25:57] detectron2.evaluation.evaluator INFO: Inference done 907/2562. 0.1800 s / img. ETA=0:05:00
[05/08 09:26:02] detectron2.evaluation.evaluator INFO: Inference done 938/2562. 0.1794 s / img. ETA=0:04:54
[05/08 09:26:07] detectron2.evaluation.evaluator INFO: Inference done 968/2562. 0.1791 s / img. ETA=0:04:48
[05/08 09:26:12] detectron2.evaluation.evaluator INFO: Inference done 1003/2562. 0.1778 s / img. ETA=0:04:40
[05/08 09:26:17] detectron2.evaluation.evaluator INFO: Inference done 1043/2562. 0.1757 s / img. ETA=0:04:29
[05/08 09:26:22] detectron2.evaluation.evaluator INFO: Inference done 1070/2562. 0.1759 s / img. ETA=0:04:25
[05/08 09:26:27] detectron2.evaluation.evaluator INFO: Inference done 1101/2562. 0.1756 s / img. ETA=0:04:19
[05/08 09:26:32] detectron2.evaluation.evaluator INFO: Inference done 1139/2562. 0.1741 s / img. ETA=0:04:10
[05/08 09:26:37] detectron2.evaluation.evaluator INFO: Inference done 1178/2562. 0.1726 s / img. ETA=0:04:01
[05/08 09:26:42] detectron2.evaluation.evaluator INFO: Inference done 1215/2562. 0.1714 s / img. ETA=0:03:53
[05/08 09:26:47] detectron2.evaluation.evaluator INFO: Inference done 1247/2562. 0.1710 s / img. ETA=0:03:47
[05/08 09:26:52] detectron2.evaluation.evaluator INFO: Inference done 1272/2562. 0.1715 s / img. ETA=0:03:43
[05/08 09:26:57] detectron2.evaluation.evaluator INFO: Inference done 1299/2562. 0.1718 s / img. ETA=0:03:39
[05/08 09:27:02] detectron2.evaluation.evaluator INFO: Inference done 1334/2562. 0.1710 s / img. ETA=0:03:32
[05/08 09:27:07] detectron2.evaluation.evaluator INFO: Inference done 1370/2562. 0.1702 s / img. ETA=0:03:25
[05/08 09:27:13] detectron2.evaluation.evaluator INFO: Inference done 1399/2562. 0.1703 s / img. ETA=0:03:20
[05/08 09:27:18] detectron2.evaluation.evaluator INFO: Inference done 1427/2562. 0.1704 s / img. ETA=0:03:15
[05/08 09:27:23] detectron2.evaluation.evaluator INFO: Inference done 1454/2562. 0.1707 s / img. ETA=0:03:11
[05/08 09:27:28] detectron2.evaluation.evaluator INFO: Inference done 1484/2562. 0.1707 s / img. ETA=0:03:05
[05/08 09:27:33] detectron2.evaluation.evaluator INFO: Inference done 1513/2562. 0.1707 s / img. ETA=0:03:00
[05/08 09:27:38] detectron2.evaluation.evaluator INFO: Inference done 1542/2562. 0.1707 s / img. ETA=0:02:56
[05/08 09:27:43] detectron2.evaluation.evaluator INFO: Inference done 1568/2562. 0.1711 s / img. ETA=0:02:51
[05/08 09:27:48] detectron2.evaluation.evaluator INFO: Inference done 1593/2562. 0.1716 s / img. ETA=0:02:48
[05/08 09:27:53] detectron2.evaluation.evaluator INFO: Inference done 1623/2562. 0.1716 s / img. ETA=0:02:42
[05/08 09:27:58] detectron2.evaluation.evaluator INFO: Inference done 1653/2562. 0.1716 s / img. ETA=0:02:37
[05/08 09:28:03] detectron2.evaluation.evaluator INFO: Inference done 1684/2562. 0.1713 s / img. ETA=0:02:32
[05/08 09:28:08] detectron2.evaluation.evaluator INFO: Inference done 1711/2562. 0.1715 s / img. ETA=0:02:27
[05/08 09:28:14] detectron2.evaluation.evaluator INFO: Inference done 1744/2562. 0.1712 s / img. ETA=0:02:21
[05/08 09:28:19] detectron2.evaluation.evaluator INFO: Inference done 1770/2562. 0.1716 s / img. ETA=0:02:17
[05/08 09:28:24] detectron2.evaluation.evaluator INFO: Inference done 1800/2562. 0.1715 s / img. ETA=0:02:12
[05/08 09:28:29] detectron2.evaluation.evaluator INFO: Inference done 1839/2562. 0.1706 s / img. ETA=0:02:04
[05/08 09:28:34] detectron2.evaluation.evaluator INFO: Inference done 1874/2562. 0.1702 s / img. ETA=0:01:58
[05/08 09:28:39] detectron2.evaluation.evaluator INFO: Inference done 1902/2562. 0.1703 s / img. ETA=0:01:53
[05/08 09:28:44] detectron2.evaluation.evaluator INFO: Inference done 1935/2562. 0.1700 s / img. ETA=0:01:47
[05/08 09:28:49] detectron2.evaluation.evaluator INFO: Inference done 1964/2562. 0.1700 s / img. ETA=0:01:42
[05/08 09:28:54] detectron2.evaluation.evaluator INFO: Inference done 1996/2562. 0.1698 s / img. ETA=0:01:37
[05/08 09:28:59] detectron2.evaluation.evaluator INFO: Inference done 2024/2562. 0.1699 s / img. ETA=0:01:32
[05/08 09:29:05] detectron2.evaluation.evaluator INFO: Inference done 2053/2562. 0.1700 s / img. ETA=0:01:27
[05/08 09:29:10] detectron2.evaluation.evaluator INFO: Inference done 2082/2562. 0.1701 s / img. ETA=0:01:22
[05/08 09:29:15] detectron2.evaluation.evaluator INFO: Inference done 2111/2562. 0.1701 s / img. ETA=0:01:17
[05/08 09:29:20] detectron2.evaluation.evaluator INFO: Inference done 2141/2562. 0.1701 s / img. ETA=0:01:12
[05/08 09:29:25] detectron2.evaluation.evaluator INFO: Inference done 2171/2562. 0.1701 s / img. ETA=0:01:07
[05/08 09:29:30] detectron2.evaluation.evaluator INFO: Inference done 2217/2562. 0.1688 s / img. ETA=0:00:58
[05/08 09:29:35] detectron2.evaluation.evaluator INFO: Inference done 2262/2562. 0.1677 s / img. ETA=0:00:50
[05/08 09:29:40] detectron2.evaluation.evaluator INFO: Inference done 2298/2562. 0.1672 s / img. ETA=0:00:44
[05/08 09:29:45] detectron2.evaluation.evaluator INFO: Inference done 2330/2562. 0.1671 s / img. ETA=0:00:39
[05/08 09:29:50] detectron2.evaluation.evaluator INFO: Inference done 2366/2562. 0.1666 s / img. ETA=0:00:33
[05/08 09:29:55] detectron2.evaluation.evaluator INFO: Inference done 2400/2562. 0.1664 s / img. ETA=0:00:27
[05/08 09:30:01] detectron2.evaluation.evaluator INFO: Inference done 2435/2562. 0.1660 s / img. ETA=0:00:21
[05/08 09:30:06] detectron2.evaluation.evaluator INFO: Inference done 2464/2562. 0.1661 s / img. ETA=0:00:16
[05/08 09:30:11] detectron2.evaluation.evaluator INFO: Inference done 2494/2562. 0.1662 s / img. ETA=0:00:11
[05/08 09:30:16] detectron2.evaluation.evaluator INFO: Inference done 2523/2562. 0.1662 s / img. ETA=0:00:06
[05/08 09:30:21] detectron2.evaluation.evaluator INFO: Inference done 2552/2562. 0.1663 s / img. ETA=0:00:01
[05/08 09:30:23] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:10.161127 (0.168229 s / img per device, on 4 devices)
[05/08 09:30:23] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:05 (0.166271 s / img per device, on 4 devices)
[05/08 09:32:23] detectron2 INFO: Rank of current process: 2. World size: 4
[05/08 09:32:24] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:32:24] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:32:24] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.2
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:32:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:32:24] detectron2.utils.env INFO: Using a generated random seed 24414508
[05/08 09:32:24] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:32:24] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:32:25] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:32:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:32:27] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:32:27] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:32:27] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:32:27] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:32:27] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:32:27] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:32:27] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:32:27] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:32:27] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:32:36] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1899 s / img. ETA=0:08:08
[05/08 09:32:42] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1940 s / img. ETA=0:08:15
[05/08 09:32:47] detectron2.evaluation.evaluator INFO: Inference done 65/2562. 0.1862 s / img. ETA=0:07:50
[05/08 09:32:52] detectron2.evaluation.evaluator INFO: Inference done 97/2562. 0.1754 s / img. ETA=0:07:17
[05/08 09:32:57] detectron2.evaluation.evaluator INFO: Inference done 131/2562. 0.1682 s / img. ETA=0:06:53
[05/08 09:33:02] detectron2.evaluation.evaluator INFO: Inference done 162/2562. 0.1670 s / img. ETA=0:06:45
[05/08 09:33:07] detectron2.evaluation.evaluator INFO: Inference done 189/2562. 0.1695 s / img. ETA=0:06:47
[05/08 09:33:12] detectron2.evaluation.evaluator INFO: Inference done 213/2562. 0.1738 s / img. ETA=0:06:52
[05/08 09:33:17] detectron2.evaluation.evaluator INFO: Inference done 238/2562. 0.1766 s / img. ETA=0:06:55
[05/08 09:33:22] detectron2.evaluation.evaluator INFO: Inference done 262/2562. 0.1794 s / img. ETA=0:06:57
[05/08 09:33:27] detectron2.evaluation.evaluator INFO: Inference done 289/2562. 0.1798 s / img. ETA=0:06:53
[05/08 09:33:32] detectron2.evaluation.evaluator INFO: Inference done 313/2562. 0.1822 s / img. ETA=0:06:54
[05/08 09:33:37] detectron2.evaluation.evaluator INFO: Inference done 339/2562. 0.1830 s / img. ETA=0:06:51
[05/08 09:33:42] detectron2.evaluation.evaluator INFO: Inference done 367/2562. 0.1831 s / img. ETA=0:06:46
[05/08 09:33:48] detectron2.evaluation.evaluator INFO: Inference done 396/2562. 0.1826 s / img. ETA=0:06:39
[05/08 09:33:53] detectron2.evaluation.evaluator INFO: Inference done 423/2562. 0.1828 s / img. ETA=0:06:35
[05/08 09:33:58] detectron2.evaluation.evaluator INFO: Inference done 453/2562. 0.1819 s / img. ETA=0:06:27
[05/08 09:34:03] detectron2.evaluation.evaluator INFO: Inference done 485/2562. 0.1802 s / img. ETA=0:06:18
[05/08 09:34:08] detectron2.evaluation.evaluator INFO: Inference done 515/2562. 0.1795 s / img. ETA=0:06:11
[05/08 09:34:13] detectron2.evaluation.evaluator INFO: Inference done 540/2562. 0.1804 s / img. ETA=0:06:08
[05/08 09:34:18] detectron2.evaluation.evaluator INFO: Inference done 566/2562. 0.1811 s / img. ETA=0:06:05
[05/08 09:34:23] detectron2.evaluation.evaluator INFO: Inference done 589/2562. 0.1825 s / img. ETA=0:06:03
[05/08 09:34:28] detectron2.evaluation.evaluator INFO: Inference done 616/2562. 0.1827 s / img. ETA=0:05:59
[05/08 09:34:33] detectron2.evaluation.evaluator INFO: Inference done 646/2562. 0.1820 s / img. ETA=0:05:52
[05/08 09:34:38] detectron2.evaluation.evaluator INFO: Inference done 675/2562. 0.1815 s / img. ETA=0:05:46
[05/08 09:34:43] detectron2.evaluation.evaluator INFO: Inference done 700/2562. 0.1824 s / img. ETA=0:05:43
[05/08 09:34:49] detectron2.evaluation.evaluator INFO: Inference done 723/2562. 0.1835 s / img. ETA=0:05:41
[05/08 09:34:54] detectron2.evaluation.evaluator INFO: Inference done 747/2562. 0.1843 s / img. ETA=0:05:38
[05/08 09:34:59] detectron2.evaluation.evaluator INFO: Inference done 777/2562. 0.1837 s / img. ETA=0:05:31
[05/08 09:35:04] detectron2.evaluation.evaluator INFO: Inference done 807/2562. 0.1830 s / img. ETA=0:05:24
[05/08 09:35:09] detectron2.evaluation.evaluator INFO: Inference done 834/2562. 0.1832 s / img. ETA=0:05:19
[05/08 09:35:14] detectron2.evaluation.evaluator INFO: Inference done 869/2562. 0.1817 s / img. ETA=0:05:10
[05/08 09:35:19] detectron2.evaluation.evaluator INFO: Inference done 897/2562. 0.1815 s / img. ETA=0:05:05
[05/08 09:35:24] detectron2.evaluation.evaluator INFO: Inference done 925/2562. 0.1814 s / img. ETA=0:05:00
[05/08 09:35:29] detectron2.evaluation.evaluator INFO: Inference done 954/2562. 0.1813 s / img. ETA=0:04:54
[05/08 09:35:34] detectron2.evaluation.evaluator INFO: Inference done 985/2562. 0.1806 s / img. ETA=0:04:47
[05/08 09:35:39] detectron2.evaluation.evaluator INFO: Inference done 1026/2562. 0.1782 s / img. ETA=0:04:36
[05/08 09:35:44] detectron2.evaluation.evaluator INFO: Inference done 1058/2562. 0.1775 s / img. ETA=0:04:29
[05/08 09:35:49] detectron2.evaluation.evaluator INFO: Inference done 1087/2562. 0.1774 s / img. ETA=0:04:24
[05/08 09:35:54] detectron2.evaluation.evaluator INFO: Inference done 1121/2562. 0.1765 s / img. ETA=0:04:17
[05/08 09:36:00] detectron2.evaluation.evaluator INFO: Inference done 1158/2562. 0.1752 s / img. ETA=0:04:08
[05/08 09:36:05] detectron2.evaluation.evaluator INFO: Inference done 1198/2562. 0.1736 s / img. ETA=0:03:59
[05/08 09:36:10] detectron2.evaluation.evaluator INFO: Inference done 1231/2562. 0.1730 s / img. ETA=0:03:52
[05/08 09:36:15] detectron2.evaluation.evaluator INFO: Inference done 1259/2562. 0.1731 s / img. ETA=0:03:48
[05/08 09:36:20] detectron2.evaluation.evaluator INFO: Inference done 1285/2562. 0.1736 s / img. ETA=0:03:44
[05/08 09:36:25] detectron2.evaluation.evaluator INFO: Inference done 1314/2562. 0.1735 s / img. ETA=0:03:38
[05/08 09:36:30] detectron2.evaluation.evaluator INFO: Inference done 1352/2562. 0.1723 s / img. ETA=0:03:30
[05/08 09:36:35] detectron2.evaluation.evaluator INFO: Inference done 1383/2562. 0.1721 s / img. ETA=0:03:25
[05/08 09:36:40] detectron2.evaluation.evaluator INFO: Inference done 1412/2562. 0.1721 s / img. ETA=0:03:20
[05/08 09:36:45] detectron2.evaluation.evaluator INFO: Inference done 1439/2562. 0.1724 s / img. ETA=0:03:15
[05/08 09:36:50] detectron2.evaluation.evaluator INFO: Inference done 1466/2562. 0.1726 s / img. ETA=0:03:11
[05/08 09:36:55] detectron2.evaluation.evaluator INFO: Inference done 1494/2562. 0.1728 s / img. ETA=0:03:06
[05/08 09:37:00] detectron2.evaluation.evaluator INFO: Inference done 1523/2562. 0.1727 s / img. ETA=0:03:01
[05/08 09:37:05] detectron2.evaluation.evaluator INFO: Inference done 1551/2562. 0.1728 s / img. ETA=0:02:56
[05/08 09:37:11] detectron2.evaluation.evaluator INFO: Inference done 1576/2562. 0.1733 s / img. ETA=0:02:52
[05/08 09:37:16] detectron2.evaluation.evaluator INFO: Inference done 1603/2562. 0.1736 s / img. ETA=0:02:48
[05/08 09:37:21] detectron2.evaluation.evaluator INFO: Inference done 1632/2562. 0.1737 s / img. ETA=0:02:43
[05/08 09:37:26] detectron2.evaluation.evaluator INFO: Inference done 1662/2562. 0.1735 s / img. ETA=0:02:37
[05/08 09:37:31] detectron2.evaluation.evaluator INFO: Inference done 1693/2562. 0.1733 s / img. ETA=0:02:32
[05/08 09:37:36] detectron2.evaluation.evaluator INFO: Inference done 1720/2562. 0.1735 s / img. ETA=0:02:27
[05/08 09:37:41] detectron2.evaluation.evaluator INFO: Inference done 1750/2562. 0.1735 s / img. ETA=0:02:22
[05/08 09:37:46] detectron2.evaluation.evaluator INFO: Inference done 1777/2562. 0.1736 s / img. ETA=0:02:17
[05/08 09:37:51] detectron2.evaluation.evaluator INFO: Inference done 1806/2562. 0.1736 s / img. ETA=0:02:12
[05/08 09:37:56] detectron2.evaluation.evaluator INFO: Inference done 1847/2562. 0.1724 s / img. ETA=0:02:04
[05/08 09:38:01] detectron2.evaluation.evaluator INFO: Inference done 1878/2562. 0.1722 s / img. ETA=0:01:59
[05/08 09:38:07] detectron2.evaluation.evaluator INFO: Inference done 1906/2562. 0.1724 s / img. ETA=0:01:54
[05/08 09:38:12] detectron2.evaluation.evaluator INFO: Inference done 1940/2562. 0.1720 s / img. ETA=0:01:48
[05/08 09:38:17] detectron2.evaluation.evaluator INFO: Inference done 1968/2562. 0.1721 s / img. ETA=0:01:43
[05/08 09:38:22] detectron2.evaluation.evaluator INFO: Inference done 2000/2562. 0.1718 s / img. ETA=0:01:37
[05/08 09:38:27] detectron2.evaluation.evaluator INFO: Inference done 2028/2562. 0.1720 s / img. ETA=0:01:32
[05/08 09:38:32] detectron2.evaluation.evaluator INFO: Inference done 2057/2562. 0.1720 s / img. ETA=0:01:27
[05/08 09:38:37] detectron2.evaluation.evaluator INFO: Inference done 2086/2562. 0.1720 s / img. ETA=0:01:22
[05/08 09:38:42] detectron2.evaluation.evaluator INFO: Inference done 2115/2562. 0.1721 s / img. ETA=0:01:17
[05/08 09:38:48] detectron2.evaluation.evaluator INFO: Inference done 2144/2562. 0.1722 s / img. ETA=0:01:12
[05/08 09:38:53] detectron2.evaluation.evaluator INFO: Inference done 2176/2562. 0.1719 s / img. ETA=0:01:07
[05/08 09:38:58] detectron2.evaluation.evaluator INFO: Inference done 2221/2562. 0.1707 s / img. ETA=0:00:58
[05/08 09:39:03] detectron2.evaluation.evaluator INFO: Inference done 2264/2562. 0.1697 s / img. ETA=0:00:51
[05/08 09:39:08] detectron2.evaluation.evaluator INFO: Inference done 2302/2562. 0.1691 s / img. ETA=0:00:44
[05/08 09:39:13] detectron2.evaluation.evaluator INFO: Inference done 2332/2562. 0.1691 s / img. ETA=0:00:39
[05/08 09:39:18] detectron2.evaluation.evaluator INFO: Inference done 2371/2562. 0.1684 s / img. ETA=0:00:32
[05/08 09:39:23] detectron2.evaluation.evaluator INFO: Inference done 2403/2562. 0.1683 s / img. ETA=0:00:27
[05/08 09:39:28] detectron2.evaluation.evaluator INFO: Inference done 2438/2562. 0.1679 s / img. ETA=0:00:21
[05/08 09:39:34] detectron2.evaluation.evaluator INFO: Inference done 2467/2562. 0.1680 s / img. ETA=0:00:16
[05/08 09:39:39] detectron2.evaluation.evaluator INFO: Inference done 2496/2562. 0.1681 s / img. ETA=0:00:11
[05/08 09:39:44] detectron2.evaluation.evaluator INFO: Inference done 2526/2562. 0.1681 s / img. ETA=0:00:06
[05/08 09:39:49] detectron2.evaluation.evaluator INFO: Inference done 2555/2562. 0.1682 s / img. ETA=0:00:01
[05/08 09:39:50] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:15.011760 (0.170126 s / img per device, on 4 devices)
[05/08 09:39:50] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:10 (0.168171 s / img per device, on 4 devices)
[05/08 09:44:52] detectron2 INFO: Rank of current process: 2. World size: 4
[05/08 09:44:53] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:44:53] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:44:53] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4 # 0.2, 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:44:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:44:53] detectron2.utils.env INFO: Using a generated random seed 53519386
[05/08 09:44:54] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:44:54] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:44:54] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:44:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:44:56] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:44:56] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:44:56] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:44:56] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:44:56] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:44:56] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:44:56] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:44:56] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:44:56] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:45:05] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1895 s / img. ETA=0:08:07
[05/08 09:45:10] detectron2.evaluation.evaluator INFO: Inference done 37/2562. 0.1920 s / img. ETA=0:08:09
[05/08 09:45:15] detectron2.evaluation.evaluator INFO: Inference done 66/2562. 0.1825 s / img. ETA=0:07:40
[05/08 09:45:20] detectron2.evaluation.evaluator INFO: Inference done 98/2562. 0.1735 s / img. ETA=0:07:12
[05/08 09:45:25] detectron2.evaluation.evaluator INFO: Inference done 132/2562. 0.1662 s / img. ETA=0:06:48
[05/08 09:45:30] detectron2.evaluation.evaluator INFO: Inference done 163/2562. 0.1654 s / img. ETA=0:06:41
[05/08 09:45:35] detectron2.evaluation.evaluator INFO: Inference done 190/2562. 0.1682 s / img. ETA=0:06:43
[05/08 09:45:41] detectron2.evaluation.evaluator INFO: Inference done 215/2562. 0.1724 s / img. ETA=0:06:49
[05/08 09:45:46] detectron2.evaluation.evaluator INFO: Inference done 240/2562. 0.1753 s / img. ETA=0:06:51
[05/08 09:45:51] detectron2.evaluation.evaluator INFO: Inference done 265/2562. 0.1780 s / img. ETA=0:06:53
[05/08 09:45:56] detectron2.evaluation.evaluator INFO: Inference done 292/2562. 0.1786 s / img. ETA=0:06:49
[05/08 09:46:01] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1806 s / img. ETA=0:06:49
[05/08 09:46:06] detectron2.evaluation.evaluator INFO: Inference done 344/2562. 0.1813 s / img. ETA=0:06:46
[05/08 09:46:11] detectron2.evaluation.evaluator INFO: Inference done 372/2562. 0.1814 s / img. ETA=0:06:41
[05/08 09:46:16] detectron2.evaluation.evaluator INFO: Inference done 400/2562. 0.1814 s / img. ETA=0:06:36
[05/08 09:46:22] detectron2.evaluation.evaluator INFO: Inference done 428/2562. 0.1815 s / img. ETA=0:06:31
[05/08 09:46:27] detectron2.evaluation.evaluator INFO: Inference done 460/2562. 0.1799 s / img. ETA=0:06:22
[05/08 09:46:32] detectron2.evaluation.evaluator INFO: Inference done 491/2562. 0.1787 s / img. ETA=0:06:14
[05/08 09:46:37] detectron2.evaluation.evaluator INFO: Inference done 521/2562. 0.1782 s / img. ETA=0:06:07
[05/08 09:46:42] detectron2.evaluation.evaluator INFO: Inference done 545/2562. 0.1796 s / img. ETA=0:06:06
[05/08 09:46:47] detectron2.evaluation.evaluator INFO: Inference done 572/2562. 0.1801 s / img. ETA=0:06:02
[05/08 09:46:52] detectron2.evaluation.evaluator INFO: Inference done 596/2562. 0.1814 s / img. ETA=0:06:00
[05/08 09:46:57] detectron2.evaluation.evaluator INFO: Inference done 623/2562. 0.1815 s / img. ETA=0:05:55
[05/08 09:47:02] detectron2.evaluation.evaluator INFO: Inference done 654/2562. 0.1807 s / img. ETA=0:05:48
[05/08 09:47:08] detectron2.evaluation.evaluator INFO: Inference done 682/2562. 0.1808 s / img. ETA=0:05:43
[05/08 09:47:13] detectron2.evaluation.evaluator INFO: Inference done 706/2562. 0.1817 s / img. ETA=0:05:40
[05/08 09:47:18] detectron2.evaluation.evaluator INFO: Inference done 729/2562. 0.1829 s / img. ETA=0:05:38
[05/08 09:47:23] detectron2.evaluation.evaluator INFO: Inference done 755/2562. 0.1834 s / img. ETA=0:05:34
[05/08 09:47:28] detectron2.evaluation.evaluator INFO: Inference done 787/2562. 0.1824 s / img. ETA=0:05:27
[05/08 09:47:33] detectron2.evaluation.evaluator INFO: Inference done 817/2562. 0.1820 s / img. ETA=0:05:20
[05/08 09:47:38] detectron2.evaluation.evaluator INFO: Inference done 846/2562. 0.1817 s / img. ETA=0:05:15
[05/08 09:47:43] detectron2.evaluation.evaluator INFO: Inference done 879/2562. 0.1806 s / img. ETA=0:05:07
[05/08 09:47:49] detectron2.evaluation.evaluator INFO: Inference done 905/2562. 0.1811 s / img. ETA=0:05:03
[05/08 09:47:54] detectron2.evaluation.evaluator INFO: Inference done 935/2562. 0.1806 s / img. ETA=0:04:56
[05/08 09:47:59] detectron2.evaluation.evaluator INFO: Inference done 964/2562. 0.1805 s / img. ETA=0:04:51
[05/08 09:48:04] detectron2.evaluation.evaluator INFO: Inference done 998/2562. 0.1793 s / img. ETA=0:04:43
[05/08 09:48:09] detectron2.evaluation.evaluator INFO: Inference done 1038/2562. 0.1773 s / img. ETA=0:04:33
[05/08 09:48:14] detectron2.evaluation.evaluator INFO: Inference done 1066/2562. 0.1773 s / img. ETA=0:04:28
[05/08 09:48:19] detectron2.evaluation.evaluator INFO: Inference done 1097/2562. 0.1770 s / img. ETA=0:04:22
[05/08 09:48:24] detectron2.evaluation.evaluator INFO: Inference done 1133/2562. 0.1758 s / img. ETA=0:04:13
[05/08 09:48:30] detectron2.evaluation.evaluator INFO: Inference done 1171/2562. 0.1744 s / img. ETA=0:04:05
[05/08 09:48:35] detectron2.evaluation.evaluator INFO: Inference done 1210/2562. 0.1730 s / img. ETA=0:03:56
[05/08 09:48:40] detectron2.evaluation.evaluator INFO: Inference done 1244/2562. 0.1724 s / img. ETA=0:03:49
[05/08 09:48:45] detectron2.evaluation.evaluator INFO: Inference done 1270/2562. 0.1729 s / img. ETA=0:03:45
[05/08 09:48:50] detectron2.evaluation.evaluator INFO: Inference done 1296/2562. 0.1732 s / img. ETA=0:03:41
[05/08 09:48:55] detectron2.evaluation.evaluator INFO: Inference done 1330/2562. 0.1726 s / img. ETA=0:03:34
[05/08 09:49:00] detectron2.evaluation.evaluator INFO: Inference done 1366/2562. 0.1717 s / img. ETA=0:03:27
[05/08 09:49:05] detectron2.evaluation.evaluator INFO: Inference done 1396/2562. 0.1717 s / img. ETA=0:03:22
[05/08 09:49:10] detectron2.evaluation.evaluator INFO: Inference done 1424/2562. 0.1719 s / img. ETA=0:03:17
[05/08 09:49:16] detectron2.evaluation.evaluator INFO: Inference done 1451/2562. 0.1721 s / img. ETA=0:03:13
[05/08 09:49:21] detectron2.evaluation.evaluator INFO: Inference done 1479/2562. 0.1722 s / img. ETA=0:03:08
[05/08 09:49:26] detectron2.evaluation.evaluator INFO: Inference done 1508/2562. 0.1723 s / img. ETA=0:03:03
[05/08 09:49:31] detectron2.evaluation.evaluator INFO: Inference done 1536/2562. 0.1724 s / img. ETA=0:02:58
[05/08 09:49:36] detectron2.evaluation.evaluator INFO: Inference done 1563/2562. 0.1726 s / img. ETA=0:02:54
[05/08 09:49:41] detectron2.evaluation.evaluator INFO: Inference done 1589/2562. 0.1730 s / img. ETA=0:02:50
[05/08 09:49:46] detectron2.evaluation.evaluator INFO: Inference done 1617/2562. 0.1731 s / img. ETA=0:02:45
[05/08 09:49:51] detectron2.evaluation.evaluator INFO: Inference done 1647/2562. 0.1730 s / img. ETA=0:02:40
[05/08 09:49:56] detectron2.evaluation.evaluator INFO: Inference done 1677/2562. 0.1729 s / img. ETA=0:02:34
[05/08 09:50:01] detectron2.evaluation.evaluator INFO: Inference done 1705/2562. 0.1730 s / img. ETA=0:02:29
[05/08 09:50:06] detectron2.evaluation.evaluator INFO: Inference done 1736/2562. 0.1728 s / img. ETA=0:02:24
[05/08 09:50:12] detectron2.evaluation.evaluator INFO: Inference done 1763/2562. 0.1730 s / img. ETA=0:02:19
[05/08 09:50:17] detectron2.evaluation.evaluator INFO: Inference done 1790/2562. 0.1732 s / img. ETA=0:02:15
[05/08 09:50:22] detectron2.evaluation.evaluator INFO: Inference done 1825/2562. 0.1726 s / img. ETA=0:02:08
[05/08 09:50:27] detectron2.evaluation.evaluator INFO: Inference done 1865/2562. 0.1716 s / img. ETA=0:02:00
[05/08 09:50:32] detectron2.evaluation.evaluator INFO: Inference done 1892/2562. 0.1718 s / img. ETA=0:01:56
[05/08 09:50:37] detectron2.evaluation.evaluator INFO: Inference done 1924/2562. 0.1715 s / img. ETA=0:01:50
[05/08 09:50:42] detectron2.evaluation.evaluator INFO: Inference done 1954/2562. 0.1715 s / img. ETA=0:01:45
[05/08 09:50:47] detectron2.evaluation.evaluator INFO: Inference done 1986/2562. 0.1713 s / img. ETA=0:01:39
[05/08 09:50:52] detectron2.evaluation.evaluator INFO: Inference done 2014/2562. 0.1714 s / img. ETA=0:01:34
[05/08 09:50:57] detectron2.evaluation.evaluator INFO: Inference done 2042/2562. 0.1715 s / img. ETA=0:01:30
[05/08 09:51:02] detectron2.evaluation.evaluator INFO: Inference done 2071/2562. 0.1716 s / img. ETA=0:01:25
[05/08 09:51:07] detectron2.evaluation.evaluator INFO: Inference done 2100/2562. 0.1716 s / img. ETA=0:01:20
[05/08 09:51:13] detectron2.evaluation.evaluator INFO: Inference done 2130/2562. 0.1716 s / img. ETA=0:01:14
[05/08 09:51:18] detectron2.evaluation.evaluator INFO: Inference done 2156/2562. 0.1718 s / img. ETA=0:01:10
[05/08 09:51:23] detectron2.evaluation.evaluator INFO: Inference done 2198/2562. 0.1708 s / img. ETA=0:01:02
[05/08 09:51:28] detectron2.evaluation.evaluator INFO: Inference done 2243/2562. 0.1696 s / img. ETA=0:00:54
[05/08 09:51:33] detectron2.evaluation.evaluator INFO: Inference done 2283/2562. 0.1688 s / img. ETA=0:00:47
[05/08 09:51:38] detectron2.evaluation.evaluator INFO: Inference done 2318/2562. 0.1684 s / img. ETA=0:00:41
[05/08 09:51:43] detectron2.evaluation.evaluator INFO: Inference done 2346/2562. 0.1685 s / img. ETA=0:00:36
[05/08 09:51:48] detectron2.evaluation.evaluator INFO: Inference done 2389/2562. 0.1676 s / img. ETA=0:00:29
[05/08 09:51:53] detectron2.evaluation.evaluator INFO: Inference done 2419/2562. 0.1676 s / img. ETA=0:00:24
[05/08 09:51:58] detectron2.evaluation.evaluator INFO: Inference done 2450/2562. 0.1675 s / img. ETA=0:00:18
[05/08 09:52:03] detectron2.evaluation.evaluator INFO: Inference done 2480/2562. 0.1675 s / img. ETA=0:00:13
[05/08 09:52:08] detectron2.evaluation.evaluator INFO: Inference done 2509/2562. 0.1676 s / img. ETA=0:00:08
[05/08 09:52:14] detectron2.evaluation.evaluator INFO: Inference done 2539/2562. 0.1676 s / img. ETA=0:00:03
[05/08 09:52:18] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:13.803511 (0.169653 s / img per device, on 4 devices)
[05/08 09:52:18] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:08 (0.167642 s / img per device, on 4 devices)
