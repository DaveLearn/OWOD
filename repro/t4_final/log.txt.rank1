[05/07 16:05:54] detectron2 INFO: Rank of current process: 1. World size: 4
[05/07 16:05:55] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 16:05:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 16:05:55] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 16:05:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 16:05:55] detectron2.utils.env INFO: Using a generated random seed 55535229
[05/07 16:05:56] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 16:05:56] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 16:05:56] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 16:05:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 16:05:58] detectron2.data.build INFO: Known classes: range(0, 80)
[05/07 16:05:58] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 16:05:58] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 16:05:58] detectron2.data.build INFO: Number of datapoints: 10246
[05/07 16:05:58] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 16:05:58] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 16:05:58] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 16:05:58] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 16:05:58] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/07 16:06:07] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1158 s / img. ETA=0:04:58
[05/07 16:06:12] detectron2.evaluation.evaluator INFO: Inference done 45/2562. 0.1435 s / img. ETA=0:06:05
[05/07 16:06:17] detectron2.evaluation.evaluator INFO: Inference done 78/2562. 0.1472 s / img. ETA=0:06:09
[05/07 16:06:22] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1469 s / img. ETA=0:06:04
[05/07 16:06:27] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1455 s / img. ETA=0:05:55
[05/07 16:06:32] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1450 s / img. ETA=0:05:49
[05/07 16:06:37] detectron2.evaluation.evaluator INFO: Inference done 216/2562. 0.1451 s / img. ETA=0:05:44
[05/07 16:06:42] detectron2.evaluation.evaluator INFO: Inference done 249/2562. 0.1463 s / img. ETA=0:05:42
[05/07 16:06:48] detectron2.evaluation.evaluator INFO: Inference done 284/2562. 0.1459 s / img. ETA=0:05:36
[05/07 16:06:53] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1464 s / img. ETA=0:05:32
[05/07 16:06:58] detectron2.evaluation.evaluator INFO: Inference done 350/2562. 0.1469 s / img. ETA=0:05:28
[05/07 16:07:03] detectron2.evaluation.evaluator INFO: Inference done 381/2562. 0.1482 s / img. ETA=0:05:26
[05/07 16:07:08] detectron2.evaluation.evaluator INFO: Inference done 417/2562. 0.1473 s / img. ETA=0:05:19
[05/07 16:07:13] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1479 s / img. ETA=0:05:16
[05/07 16:07:18] detectron2.evaluation.evaluator INFO: Inference done 483/2562. 0.1479 s / img. ETA=0:05:10
[05/07 16:07:23] detectron2.evaluation.evaluator INFO: Inference done 515/2562. 0.1486 s / img. ETA=0:05:07
[05/07 16:07:28] detectron2.evaluation.evaluator INFO: Inference done 549/2562. 0.1486 s / img. ETA=0:05:02
[05/07 16:07:33] detectron2.evaluation.evaluator INFO: Inference done 583/2562. 0.1485 s / img. ETA=0:04:57
[05/07 16:07:38] detectron2.evaluation.evaluator INFO: Inference done 614/2562. 0.1493 s / img. ETA=0:04:54
[05/07 16:07:44] detectron2.evaluation.evaluator INFO: Inference done 647/2562. 0.1496 s / img. ETA=0:04:49
[05/07 16:07:49] detectron2.evaluation.evaluator INFO: Inference done 680/2562. 0.1497 s / img. ETA=0:04:44
[05/07 16:07:54] detectron2.evaluation.evaluator INFO: Inference done 714/2562. 0.1496 s / img. ETA=0:04:39
[05/07 16:07:59] detectron2.evaluation.evaluator INFO: Inference done 748/2562. 0.1495 s / img. ETA=0:04:34
[05/07 16:08:04] detectron2.evaluation.evaluator INFO: Inference done 784/2562. 0.1491 s / img. ETA=0:04:28
[05/07 16:08:09] detectron2.evaluation.evaluator INFO: Inference done 817/2562. 0.1492 s / img. ETA=0:04:23
[05/07 16:08:14] detectron2.evaluation.evaluator INFO: Inference done 852/2562. 0.1489 s / img. ETA=0:04:17
[05/07 16:08:19] detectron2.evaluation.evaluator INFO: Inference done 885/2562. 0.1490 s / img. ETA=0:04:12
[05/07 16:08:24] detectron2.evaluation.evaluator INFO: Inference done 918/2562. 0.1490 s / img. ETA=0:04:07
[05/07 16:08:29] detectron2.evaluation.evaluator INFO: Inference done 952/2562. 0.1490 s / img. ETA=0:04:02
[05/07 16:08:34] detectron2.evaluation.evaluator INFO: Inference done 983/2562. 0.1495 s / img. ETA=0:03:58
[05/07 16:08:39] detectron2.evaluation.evaluator INFO: Inference done 1016/2562. 0.1495 s / img. ETA=0:03:53
[05/07 16:08:44] detectron2.evaluation.evaluator INFO: Inference done 1051/2562. 0.1494 s / img. ETA=0:03:48
[05/07 16:08:49] detectron2.evaluation.evaluator INFO: Inference done 1085/2562. 0.1492 s / img. ETA=0:03:42
[05/07 16:08:55] detectron2.evaluation.evaluator INFO: Inference done 1117/2562. 0.1495 s / img. ETA=0:03:38
[05/07 16:09:00] detectron2.evaluation.evaluator INFO: Inference done 1151/2562. 0.1494 s / img. ETA=0:03:33
[05/07 16:09:05] detectron2.evaluation.evaluator INFO: Inference done 1186/2562. 0.1493 s / img. ETA=0:03:27
[05/07 16:09:10] detectron2.evaluation.evaluator INFO: Inference done 1217/2562. 0.1496 s / img. ETA=0:03:23
[05/07 16:09:15] detectron2.evaluation.evaluator INFO: Inference done 1248/2562. 0.1498 s / img. ETA=0:03:19
[05/07 16:09:20] detectron2.evaluation.evaluator INFO: Inference done 1278/2562. 0.1503 s / img. ETA=0:03:15
[05/07 16:09:25] detectron2.evaluation.evaluator INFO: Inference done 1312/2562. 0.1502 s / img. ETA=0:03:09
[05/07 16:09:30] detectron2.evaluation.evaluator INFO: Inference done 1344/2562. 0.1504 s / img. ETA=0:03:05
[05/07 16:09:35] detectron2.evaluation.evaluator INFO: Inference done 1377/2562. 0.1504 s / img. ETA=0:03:00
[05/07 16:09:40] detectron2.evaluation.evaluator INFO: Inference done 1407/2562. 0.1508 s / img. ETA=0:02:56
[05/07 16:09:45] detectron2.evaluation.evaluator INFO: Inference done 1438/2562. 0.1510 s / img. ETA=0:02:51
[05/07 16:09:50] detectron2.evaluation.evaluator INFO: Inference done 1469/2562. 0.1512 s / img. ETA=0:02:47
[05/07 16:09:55] detectron2.evaluation.evaluator INFO: Inference done 1502/2562. 0.1512 s / img. ETA=0:02:42
[05/07 16:10:00] detectron2.evaluation.evaluator INFO: Inference done 1534/2562. 0.1513 s / img. ETA=0:02:37
[05/07 16:10:05] detectron2.evaluation.evaluator INFO: Inference done 1566/2562. 0.1514 s / img. ETA=0:02:32
[05/07 16:10:11] detectron2.evaluation.evaluator INFO: Inference done 1598/2562. 0.1516 s / img. ETA=0:02:27
[05/07 16:10:16] detectron2.evaluation.evaluator INFO: Inference done 1632/2562. 0.1515 s / img. ETA=0:02:22
[05/07 16:10:21] detectron2.evaluation.evaluator INFO: Inference done 1661/2562. 0.1518 s / img. ETA=0:02:18
[05/07 16:10:26] detectron2.evaluation.evaluator INFO: Inference done 1694/2562. 0.1519 s / img. ETA=0:02:13
[05/07 16:10:31] detectron2.evaluation.evaluator INFO: Inference done 1727/2562. 0.1519 s / img. ETA=0:02:08
[05/07 16:10:36] detectron2.evaluation.evaluator INFO: Inference done 1760/2562. 0.1519 s / img. ETA=0:02:03
[05/07 16:10:41] detectron2.evaluation.evaluator INFO: Inference done 1793/2562. 0.1518 s / img. ETA=0:01:58
[05/07 16:10:46] detectron2.evaluation.evaluator INFO: Inference done 1827/2562. 0.1518 s / img. ETA=0:01:52
[05/07 16:10:51] detectron2.evaluation.evaluator INFO: Inference done 1860/2562. 0.1518 s / img. ETA=0:01:47
[05/07 16:10:56] detectron2.evaluation.evaluator INFO: Inference done 1896/2562. 0.1516 s / img. ETA=0:01:42
[05/07 16:11:01] detectron2.evaluation.evaluator INFO: Inference done 1930/2562. 0.1516 s / img. ETA=0:01:36
[05/07 16:11:07] detectron2.evaluation.evaluator INFO: Inference done 1963/2562. 0.1516 s / img. ETA=0:01:31
[05/07 16:11:12] detectron2.evaluation.evaluator INFO: Inference done 1993/2562. 0.1519 s / img. ETA=0:01:27
[05/07 16:11:17] detectron2.evaluation.evaluator INFO: Inference done 2027/2562. 0.1518 s / img. ETA=0:01:22
[05/07 16:11:22] detectron2.evaluation.evaluator INFO: Inference done 2059/2562. 0.1519 s / img. ETA=0:01:17
[05/07 16:11:27] detectron2.evaluation.evaluator INFO: Inference done 2091/2562. 0.1520 s / img. ETA=0:01:12
[05/07 16:11:32] detectron2.evaluation.evaluator INFO: Inference done 2123/2562. 0.1521 s / img. ETA=0:01:07
[05/07 16:11:37] detectron2.evaluation.evaluator INFO: Inference done 2159/2562. 0.1519 s / img. ETA=0:01:01
[05/07 16:11:42] detectron2.evaluation.evaluator INFO: Inference done 2188/2562. 0.1522 s / img. ETA=0:00:57
[05/07 16:11:47] detectron2.evaluation.evaluator INFO: Inference done 2223/2562. 0.1520 s / img. ETA=0:00:52
[05/07 16:11:53] detectron2.evaluation.evaluator INFO: Inference done 2257/2562. 0.1520 s / img. ETA=0:00:46
[05/07 16:11:58] detectron2.evaluation.evaluator INFO: Inference done 2290/2562. 0.1520 s / img. ETA=0:00:41
[05/07 16:12:03] detectron2.evaluation.evaluator INFO: Inference done 2321/2562. 0.1521 s / img. ETA=0:00:37
[05/07 16:12:08] detectron2.evaluation.evaluator INFO: Inference done 2349/2562. 0.1524 s / img. ETA=0:00:32
[05/07 16:12:13] detectron2.evaluation.evaluator INFO: Inference done 2383/2562. 0.1523 s / img. ETA=0:00:27
[05/07 16:12:18] detectron2.evaluation.evaluator INFO: Inference done 2411/2562. 0.1527 s / img. ETA=0:00:23
[05/07 16:12:23] detectron2.evaluation.evaluator INFO: Inference done 2441/2562. 0.1528 s / img. ETA=0:00:18
[05/07 16:12:28] detectron2.evaluation.evaluator INFO: Inference done 2469/2562. 0.1531 s / img. ETA=0:00:14
[05/07 16:12:33] detectron2.evaluation.evaluator INFO: Inference done 2495/2562. 0.1536 s / img. ETA=0:00:10
[05/07 16:12:38] detectron2.evaluation.evaluator INFO: Inference done 2520/2562. 0.1541 s / img. ETA=0:00:06
[05/07 16:12:43] detectron2.evaluation.evaluator INFO: Inference done 2544/2562. 0.1546 s / img. ETA=0:00:02
[05/07 16:12:46] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:39.923917 (0.156404 s / img per device, on 4 devices)
[05/07 16:12:46] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:35 (0.154531 s / img per device, on 4 devices)
[05/07 17:04:24] detectron2 INFO: Rank of current process: 1. World size: 4
[05/07 17:04:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 17:04:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 17:04:25] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 17:04:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 17:04:25] detectron2.utils.env INFO: Using a generated random seed 25321284
[05/07 17:04:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 17:04:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 17:04:26] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 17:04:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 17:04:27] detectron2.data.build INFO: Known classes: range(0, 80)
[05/07 17:04:27] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 17:04:28] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 17:04:28] detectron2.data.build INFO: Number of datapoints: 10246
[05/07 17:04:28] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 17:04:28] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 17:04:28] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 17:04:28] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 17:04:28] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/07 17:04:37] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1163 s / img. ETA=0:04:59
[05/07 17:04:42] detectron2.evaluation.evaluator INFO: Inference done 45/2562. 0.1436 s / img. ETA=0:06:05
[05/07 17:04:47] detectron2.evaluation.evaluator INFO: Inference done 78/2562. 0.1474 s / img. ETA=0:06:10
[05/07 17:04:52] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1474 s / img. ETA=0:06:05
[05/07 17:04:57] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1462 s / img. ETA=0:05:57
[05/07 17:05:02] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1456 s / img. ETA=0:05:50
[05/07 17:05:07] detectron2.evaluation.evaluator INFO: Inference done 216/2562. 0.1456 s / img. ETA=0:05:45
[05/07 17:05:12] detectron2.evaluation.evaluator INFO: Inference done 249/2562. 0.1468 s / img. ETA=0:05:43
[05/07 17:05:17] detectron2.evaluation.evaluator INFO: Inference done 284/2562. 0.1463 s / img. ETA=0:05:37
[05/07 17:05:22] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1468 s / img. ETA=0:05:33
[05/07 17:05:27] detectron2.evaluation.evaluator INFO: Inference done 350/2562. 0.1473 s / img. ETA=0:05:29
[05/07 17:05:33] detectron2.evaluation.evaluator INFO: Inference done 381/2562. 0.1485 s / img. ETA=0:05:27
[05/07 17:05:38] detectron2.evaluation.evaluator INFO: Inference done 417/2562. 0.1476 s / img. ETA=0:05:20
[05/07 17:05:43] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1482 s / img. ETA=0:05:16
[05/07 17:05:48] detectron2.evaluation.evaluator INFO: Inference done 483/2562. 0.1481 s / img. ETA=0:05:11
[05/07 17:05:53] detectron2.evaluation.evaluator INFO: Inference done 515/2562. 0.1488 s / img. ETA=0:05:08
[05/07 17:05:58] detectron2.evaluation.evaluator INFO: Inference done 549/2562. 0.1487 s / img. ETA=0:05:03
[05/07 17:06:03] detectron2.evaluation.evaluator INFO: Inference done 584/2562. 0.1485 s / img. ETA=0:04:57
[05/07 17:06:08] detectron2.evaluation.evaluator INFO: Inference done 614/2562. 0.1494 s / img. ETA=0:04:54
[05/07 17:06:13] detectron2.evaluation.evaluator INFO: Inference done 647/2562. 0.1495 s / img. ETA=0:04:49
[05/07 17:06:18] detectron2.evaluation.evaluator INFO: Inference done 679/2562. 0.1498 s / img. ETA=0:04:45
[05/07 17:06:23] detectron2.evaluation.evaluator INFO: Inference done 713/2562. 0.1497 s / img. ETA=0:04:40
[05/07 17:06:28] detectron2.evaluation.evaluator INFO: Inference done 747/2562. 0.1497 s / img. ETA=0:04:34
[05/07 17:06:34] detectron2.evaluation.evaluator INFO: Inference done 783/2562. 0.1492 s / img. ETA=0:04:28
[05/07 17:06:39] detectron2.evaluation.evaluator INFO: Inference done 816/2562. 0.1493 s / img. ETA=0:04:23
[05/07 17:06:44] detectron2.evaluation.evaluator INFO: Inference done 851/2562. 0.1490 s / img. ETA=0:04:17
[05/07 17:06:49] detectron2.evaluation.evaluator INFO: Inference done 885/2562. 0.1489 s / img. ETA=0:04:12
[05/07 17:06:54] detectron2.evaluation.evaluator INFO: Inference done 919/2562. 0.1490 s / img. ETA=0:04:07
[05/07 17:06:59] detectron2.evaluation.evaluator INFO: Inference done 954/2562. 0.1489 s / img. ETA=0:04:02
[05/07 17:07:04] detectron2.evaluation.evaluator INFO: Inference done 985/2562. 0.1493 s / img. ETA=0:03:58
[05/07 17:07:09] detectron2.evaluation.evaluator INFO: Inference done 1018/2562. 0.1494 s / img. ETA=0:03:53
[05/07 17:07:14] detectron2.evaluation.evaluator INFO: Inference done 1052/2562. 0.1494 s / img. ETA=0:03:48
[05/07 17:07:19] detectron2.evaluation.evaluator INFO: Inference done 1087/2562. 0.1491 s / img. ETA=0:03:42
[05/07 17:07:24] detectron2.evaluation.evaluator INFO: Inference done 1119/2562. 0.1493 s / img. ETA=0:03:37
[05/07 17:07:29] detectron2.evaluation.evaluator INFO: Inference done 1153/2562. 0.1492 s / img. ETA=0:03:32
[05/07 17:07:34] detectron2.evaluation.evaluator INFO: Inference done 1188/2562. 0.1490 s / img. ETA=0:03:27
[05/07 17:07:39] detectron2.evaluation.evaluator INFO: Inference done 1219/2562. 0.1493 s / img. ETA=0:03:22
[05/07 17:07:44] detectron2.evaluation.evaluator INFO: Inference done 1250/2562. 0.1496 s / img. ETA=0:03:18
[05/07 17:07:50] detectron2.evaluation.evaluator INFO: Inference done 1280/2562. 0.1500 s / img. ETA=0:03:14
[05/07 17:07:55] detectron2.evaluation.evaluator INFO: Inference done 1315/2562. 0.1499 s / img. ETA=0:03:09
[05/07 17:08:00] detectron2.evaluation.evaluator INFO: Inference done 1348/2562. 0.1500 s / img. ETA=0:03:04
[05/07 17:08:05] detectron2.evaluation.evaluator INFO: Inference done 1380/2562. 0.1501 s / img. ETA=0:02:59
[05/07 17:08:10] detectron2.evaluation.evaluator INFO: Inference done 1411/2562. 0.1504 s / img. ETA=0:02:55
[05/07 17:08:15] detectron2.evaluation.evaluator INFO: Inference done 1442/2562. 0.1506 s / img. ETA=0:02:50
[05/07 17:08:20] detectron2.evaluation.evaluator INFO: Inference done 1474/2562. 0.1508 s / img. ETA=0:02:46
[05/07 17:08:25] detectron2.evaluation.evaluator INFO: Inference done 1508/2562. 0.1508 s / img. ETA=0:02:40
[05/07 17:08:31] detectron2.evaluation.evaluator INFO: Inference done 1540/2562. 0.1510 s / img. ETA=0:02:36
[05/07 17:08:36] detectron2.evaluation.evaluator INFO: Inference done 1573/2562. 0.1510 s / img. ETA=0:02:31
[05/07 17:08:41] detectron2.evaluation.evaluator INFO: Inference done 1605/2562. 0.1512 s / img. ETA=0:02:26
[05/07 17:08:46] detectron2.evaluation.evaluator INFO: Inference done 1640/2562. 0.1510 s / img. ETA=0:02:20
[05/07 17:08:51] detectron2.evaluation.evaluator INFO: Inference done 1668/2562. 0.1515 s / img. ETA=0:02:17
[05/07 17:08:56] detectron2.evaluation.evaluator INFO: Inference done 1702/2562. 0.1514 s / img. ETA=0:02:11
[05/07 17:09:01] detectron2.evaluation.evaluator INFO: Inference done 1734/2562. 0.1515 s / img. ETA=0:02:06
[05/07 17:09:06] detectron2.evaluation.evaluator INFO: Inference done 1769/2562. 0.1514 s / img. ETA=0:02:01
[05/07 17:09:11] detectron2.evaluation.evaluator INFO: Inference done 1802/2562. 0.1515 s / img. ETA=0:01:56
[05/07 17:09:16] detectron2.evaluation.evaluator INFO: Inference done 1836/2562. 0.1514 s / img. ETA=0:01:51
[05/07 17:09:22] detectron2.evaluation.evaluator INFO: Inference done 1871/2562. 0.1513 s / img. ETA=0:01:45
[05/07 17:09:27] detectron2.evaluation.evaluator INFO: Inference done 1908/2562. 0.1510 s / img. ETA=0:01:39
[05/07 17:09:32] detectron2.evaluation.evaluator INFO: Inference done 1939/2562. 0.1512 s / img. ETA=0:01:35
[05/07 17:09:37] detectron2.evaluation.evaluator INFO: Inference done 1971/2562. 0.1512 s / img. ETA=0:01:30
[05/07 17:09:42] detectron2.evaluation.evaluator INFO: Inference done 2003/2562. 0.1513 s / img. ETA=0:01:25
[05/07 17:09:47] detectron2.evaluation.evaluator INFO: Inference done 2037/2562. 0.1513 s / img. ETA=0:01:20
[05/07 17:09:52] detectron2.evaluation.evaluator INFO: Inference done 2069/2562. 0.1514 s / img. ETA=0:01:15
[05/07 17:09:57] detectron2.evaluation.evaluator INFO: Inference done 2102/2562. 0.1514 s / img. ETA=0:01:10
[05/07 17:10:02] detectron2.evaluation.evaluator INFO: Inference done 2134/2562. 0.1515 s / img. ETA=0:01:05
[05/07 17:10:07] detectron2.evaluation.evaluator INFO: Inference done 2169/2562. 0.1514 s / img. ETA=0:01:00
[05/07 17:10:12] detectron2.evaluation.evaluator INFO: Inference done 2199/2562. 0.1516 s / img. ETA=0:00:55
[05/07 17:10:18] detectron2.evaluation.evaluator INFO: Inference done 2234/2562. 0.1515 s / img. ETA=0:00:50
[05/07 17:10:23] detectron2.evaluation.evaluator INFO: Inference done 2266/2562. 0.1515 s / img. ETA=0:00:45
[05/07 17:10:28] detectron2.evaluation.evaluator INFO: Inference done 2298/2562. 0.1516 s / img. ETA=0:00:40
[05/07 17:10:33] detectron2.evaluation.evaluator INFO: Inference done 2327/2562. 0.1518 s / img. ETA=0:00:36
[05/07 17:10:38] detectron2.evaluation.evaluator INFO: Inference done 2358/2562. 0.1520 s / img. ETA=0:00:31
[05/07 17:10:43] detectron2.evaluation.evaluator INFO: Inference done 2392/2562. 0.1519 s / img. ETA=0:00:26
[05/07 17:10:48] detectron2.evaluation.evaluator INFO: Inference done 2418/2562. 0.1524 s / img. ETA=0:00:22
[05/07 17:10:53] detectron2.evaluation.evaluator INFO: Inference done 2448/2562. 0.1526 s / img. ETA=0:00:17
[05/07 17:10:58] detectron2.evaluation.evaluator INFO: Inference done 2477/2562. 0.1529 s / img. ETA=0:00:13
[05/07 17:11:03] detectron2.evaluation.evaluator INFO: Inference done 2502/2562. 0.1534 s / img. ETA=0:00:09
[05/07 17:11:08] detectron2.evaluation.evaluator INFO: Inference done 2526/2562. 0.1539 s / img. ETA=0:00:05
[05/07 17:11:14] detectron2.evaluation.evaluator INFO: Inference done 2553/2562. 0.1543 s / img. ETA=0:00:01
[05/07 17:11:15] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:39.140158 (0.156097 s / img per device, on 4 devices)
[05/07 17:11:15] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:34 (0.154186 s / img per device, on 4 devices)
[05/08 08:50:10] detectron2 INFO: Rank of current process: 1. World size: 4
[05/08 08:50:11] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 08:50:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 08:50:11] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 10
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 08:50:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 10
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 08:50:11] detectron2.utils.env INFO: Using a generated random seed 11427966
[05/08 08:50:12] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 08:50:12] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 08:50:12] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 08:50:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 08:50:14] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 08:50:14] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 08:50:14] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 08:50:14] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 08:50:14] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 08:50:14] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 08:50:14] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 08:50:14] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 08:50:14] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 08:50:23] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1169 s / img. ETA=0:05:01
[05/08 08:50:28] detectron2.evaluation.evaluator INFO: Inference done 44/2562. 0.1450 s / img. ETA=0:06:08
[05/08 08:50:33] detectron2.evaluation.evaluator INFO: Inference done 77/2562. 0.1486 s / img. ETA=0:06:13
[05/08 08:50:38] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1476 s / img. ETA=0:06:05
[05/08 08:50:43] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1462 s / img. ETA=0:05:56
[05/08 08:50:48] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1454 s / img. ETA=0:05:49
[05/08 08:50:53] detectron2.evaluation.evaluator INFO: Inference done 216/2562. 0.1455 s / img. ETA=0:05:45
[05/08 08:50:59] detectron2.evaluation.evaluator INFO: Inference done 249/2562. 0.1466 s / img. ETA=0:05:42
[05/08 08:51:04] detectron2.evaluation.evaluator INFO: Inference done 284/2562. 0.1462 s / img. ETA=0:05:36
[05/08 08:51:09] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1467 s / img. ETA=0:05:32
[05/08 08:51:14] detectron2.evaluation.evaluator INFO: Inference done 350/2562. 0.1472 s / img. ETA=0:05:29
[05/08 08:51:19] detectron2.evaluation.evaluator INFO: Inference done 381/2562. 0.1484 s / img. ETA=0:05:27
[05/08 08:51:24] detectron2.evaluation.evaluator INFO: Inference done 417/2562. 0.1476 s / img. ETA=0:05:19
[05/08 08:51:29] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1481 s / img. ETA=0:05:16
[05/08 08:51:34] detectron2.evaluation.evaluator INFO: Inference done 483/2562. 0.1481 s / img. ETA=0:05:11
[05/08 08:51:39] detectron2.evaluation.evaluator INFO: Inference done 515/2562. 0.1487 s / img. ETA=0:05:07
[05/08 08:51:44] detectron2.evaluation.evaluator INFO: Inference done 549/2562. 0.1487 s / img. ETA=0:05:02
[05/08 08:51:49] detectron2.evaluation.evaluator INFO: Inference done 584/2562. 0.1485 s / img. ETA=0:04:56
[05/08 08:51:54] detectron2.evaluation.evaluator INFO: Inference done 615/2562. 0.1492 s / img. ETA=0:04:53
[05/08 08:51:59] detectron2.evaluation.evaluator INFO: Inference done 648/2562. 0.1494 s / img. ETA=0:04:49
[05/08 08:52:04] detectron2.evaluation.evaluator INFO: Inference done 683/2562. 0.1491 s / img. ETA=0:04:43
[05/08 08:52:09] detectron2.evaluation.evaluator INFO: Inference done 716/2562. 0.1491 s / img. ETA=0:04:38
[05/08 08:52:14] detectron2.evaluation.evaluator INFO: Inference done 750/2562. 0.1490 s / img. ETA=0:04:32
[05/08 08:52:20] detectron2.evaluation.evaluator INFO: Inference done 786/2562. 0.1486 s / img. ETA=0:04:26
[05/08 08:52:25] detectron2.evaluation.evaluator INFO: Inference done 819/2562. 0.1487 s / img. ETA=0:04:21
[05/08 08:52:30] detectron2.evaluation.evaluator INFO: Inference done 854/2562. 0.1484 s / img. ETA=0:04:16
[05/08 08:52:35] detectron2.evaluation.evaluator INFO: Inference done 887/2562. 0.1485 s / img. ETA=0:04:11
[05/08 08:52:40] detectron2.evaluation.evaluator INFO: Inference done 920/2562. 0.1486 s / img. ETA=0:04:06
[05/08 08:52:45] detectron2.evaluation.evaluator INFO: Inference done 954/2562. 0.1487 s / img. ETA=0:04:01
[05/08 08:52:50] detectron2.evaluation.evaluator INFO: Inference done 984/2562. 0.1492 s / img. ETA=0:03:57
[05/08 08:52:55] detectron2.evaluation.evaluator INFO: Inference done 1017/2562. 0.1493 s / img. ETA=0:03:53
[05/08 08:53:00] detectron2.evaluation.evaluator INFO: Inference done 1052/2562. 0.1492 s / img. ETA=0:03:47
[05/08 08:53:05] detectron2.evaluation.evaluator INFO: Inference done 1087/2562. 0.1490 s / img. ETA=0:03:42
[05/08 08:53:10] detectron2.evaluation.evaluator INFO: Inference done 1119/2562. 0.1492 s / img. ETA=0:03:37
[05/08 08:53:15] detectron2.evaluation.evaluator INFO: Inference done 1154/2562. 0.1490 s / img. ETA=0:03:31
[05/08 08:53:20] detectron2.evaluation.evaluator INFO: Inference done 1188/2562. 0.1489 s / img. ETA=0:03:26
[05/08 08:53:25] detectron2.evaluation.evaluator INFO: Inference done 1218/2562. 0.1493 s / img. ETA=0:03:22
[05/08 08:53:30] detectron2.evaluation.evaluator INFO: Inference done 1249/2562. 0.1496 s / img. ETA=0:03:18
[05/08 08:53:36] detectron2.evaluation.evaluator INFO: Inference done 1279/2562. 0.1501 s / img. ETA=0:03:14
[05/08 08:53:41] detectron2.evaluation.evaluator INFO: Inference done 1314/2562. 0.1500 s / img. ETA=0:03:09
[05/08 08:53:46] detectron2.evaluation.evaluator INFO: Inference done 1346/2562. 0.1501 s / img. ETA=0:03:04
[05/08 08:53:51] detectron2.evaluation.evaluator INFO: Inference done 1378/2562. 0.1503 s / img. ETA=0:02:59
[05/08 08:53:56] detectron2.evaluation.evaluator INFO: Inference done 1408/2562. 0.1507 s / img. ETA=0:02:55
[05/08 08:54:01] detectron2.evaluation.evaluator INFO: Inference done 1441/2562. 0.1508 s / img. ETA=0:02:50
[05/08 08:54:06] detectron2.evaluation.evaluator INFO: Inference done 1472/2562. 0.1511 s / img. ETA=0:02:46
[05/08 08:54:11] detectron2.evaluation.evaluator INFO: Inference done 1506/2562. 0.1511 s / img. ETA=0:02:41
[05/08 08:54:16] detectron2.evaluation.evaluator INFO: Inference done 1537/2562. 0.1512 s / img. ETA=0:02:36
[05/08 08:54:22] detectron2.evaluation.evaluator INFO: Inference done 1569/2562. 0.1514 s / img. ETA=0:02:31
[05/08 08:54:27] detectron2.evaluation.evaluator INFO: Inference done 1601/2562. 0.1515 s / img. ETA=0:02:27
[05/08 08:54:32] detectron2.evaluation.evaluator INFO: Inference done 1635/2562. 0.1514 s / img. ETA=0:02:21
[05/08 08:54:37] detectron2.evaluation.evaluator INFO: Inference done 1664/2562. 0.1518 s / img. ETA=0:02:17
[05/08 08:54:42] detectron2.evaluation.evaluator INFO: Inference done 1697/2562. 0.1518 s / img. ETA=0:02:12
[05/08 08:54:47] detectron2.evaluation.evaluator INFO: Inference done 1730/2562. 0.1519 s / img. ETA=0:02:07
[05/08 08:54:52] detectron2.evaluation.evaluator INFO: Inference done 1765/2562. 0.1517 s / img. ETA=0:02:02
[05/08 08:54:57] detectron2.evaluation.evaluator INFO: Inference done 1798/2562. 0.1518 s / img. ETA=0:01:57
[05/08 08:55:02] detectron2.evaluation.evaluator INFO: Inference done 1831/2562. 0.1518 s / img. ETA=0:01:52
[05/08 08:55:07] detectron2.evaluation.evaluator INFO: Inference done 1865/2562. 0.1517 s / img. ETA=0:01:46
[05/08 08:55:13] detectron2.evaluation.evaluator INFO: Inference done 1900/2562. 0.1516 s / img. ETA=0:01:41
[05/08 08:55:18] detectron2.evaluation.evaluator INFO: Inference done 1935/2562. 0.1515 s / img. ETA=0:01:35
[05/08 08:55:23] detectron2.evaluation.evaluator INFO: Inference done 1967/2562. 0.1516 s / img. ETA=0:01:31
[05/08 08:55:28] detectron2.evaluation.evaluator INFO: Inference done 1999/2562. 0.1517 s / img. ETA=0:01:26
[05/08 08:55:33] detectron2.evaluation.evaluator INFO: Inference done 2033/2562. 0.1517 s / img. ETA=0:01:21
[05/08 08:55:38] detectron2.evaluation.evaluator INFO: Inference done 2064/2562. 0.1518 s / img. ETA=0:01:16
[05/08 08:55:43] detectron2.evaluation.evaluator INFO: Inference done 2097/2562. 0.1518 s / img. ETA=0:01:11
[05/08 08:55:48] detectron2.evaluation.evaluator INFO: Inference done 2129/2562. 0.1520 s / img. ETA=0:01:06
[05/08 08:55:53] detectron2.evaluation.evaluator INFO: Inference done 2164/2562. 0.1518 s / img. ETA=0:01:01
[05/08 08:55:59] detectron2.evaluation.evaluator INFO: Inference done 2194/2562. 0.1521 s / img. ETA=0:00:56
[05/08 08:56:04] detectron2.evaluation.evaluator INFO: Inference done 2230/2562. 0.1519 s / img. ETA=0:00:50
[05/08 08:56:09] detectron2.evaluation.evaluator INFO: Inference done 2263/2562. 0.1519 s / img. ETA=0:00:45
[05/08 08:56:14] detectron2.evaluation.evaluator INFO: Inference done 2296/2562. 0.1519 s / img. ETA=0:00:40
[05/08 08:56:19] detectron2.evaluation.evaluator INFO: Inference done 2325/2562. 0.1521 s / img. ETA=0:00:36
[05/08 08:56:24] detectron2.evaluation.evaluator INFO: Inference done 2356/2562. 0.1522 s / img. ETA=0:00:31
[05/08 08:56:29] detectron2.evaluation.evaluator INFO: Inference done 2390/2562. 0.1522 s / img. ETA=0:00:26
[05/08 08:56:34] detectron2.evaluation.evaluator INFO: Inference done 2416/2562. 0.1527 s / img. ETA=0:00:22
[05/08 08:56:39] detectron2.evaluation.evaluator INFO: Inference done 2446/2562. 0.1528 s / img. ETA=0:00:17
[05/08 08:56:44] detectron2.evaluation.evaluator INFO: Inference done 2474/2562. 0.1532 s / img. ETA=0:00:13
[05/08 08:56:49] detectron2.evaluation.evaluator INFO: Inference done 2499/2562. 0.1537 s / img. ETA=0:00:09
[05/08 08:56:55] detectron2.evaluation.evaluator INFO: Inference done 2523/2562. 0.1542 s / img. ETA=0:00:06
[05/08 08:57:00] detectron2.evaluation.evaluator INFO: Inference done 2548/2562. 0.1547 s / img. ETA=0:00:02
[05/08 08:57:02] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:39.354022 (0.156181 s / img per device, on 4 devices)
[05/08 08:57:02] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:35 (0.154524 s / img per device, on 4 devices)
[05/08 09:08:03] detectron2 INFO: Rank of current process: 1. World size: 4
[05/08 09:08:04] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:08:04] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:08:04] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 200
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:08:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:08:04] detectron2.utils.env INFO: Using a generated random seed 4674930
[05/08 09:08:05] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:08:05] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:08:05] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:08:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:08:07] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:08:07] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:08:07] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:08:07] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:08:07] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:08:07] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:08:07] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:08:07] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:08:07] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:08:16] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1151 s / img. ETA=0:04:56
[05/08 09:08:21] detectron2.evaluation.evaluator INFO: Inference done 45/2562. 0.1430 s / img. ETA=0:06:04
[05/08 09:08:26] detectron2.evaluation.evaluator INFO: Inference done 78/2562. 0.1467 s / img. ETA=0:06:08
[05/08 09:08:31] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1468 s / img. ETA=0:06:04
[05/08 09:08:36] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1457 s / img. ETA=0:05:56
[05/08 09:08:41] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1451 s / img. ETA=0:05:49
[05/08 09:08:46] detectron2.evaluation.evaluator INFO: Inference done 216/2562. 0.1451 s / img. ETA=0:05:44
[05/08 09:08:52] detectron2.evaluation.evaluator INFO: Inference done 249/2562. 0.1463 s / img. ETA=0:05:42
[05/08 09:08:57] detectron2.evaluation.evaluator INFO: Inference done 284/2562. 0.1459 s / img. ETA=0:05:36
[05/08 09:09:02] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1464 s / img. ETA=0:05:32
[05/08 09:09:07] detectron2.evaluation.evaluator INFO: Inference done 350/2562. 0.1470 s / img. ETA=0:05:29
[05/08 09:09:12] detectron2.evaluation.evaluator INFO: Inference done 381/2562. 0.1482 s / img. ETA=0:05:27
[05/08 09:09:17] detectron2.evaluation.evaluator INFO: Inference done 417/2562. 0.1474 s / img. ETA=0:05:20
[05/08 09:09:22] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1479 s / img. ETA=0:05:16
[05/08 09:09:27] detectron2.evaluation.evaluator INFO: Inference done 483/2562. 0.1479 s / img. ETA=0:05:11
[05/08 09:09:32] detectron2.evaluation.evaluator INFO: Inference done 515/2562. 0.1486 s / img. ETA=0:05:08
[05/08 09:09:37] detectron2.evaluation.evaluator INFO: Inference done 548/2562. 0.1487 s / img. ETA=0:05:03
[05/08 09:09:42] detectron2.evaluation.evaluator INFO: Inference done 582/2562. 0.1485 s / img. ETA=0:04:57
[05/08 09:09:47] detectron2.evaluation.evaluator INFO: Inference done 613/2562. 0.1492 s / img. ETA=0:04:54
[05/08 09:09:52] detectron2.evaluation.evaluator INFO: Inference done 645/2562. 0.1496 s / img. ETA=0:04:50
[05/08 09:09:57] detectron2.evaluation.evaluator INFO: Inference done 678/2562. 0.1497 s / img. ETA=0:04:45
[05/08 09:10:03] detectron2.evaluation.evaluator INFO: Inference done 712/2562. 0.1496 s / img. ETA=0:04:40
[05/08 09:10:08] detectron2.evaluation.evaluator INFO: Inference done 747/2562. 0.1494 s / img. ETA=0:04:34
[05/08 09:10:13] detectron2.evaluation.evaluator INFO: Inference done 783/2562. 0.1490 s / img. ETA=0:04:28
[05/08 09:10:18] detectron2.evaluation.evaluator INFO: Inference done 815/2562. 0.1492 s / img. ETA=0:04:23
[05/08 09:10:23] detectron2.evaluation.evaluator INFO: Inference done 851/2562. 0.1488 s / img. ETA=0:04:17
[05/08 09:10:28] detectron2.evaluation.evaluator INFO: Inference done 884/2562. 0.1489 s / img. ETA=0:04:13
[05/08 09:10:33] detectron2.evaluation.evaluator INFO: Inference done 918/2562. 0.1489 s / img. ETA=0:04:07
[05/08 09:10:38] detectron2.evaluation.evaluator INFO: Inference done 952/2562. 0.1488 s / img. ETA=0:04:02
[05/08 09:10:43] detectron2.evaluation.evaluator INFO: Inference done 982/2562. 0.1494 s / img. ETA=0:03:58
[05/08 09:10:48] detectron2.evaluation.evaluator INFO: Inference done 1015/2562. 0.1494 s / img. ETA=0:03:54
[05/08 09:10:53] detectron2.evaluation.evaluator INFO: Inference done 1050/2562. 0.1493 s / img. ETA=0:03:48
[05/08 09:10:59] detectron2.evaluation.evaluator INFO: Inference done 1084/2562. 0.1493 s / img. ETA=0:03:43
[05/08 09:11:04] detectron2.evaluation.evaluator INFO: Inference done 1116/2562. 0.1494 s / img. ETA=0:03:38
[05/08 09:11:09] detectron2.evaluation.evaluator INFO: Inference done 1150/2562. 0.1493 s / img. ETA=0:03:33
[05/08 09:11:14] detectron2.evaluation.evaluator INFO: Inference done 1185/2562. 0.1492 s / img. ETA=0:03:28
[05/08 09:11:19] detectron2.evaluation.evaluator INFO: Inference done 1215/2562. 0.1496 s / img. ETA=0:03:24
[05/08 09:11:24] detectron2.evaluation.evaluator INFO: Inference done 1247/2562. 0.1499 s / img. ETA=0:03:19
[05/08 09:11:29] detectron2.evaluation.evaluator INFO: Inference done 1277/2562. 0.1503 s / img. ETA=0:03:15
[05/08 09:11:34] detectron2.evaluation.evaluator INFO: Inference done 1310/2562. 0.1503 s / img. ETA=0:03:10
[05/08 09:11:39] detectron2.evaluation.evaluator INFO: Inference done 1342/2562. 0.1505 s / img. ETA=0:03:05
[05/08 09:11:44] detectron2.evaluation.evaluator INFO: Inference done 1376/2562. 0.1505 s / img. ETA=0:03:00
[05/08 09:11:49] detectron2.evaluation.evaluator INFO: Inference done 1406/2562. 0.1509 s / img. ETA=0:02:56
[05/08 09:11:55] detectron2.evaluation.evaluator INFO: Inference done 1438/2562. 0.1511 s / img. ETA=0:02:51
[05/08 09:12:00] detectron2.evaluation.evaluator INFO: Inference done 1469/2562. 0.1513 s / img. ETA=0:02:47
[05/08 09:12:05] detectron2.evaluation.evaluator INFO: Inference done 1502/2562. 0.1513 s / img. ETA=0:02:42
[05/08 09:12:10] detectron2.evaluation.evaluator INFO: Inference done 1534/2562. 0.1514 s / img. ETA=0:02:37
[05/08 09:12:15] detectron2.evaluation.evaluator INFO: Inference done 1565/2562. 0.1515 s / img. ETA=0:02:32
[05/08 09:12:20] detectron2.evaluation.evaluator INFO: Inference done 1596/2562. 0.1517 s / img. ETA=0:02:28
[05/08 09:12:25] detectron2.evaluation.evaluator INFO: Inference done 1630/2562. 0.1517 s / img. ETA=0:02:23
[05/08 09:12:30] detectron2.evaluation.evaluator INFO: Inference done 1659/2562. 0.1520 s / img. ETA=0:02:18
[05/08 09:12:35] detectron2.evaluation.evaluator INFO: Inference done 1692/2562. 0.1520 s / img. ETA=0:02:13
[05/08 09:12:40] detectron2.evaluation.evaluator INFO: Inference done 1726/2562. 0.1519 s / img. ETA=0:02:08
[05/08 09:12:45] detectron2.evaluation.evaluator INFO: Inference done 1759/2562. 0.1519 s / img. ETA=0:02:03
[05/08 09:12:50] detectron2.evaluation.evaluator INFO: Inference done 1793/2562. 0.1518 s / img. ETA=0:01:58
[05/08 09:12:55] detectron2.evaluation.evaluator INFO: Inference done 1826/2562. 0.1518 s / img. ETA=0:01:53
[05/08 09:13:00] detectron2.evaluation.evaluator INFO: Inference done 1859/2562. 0.1518 s / img. ETA=0:01:48
[05/08 09:13:05] detectron2.evaluation.evaluator INFO: Inference done 1894/2562. 0.1516 s / img. ETA=0:01:42
[05/08 09:13:11] detectron2.evaluation.evaluator INFO: Inference done 1929/2562. 0.1515 s / img. ETA=0:01:37
[05/08 09:13:16] detectron2.evaluation.evaluator INFO: Inference done 1961/2562. 0.1516 s / img. ETA=0:01:32
[05/08 09:13:21] detectron2.evaluation.evaluator INFO: Inference done 1992/2562. 0.1517 s / img. ETA=0:01:27
[05/08 09:13:26] detectron2.evaluation.evaluator INFO: Inference done 2026/2562. 0.1517 s / img. ETA=0:01:22
[05/08 09:13:31] detectron2.evaluation.evaluator INFO: Inference done 2057/2562. 0.1518 s / img. ETA=0:01:17
[05/08 09:13:36] detectron2.evaluation.evaluator INFO: Inference done 2089/2562. 0.1519 s / img. ETA=0:01:12
[05/08 09:13:41] detectron2.evaluation.evaluator INFO: Inference done 2121/2562. 0.1520 s / img. ETA=0:01:07
[05/08 09:13:46] detectron2.evaluation.evaluator INFO: Inference done 2156/2562. 0.1518 s / img. ETA=0:01:02
[05/08 09:13:51] detectron2.evaluation.evaluator INFO: Inference done 2186/2562. 0.1520 s / img. ETA=0:00:57
[05/08 09:13:56] detectron2.evaluation.evaluator INFO: Inference done 2221/2562. 0.1519 s / img. ETA=0:00:52
[05/08 09:14:01] detectron2.evaluation.evaluator INFO: Inference done 2255/2562. 0.1518 s / img. ETA=0:00:47
[05/08 09:14:06] detectron2.evaluation.evaluator INFO: Inference done 2286/2562. 0.1520 s / img. ETA=0:00:42
[05/08 09:14:11] detectron2.evaluation.evaluator INFO: Inference done 2317/2562. 0.1521 s / img. ETA=0:00:37
[05/08 09:14:17] detectron2.evaluation.evaluator INFO: Inference done 2346/2562. 0.1524 s / img. ETA=0:00:33
[05/08 09:14:22] detectron2.evaluation.evaluator INFO: Inference done 2380/2562. 0.1523 s / img. ETA=0:00:28
[05/08 09:14:27] detectron2.evaluation.evaluator INFO: Inference done 2408/2562. 0.1526 s / img. ETA=0:00:23
[05/08 09:14:32] detectron2.evaluation.evaluator INFO: Inference done 2438/2562. 0.1528 s / img. ETA=0:00:19
[05/08 09:14:37] detectron2.evaluation.evaluator INFO: Inference done 2466/2562. 0.1531 s / img. ETA=0:00:14
[05/08 09:14:42] detectron2.evaluation.evaluator INFO: Inference done 2492/2562. 0.1535 s / img. ETA=0:00:10
[05/08 09:14:47] detectron2.evaluation.evaluator INFO: Inference done 2517/2562. 0.1540 s / img. ETA=0:00:07
[05/08 09:14:52] detectron2.evaluation.evaluator INFO: Inference done 2541/2562. 0.1545 s / img. ETA=0:00:03
[05/08 09:14:56] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:40.191672 (0.156508 s / img per device, on 4 devices)
[05/08 09:14:56] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:35 (0.154478 s / img per device, on 4 devices)
[05/08 09:23:00] detectron2 INFO: Rank of current process: 1. World size: 4
[05/08 09:23:01] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:23:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:23:01] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:23:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.3
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:23:01] detectron2.utils.env INFO: Using a generated random seed 1811868
[05/08 09:23:02] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:23:02] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:23:02] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:23:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:23:04] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:23:04] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:23:04] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:23:04] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:23:04] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:23:04] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:23:04] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:23:04] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:23:04] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:23:13] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1152 s / img. ETA=0:04:56
[05/08 09:23:18] detectron2.evaluation.evaluator INFO: Inference done 45/2562. 0.1430 s / img. ETA=0:06:03
[05/08 09:23:23] detectron2.evaluation.evaluator INFO: Inference done 78/2562. 0.1466 s / img. ETA=0:06:08
[05/08 09:23:29] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1469 s / img. ETA=0:06:04
[05/08 09:23:34] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1456 s / img. ETA=0:05:55
[05/08 09:23:39] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1449 s / img. ETA=0:05:49
[05/08 09:23:44] detectron2.evaluation.evaluator INFO: Inference done 217/2562. 0.1448 s / img. ETA=0:05:43
[05/08 09:23:49] detectron2.evaluation.evaluator INFO: Inference done 249/2562. 0.1461 s / img. ETA=0:05:42
[05/08 09:23:54] detectron2.evaluation.evaluator INFO: Inference done 284/2562. 0.1457 s / img. ETA=0:05:35
[05/08 09:23:59] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1462 s / img. ETA=0:05:32
[05/08 09:24:04] detectron2.evaluation.evaluator INFO: Inference done 350/2562. 0.1467 s / img. ETA=0:05:28
[05/08 09:24:09] detectron2.evaluation.evaluator INFO: Inference done 381/2562. 0.1479 s / img. ETA=0:05:26
[05/08 09:24:14] detectron2.evaluation.evaluator INFO: Inference done 417/2562. 0.1472 s / img. ETA=0:05:19
[05/08 09:24:19] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1478 s / img. ETA=0:05:15
[05/08 09:24:24] detectron2.evaluation.evaluator INFO: Inference done 483/2562. 0.1477 s / img. ETA=0:05:10
[05/08 09:24:29] detectron2.evaluation.evaluator INFO: Inference done 515/2562. 0.1484 s / img. ETA=0:05:07
[05/08 09:24:34] detectron2.evaluation.evaluator INFO: Inference done 549/2562. 0.1484 s / img. ETA=0:05:02
[05/08 09:24:39] detectron2.evaluation.evaluator INFO: Inference done 584/2562. 0.1482 s / img. ETA=0:04:56
[05/08 09:24:45] detectron2.evaluation.evaluator INFO: Inference done 615/2562. 0.1489 s / img. ETA=0:04:53
[05/08 09:24:50] detectron2.evaluation.evaluator INFO: Inference done 648/2562. 0.1491 s / img. ETA=0:04:48
[05/08 09:24:55] detectron2.evaluation.evaluator INFO: Inference done 683/2562. 0.1488 s / img. ETA=0:04:42
[05/08 09:25:00] detectron2.evaluation.evaluator INFO: Inference done 717/2562. 0.1488 s / img. ETA=0:04:37
[05/08 09:25:05] detectron2.evaluation.evaluator INFO: Inference done 751/2562. 0.1486 s / img. ETA=0:04:32
[05/08 09:25:10] detectron2.evaluation.evaluator INFO: Inference done 786/2562. 0.1484 s / img. ETA=0:04:26
[05/08 09:25:15] detectron2.evaluation.evaluator INFO: Inference done 819/2562. 0.1486 s / img. ETA=0:04:22
[05/08 09:25:20] detectron2.evaluation.evaluator INFO: Inference done 855/2562. 0.1482 s / img. ETA=0:04:15
[05/08 09:25:25] detectron2.evaluation.evaluator INFO: Inference done 888/2562. 0.1483 s / img. ETA=0:04:11
[05/08 09:25:30] detectron2.evaluation.evaluator INFO: Inference done 922/2562. 0.1483 s / img. ETA=0:04:06
[05/08 09:25:35] detectron2.evaluation.evaluator INFO: Inference done 955/2562. 0.1485 s / img. ETA=0:04:01
[05/08 09:25:40] detectron2.evaluation.evaluator INFO: Inference done 987/2562. 0.1488 s / img. ETA=0:03:57
[05/08 09:25:46] detectron2.evaluation.evaluator INFO: Inference done 1021/2562. 0.1488 s / img. ETA=0:03:51
[05/08 09:25:51] detectron2.evaluation.evaluator INFO: Inference done 1056/2562. 0.1486 s / img. ETA=0:03:46
[05/08 09:25:56] detectron2.evaluation.evaluator INFO: Inference done 1090/2562. 0.1486 s / img. ETA=0:03:41
[05/08 09:26:01] detectron2.evaluation.evaluator INFO: Inference done 1122/2562. 0.1488 s / img. ETA=0:03:36
[05/08 09:26:06] detectron2.evaluation.evaluator INFO: Inference done 1157/2562. 0.1486 s / img. ETA=0:03:31
[05/08 09:26:11] detectron2.evaluation.evaluator INFO: Inference done 1190/2562. 0.1488 s / img. ETA=0:03:26
[05/08 09:26:16] detectron2.evaluation.evaluator INFO: Inference done 1222/2562. 0.1491 s / img. ETA=0:03:22
[05/08 09:26:21] detectron2.evaluation.evaluator INFO: Inference done 1254/2562. 0.1493 s / img. ETA=0:03:17
[05/08 09:26:26] detectron2.evaluation.evaluator INFO: Inference done 1283/2562. 0.1498 s / img. ETA=0:03:13
[05/08 09:26:31] detectron2.evaluation.evaluator INFO: Inference done 1317/2562. 0.1497 s / img. ETA=0:03:08
[05/08 09:26:36] detectron2.evaluation.evaluator INFO: Inference done 1349/2562. 0.1499 s / img. ETA=0:03:03
[05/08 09:26:42] detectron2.evaluation.evaluator INFO: Inference done 1381/2562. 0.1501 s / img. ETA=0:02:59
[05/08 09:26:47] detectron2.evaluation.evaluator INFO: Inference done 1412/2562. 0.1504 s / img. ETA=0:02:54
[05/08 09:26:52] detectron2.evaluation.evaluator INFO: Inference done 1445/2562. 0.1505 s / img. ETA=0:02:50
[05/08 09:26:57] detectron2.evaluation.evaluator INFO: Inference done 1477/2562. 0.1507 s / img. ETA=0:02:45
[05/08 09:27:02] detectron2.evaluation.evaluator INFO: Inference done 1510/2562. 0.1507 s / img. ETA=0:02:40
[05/08 09:27:07] detectron2.evaluation.evaluator INFO: Inference done 1542/2562. 0.1508 s / img. ETA=0:02:35
[05/08 09:27:12] detectron2.evaluation.evaluator INFO: Inference done 1575/2562. 0.1509 s / img. ETA=0:02:30
[05/08 09:27:17] detectron2.evaluation.evaluator INFO: Inference done 1607/2562. 0.1510 s / img. ETA=0:02:25
[05/08 09:27:23] detectron2.evaluation.evaluator INFO: Inference done 1641/2562. 0.1510 s / img. ETA=0:02:20
[05/08 09:27:28] detectron2.evaluation.evaluator INFO: Inference done 1671/2562. 0.1513 s / img. ETA=0:02:16
[05/08 09:27:33] detectron2.evaluation.evaluator INFO: Inference done 1706/2562. 0.1512 s / img. ETA=0:02:10
[05/08 09:27:38] detectron2.evaluation.evaluator INFO: Inference done 1737/2562. 0.1514 s / img. ETA=0:02:06
[05/08 09:27:43] detectron2.evaluation.evaluator INFO: Inference done 1772/2562. 0.1513 s / img. ETA=0:02:00
[05/08 09:27:48] detectron2.evaluation.evaluator INFO: Inference done 1806/2562. 0.1512 s / img. ETA=0:01:55
[05/08 09:27:53] detectron2.evaluation.evaluator INFO: Inference done 1840/2562. 0.1512 s / img. ETA=0:01:50
[05/08 09:27:58] detectron2.evaluation.evaluator INFO: Inference done 1874/2562. 0.1511 s / img. ETA=0:01:45
[05/08 09:28:03] detectron2.evaluation.evaluator INFO: Inference done 1912/2562. 0.1507 s / img. ETA=0:01:39
[05/08 09:28:08] detectron2.evaluation.evaluator INFO: Inference done 1942/2562. 0.1509 s / img. ETA=0:01:34
[05/08 09:28:14] detectron2.evaluation.evaluator INFO: Inference done 1975/2562. 0.1510 s / img. ETA=0:01:29
[05/08 09:28:19] detectron2.evaluation.evaluator INFO: Inference done 2007/2562. 0.1511 s / img. ETA=0:01:24
[05/08 09:28:24] detectron2.evaluation.evaluator INFO: Inference done 2040/2562. 0.1511 s / img. ETA=0:01:19
[05/08 09:28:29] detectron2.evaluation.evaluator INFO: Inference done 2072/2562. 0.1511 s / img. ETA=0:01:14
[05/08 09:28:34] detectron2.evaluation.evaluator INFO: Inference done 2105/2562. 0.1512 s / img. ETA=0:01:09
[05/08 09:28:39] detectron2.evaluation.evaluator INFO: Inference done 2136/2562. 0.1513 s / img. ETA=0:01:05
[05/08 09:28:44] detectron2.evaluation.evaluator INFO: Inference done 2170/2562. 0.1512 s / img. ETA=0:00:59
[05/08 09:28:49] detectron2.evaluation.evaluator INFO: Inference done 2201/2562. 0.1514 s / img. ETA=0:00:55
[05/08 09:28:54] detectron2.evaluation.evaluator INFO: Inference done 2237/2562. 0.1512 s / img. ETA=0:00:49
[05/08 09:28:59] detectron2.evaluation.evaluator INFO: Inference done 2270/2562. 0.1512 s / img. ETA=0:00:44
[05/08 09:29:04] detectron2.evaluation.evaluator INFO: Inference done 2303/2562. 0.1513 s / img. ETA=0:00:39
[05/08 09:29:09] detectron2.evaluation.evaluator INFO: Inference done 2332/2562. 0.1516 s / img. ETA=0:00:35
[05/08 09:29:14] detectron2.evaluation.evaluator INFO: Inference done 2363/2562. 0.1517 s / img. ETA=0:00:30
[05/08 09:29:20] detectron2.evaluation.evaluator INFO: Inference done 2397/2562. 0.1516 s / img. ETA=0:00:25
[05/08 09:29:25] detectron2.evaluation.evaluator INFO: Inference done 2422/2562. 0.1522 s / img. ETA=0:00:21
[05/08 09:29:30] detectron2.evaluation.evaluator INFO: Inference done 2453/2562. 0.1523 s / img. ETA=0:00:16
[05/08 09:29:35] detectron2.evaluation.evaluator INFO: Inference done 2481/2562. 0.1527 s / img. ETA=0:00:12
[05/08 09:29:40] detectron2.evaluation.evaluator INFO: Inference done 2506/2562. 0.1532 s / img. ETA=0:00:08
[05/08 09:29:45] detectron2.evaluation.evaluator INFO: Inference done 2529/2562. 0.1537 s / img. ETA=0:00:05
[05/08 09:29:50] detectron2.evaluation.evaluator INFO: Inference done 2557/2562. 0.1540 s / img. ETA=0:00:00
[05/08 09:29:51] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:38.520969 (0.155855 s / img per device, on 4 devices)
[05/08 09:29:51] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:33 (0.153949 s / img per device, on 4 devices)
[05/08 09:32:23] detectron2 INFO: Rank of current process: 1. World size: 4
[05/08 09:32:24] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:32:24] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:32:24] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.2
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:32:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:32:24] detectron2.utils.env INFO: Using a generated random seed 24430645
[05/08 09:32:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:32:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:32:25] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:32:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:32:27] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:32:27] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:32:27] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:32:27] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:32:27] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:32:27] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:32:27] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:32:27] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:32:27] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:32:36] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1160 s / img. ETA=0:04:58
[05/08 09:32:41] detectron2.evaluation.evaluator INFO: Inference done 45/2562. 0.1438 s / img. ETA=0:06:05
[05/08 09:32:46] detectron2.evaluation.evaluator INFO: Inference done 78/2562. 0.1475 s / img. ETA=0:06:10
[05/08 09:32:51] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1474 s / img. ETA=0:06:04
[05/08 09:32:56] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1462 s / img. ETA=0:05:56
[05/08 09:33:01] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1457 s / img. ETA=0:05:50
[05/08 09:33:06] detectron2.evaluation.evaluator INFO: Inference done 216/2562. 0.1458 s / img. ETA=0:05:45
[05/08 09:33:11] detectron2.evaluation.evaluator INFO: Inference done 249/2562. 0.1470 s / img. ETA=0:05:43
[05/08 09:33:17] detectron2.evaluation.evaluator INFO: Inference done 284/2562. 0.1465 s / img. ETA=0:05:37
[05/08 09:33:22] detectron2.evaluation.evaluator INFO: Inference done 317/2562. 0.1470 s / img. ETA=0:05:33
[05/08 09:33:27] detectron2.evaluation.evaluator INFO: Inference done 350/2562. 0.1475 s / img. ETA=0:05:29
[05/08 09:33:32] detectron2.evaluation.evaluator INFO: Inference done 381/2562. 0.1486 s / img. ETA=0:05:27
[05/08 09:33:37] detectron2.evaluation.evaluator INFO: Inference done 417/2562. 0.1477 s / img. ETA=0:05:20
[05/08 09:33:42] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1483 s / img. ETA=0:05:16
[05/08 09:33:47] detectron2.evaluation.evaluator INFO: Inference done 482/2562. 0.1484 s / img. ETA=0:05:12
[05/08 09:33:52] detectron2.evaluation.evaluator INFO: Inference done 513/2562. 0.1492 s / img. ETA=0:05:09
[05/08 09:33:57] detectron2.evaluation.evaluator INFO: Inference done 546/2562. 0.1493 s / img. ETA=0:05:04
[05/08 09:34:02] detectron2.evaluation.evaluator INFO: Inference done 581/2562. 0.1492 s / img. ETA=0:04:58
[05/08 09:34:07] detectron2.evaluation.evaluator INFO: Inference done 613/2562. 0.1496 s / img. ETA=0:04:54
[05/08 09:34:12] detectron2.evaluation.evaluator INFO: Inference done 646/2562. 0.1499 s / img. ETA=0:04:50
[05/08 09:34:17] detectron2.evaluation.evaluator INFO: Inference done 679/2562. 0.1500 s / img. ETA=0:04:45
[05/08 09:34:22] detectron2.evaluation.evaluator INFO: Inference done 713/2562. 0.1498 s / img. ETA=0:04:40
[05/08 09:34:27] detectron2.evaluation.evaluator INFO: Inference done 747/2562. 0.1496 s / img. ETA=0:04:34
[05/08 09:34:32] detectron2.evaluation.evaluator INFO: Inference done 783/2562. 0.1492 s / img. ETA=0:04:28
[05/08 09:34:38] detectron2.evaluation.evaluator INFO: Inference done 816/2562. 0.1493 s / img. ETA=0:04:23
[05/08 09:34:43] detectron2.evaluation.evaluator INFO: Inference done 851/2562. 0.1490 s / img. ETA=0:04:17
[05/08 09:34:48] detectron2.evaluation.evaluator INFO: Inference done 884/2562. 0.1491 s / img. ETA=0:04:12
[05/08 09:34:53] detectron2.evaluation.evaluator INFO: Inference done 918/2562. 0.1490 s / img. ETA=0:04:07
[05/08 09:34:58] detectron2.evaluation.evaluator INFO: Inference done 951/2562. 0.1490 s / img. ETA=0:04:02
[05/08 09:35:03] detectron2.evaluation.evaluator INFO: Inference done 982/2562. 0.1494 s / img. ETA=0:03:58
[05/08 09:35:08] detectron2.evaluation.evaluator INFO: Inference done 1015/2562. 0.1495 s / img. ETA=0:03:53
[05/08 09:35:13] detectron2.evaluation.evaluator INFO: Inference done 1050/2562. 0.1492 s / img. ETA=0:03:48
[05/08 09:35:18] detectron2.evaluation.evaluator INFO: Inference done 1084/2562. 0.1491 s / img. ETA=0:03:42
[05/08 09:35:23] detectron2.evaluation.evaluator INFO: Inference done 1116/2562. 0.1494 s / img. ETA=0:03:38
[05/08 09:35:28] detectron2.evaluation.evaluator INFO: Inference done 1150/2562. 0.1494 s / img. ETA=0:03:33
[05/08 09:35:33] detectron2.evaluation.evaluator INFO: Inference done 1185/2562. 0.1492 s / img. ETA=0:03:27
[05/08 09:35:38] detectron2.evaluation.evaluator INFO: Inference done 1216/2562. 0.1495 s / img. ETA=0:03:23
[05/08 09:35:43] detectron2.evaluation.evaluator INFO: Inference done 1247/2562. 0.1498 s / img. ETA=0:03:19
[05/08 09:35:48] detectron2.evaluation.evaluator INFO: Inference done 1277/2562. 0.1503 s / img. ETA=0:03:15
[05/08 09:35:53] detectron2.evaluation.evaluator INFO: Inference done 1311/2562. 0.1502 s / img. ETA=0:03:09
[05/08 09:35:59] detectron2.evaluation.evaluator INFO: Inference done 1342/2562. 0.1504 s / img. ETA=0:03:05
[05/08 09:36:04] detectron2.evaluation.evaluator INFO: Inference done 1376/2562. 0.1504 s / img. ETA=0:03:00
[05/08 09:36:09] detectron2.evaluation.evaluator INFO: Inference done 1407/2562. 0.1507 s / img. ETA=0:02:55
[05/08 09:36:14] detectron2.evaluation.evaluator INFO: Inference done 1440/2562. 0.1508 s / img. ETA=0:02:51
[05/08 09:36:19] detectron2.evaluation.evaluator INFO: Inference done 1471/2562. 0.1510 s / img. ETA=0:02:46
[05/08 09:36:24] detectron2.evaluation.evaluator INFO: Inference done 1504/2562. 0.1510 s / img. ETA=0:02:41
[05/08 09:36:29] detectron2.evaluation.evaluator INFO: Inference done 1536/2562. 0.1512 s / img. ETA=0:02:36
[05/08 09:36:34] detectron2.evaluation.evaluator INFO: Inference done 1568/2562. 0.1512 s / img. ETA=0:02:31
[05/08 09:36:39] detectron2.evaluation.evaluator INFO: Inference done 1598/2562. 0.1515 s / img. ETA=0:02:27
[05/08 09:36:44] detectron2.evaluation.evaluator INFO: Inference done 1632/2562. 0.1514 s / img. ETA=0:02:22
[05/08 09:36:49] detectron2.evaluation.evaluator INFO: Inference done 1662/2562. 0.1517 s / img. ETA=0:02:18
[05/08 09:36:54] detectron2.evaluation.evaluator INFO: Inference done 1695/2562. 0.1517 s / img. ETA=0:02:12
[05/08 09:36:59] detectron2.evaluation.evaluator INFO: Inference done 1728/2562. 0.1517 s / img. ETA=0:02:07
[05/08 09:37:04] detectron2.evaluation.evaluator INFO: Inference done 1761/2562. 0.1517 s / img. ETA=0:02:02
[05/08 09:37:09] detectron2.evaluation.evaluator INFO: Inference done 1796/2562. 0.1515 s / img. ETA=0:01:57
[05/08 09:37:15] detectron2.evaluation.evaluator INFO: Inference done 1828/2562. 0.1516 s / img. ETA=0:01:52
[05/08 09:37:20] detectron2.evaluation.evaluator INFO: Inference done 1861/2562. 0.1516 s / img. ETA=0:01:47
[05/08 09:37:25] detectron2.evaluation.evaluator INFO: Inference done 1897/2562. 0.1513 s / img. ETA=0:01:41
[05/08 09:37:30] detectron2.evaluation.evaluator INFO: Inference done 1931/2562. 0.1513 s / img. ETA=0:01:36
[05/08 09:37:35] detectron2.evaluation.evaluator INFO: Inference done 1963/2562. 0.1513 s / img. ETA=0:01:31
[05/08 09:37:40] detectron2.evaluation.evaluator INFO: Inference done 1994/2562. 0.1515 s / img. ETA=0:01:27
[05/08 09:37:45] detectron2.evaluation.evaluator INFO: Inference done 2029/2562. 0.1514 s / img. ETA=0:01:21
[05/08 09:37:50] detectron2.evaluation.evaluator INFO: Inference done 2059/2562. 0.1516 s / img. ETA=0:01:17
[05/08 09:37:55] detectron2.evaluation.evaluator INFO: Inference done 2090/2562. 0.1517 s / img. ETA=0:01:12
[05/08 09:38:00] detectron2.evaluation.evaluator INFO: Inference done 2122/2562. 0.1518 s / img. ETA=0:01:07
[05/08 09:38:05] detectron2.evaluation.evaluator INFO: Inference done 2158/2562. 0.1516 s / img. ETA=0:01:01
[05/08 09:38:10] detectron2.evaluation.evaluator INFO: Inference done 2188/2562. 0.1518 s / img. ETA=0:00:57
[05/08 09:38:15] detectron2.evaluation.evaluator INFO: Inference done 2224/2562. 0.1517 s / img. ETA=0:00:51
[05/08 09:38:20] detectron2.evaluation.evaluator INFO: Inference done 2257/2562. 0.1516 s / img. ETA=0:00:46
[05/08 09:38:26] detectron2.evaluation.evaluator INFO: Inference done 2289/2562. 0.1517 s / img. ETA=0:00:41
[05/08 09:38:31] detectron2.evaluation.evaluator INFO: Inference done 2319/2562. 0.1519 s / img. ETA=0:00:37
[05/08 09:38:36] detectron2.evaluation.evaluator INFO: Inference done 2348/2562. 0.1522 s / img. ETA=0:00:32
[05/08 09:38:41] detectron2.evaluation.evaluator INFO: Inference done 2381/2562. 0.1522 s / img. ETA=0:00:27
[05/08 09:38:46] detectron2.evaluation.evaluator INFO: Inference done 2410/2562. 0.1525 s / img. ETA=0:00:23
[05/08 09:38:51] detectron2.evaluation.evaluator INFO: Inference done 2440/2562. 0.1527 s / img. ETA=0:00:18
[05/08 09:38:56] detectron2.evaluation.evaluator INFO: Inference done 2468/2562. 0.1530 s / img. ETA=0:00:14
[05/08 09:39:01] detectron2.evaluation.evaluator INFO: Inference done 2494/2562. 0.1534 s / img. ETA=0:00:10
[05/08 09:39:06] detectron2.evaluation.evaluator INFO: Inference done 2519/2562. 0.1539 s / img. ETA=0:00:06
[05/08 09:39:11] detectron2.evaluation.evaluator INFO: Inference done 2543/2562. 0.1545 s / img. ETA=0:00:02
[05/08 09:39:15] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:39.445991 (0.156217 s / img per device, on 4 devices)
[05/08 09:39:15] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:34 (0.154368 s / img per device, on 4 devices)
[05/08 09:44:52] detectron2 INFO: Rank of current process: 1. World size: 4
[05/08 09:44:53] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:44:53] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:44:53] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4 # 0.2, 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:44:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:44:53] detectron2.utils.env INFO: Using a generated random seed 53631078
[05/08 09:44:54] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:44:54] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:44:54] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:44:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:44:56] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:44:56] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:44:56] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:44:56] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:44:56] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:44:56] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:44:56] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:44:56] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:44:56] detectron2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 09:45:05] detectron2.evaluation.evaluator INFO: Inference done 11/2562. 0.1159 s / img. ETA=0:04:58
[05/08 09:45:10] detectron2.evaluation.evaluator INFO: Inference done 45/2562. 0.1437 s / img. ETA=0:06:05
[05/08 09:45:15] detectron2.evaluation.evaluator INFO: Inference done 78/2562. 0.1475 s / img. ETA=0:06:10
[05/08 09:45:20] detectron2.evaluation.evaluator INFO: Inference done 112/2562. 0.1473 s / img. ETA=0:06:04
[05/08 09:45:25] detectron2.evaluation.evaluator INFO: Inference done 147/2562. 0.1459 s / img. ETA=0:05:56
[05/08 09:45:30] detectron2.evaluation.evaluator INFO: Inference done 182/2562. 0.1453 s / img. ETA=0:05:49
[05/08 09:45:35] detectron2.evaluation.evaluator INFO: Inference done 216/2562. 0.1455 s / img. ETA=0:05:45
[05/08 09:45:40] detectron2.evaluation.evaluator INFO: Inference done 248/2562. 0.1468 s / img. ETA=0:05:43
[05/08 09:45:45] detectron2.evaluation.evaluator INFO: Inference done 282/2562. 0.1467 s / img. ETA=0:05:38
[05/08 09:45:50] detectron2.evaluation.evaluator INFO: Inference done 315/2562. 0.1472 s / img. ETA=0:05:34
[05/08 09:45:55] detectron2.evaluation.evaluator INFO: Inference done 349/2562. 0.1473 s / img. ETA=0:05:29
[05/08 09:46:00] detectron2.evaluation.evaluator INFO: Inference done 380/2562. 0.1486 s / img. ETA=0:05:27
[05/08 09:46:05] detectron2.evaluation.evaluator INFO: Inference done 416/2562. 0.1479 s / img. ETA=0:05:21
[05/08 09:46:11] detectron2.evaluation.evaluator INFO: Inference done 449/2562. 0.1485 s / img. ETA=0:05:17
[05/08 09:46:16] detectron2.evaluation.evaluator INFO: Inference done 482/2562. 0.1487 s / img. ETA=0:05:12
[05/08 09:46:21] detectron2.evaluation.evaluator INFO: Inference done 513/2562. 0.1494 s / img. ETA=0:05:09
[05/08 09:46:26] detectron2.evaluation.evaluator INFO: Inference done 546/2562. 0.1495 s / img. ETA=0:05:05
[05/08 09:46:31] detectron2.evaluation.evaluator INFO: Inference done 579/2562. 0.1495 s / img. ETA=0:05:00
[05/08 09:46:36] detectron2.evaluation.evaluator INFO: Inference done 609/2562. 0.1503 s / img. ETA=0:04:57
[05/08 09:46:41] detectron2.evaluation.evaluator INFO: Inference done 643/2562. 0.1503 s / img. ETA=0:04:51
[05/08 09:46:46] detectron2.evaluation.evaluator INFO: Inference done 675/2562. 0.1505 s / img. ETA=0:04:47
[05/08 09:46:51] detectron2.evaluation.evaluator INFO: Inference done 710/2562. 0.1501 s / img. ETA=0:04:41
[05/08 09:46:56] detectron2.evaluation.evaluator INFO: Inference done 744/2562. 0.1501 s / img. ETA=0:04:36
[05/08 09:47:01] detectron2.evaluation.evaluator INFO: Inference done 779/2562. 0.1497 s / img. ETA=0:04:30
[05/08 09:47:06] detectron2.evaluation.evaluator INFO: Inference done 811/2562. 0.1500 s / img. ETA=0:04:25
[05/08 09:47:11] detectron2.evaluation.evaluator INFO: Inference done 847/2562. 0.1495 s / img. ETA=0:04:19
[05/08 09:47:16] detectron2.evaluation.evaluator INFO: Inference done 878/2562. 0.1498 s / img. ETA=0:04:15
[05/08 09:47:21] detectron2.evaluation.evaluator INFO: Inference done 912/2562. 0.1498 s / img. ETA=0:04:10
[05/08 09:47:27] detectron2.evaluation.evaluator INFO: Inference done 944/2562. 0.1501 s / img. ETA=0:04:05
[05/08 09:47:32] detectron2.evaluation.evaluator INFO: Inference done 976/2562. 0.1503 s / img. ETA=0:04:01
[05/08 09:47:37] detectron2.evaluation.evaluator INFO: Inference done 1009/2562. 0.1504 s / img. ETA=0:03:56
[05/08 09:47:42] detectron2.evaluation.evaluator INFO: Inference done 1043/2562. 0.1503 s / img. ETA=0:03:51
[05/08 09:47:47] detectron2.evaluation.evaluator INFO: Inference done 1077/2562. 0.1503 s / img. ETA=0:03:45
[05/08 09:47:52] detectron2.evaluation.evaluator INFO: Inference done 1108/2562. 0.1506 s / img. ETA=0:03:41
[05/08 09:47:57] detectron2.evaluation.evaluator INFO: Inference done 1142/2562. 0.1506 s / img. ETA=0:03:36
[05/08 09:48:02] detectron2.evaluation.evaluator INFO: Inference done 1180/2562. 0.1500 s / img. ETA=0:03:29
[05/08 09:48:07] detectron2.evaluation.evaluator INFO: Inference done 1210/2562. 0.1504 s / img. ETA=0:03:25
[05/08 09:48:12] detectron2.evaluation.evaluator INFO: Inference done 1241/2562. 0.1507 s / img. ETA=0:03:21
[05/08 09:48:18] detectron2.evaluation.evaluator INFO: Inference done 1271/2562. 0.1511 s / img. ETA=0:03:17
[05/08 09:48:23] detectron2.evaluation.evaluator INFO: Inference done 1303/2562. 0.1512 s / img. ETA=0:03:12
[05/08 09:48:28] detectron2.evaluation.evaluator INFO: Inference done 1335/2562. 0.1514 s / img. ETA=0:03:07
[05/08 09:48:33] detectron2.evaluation.evaluator INFO: Inference done 1368/2562. 0.1515 s / img. ETA=0:03:03
[05/08 09:48:38] detectron2.evaluation.evaluator INFO: Inference done 1399/2562. 0.1517 s / img. ETA=0:02:58
[05/08 09:48:43] detectron2.evaluation.evaluator INFO: Inference done 1430/2562. 0.1519 s / img. ETA=0:02:53
[05/08 09:48:48] detectron2.evaluation.evaluator INFO: Inference done 1460/2562. 0.1522 s / img. ETA=0:02:49
[05/08 09:48:53] detectron2.evaluation.evaluator INFO: Inference done 1492/2562. 0.1523 s / img. ETA=0:02:44
[05/08 09:48:58] detectron2.evaluation.evaluator INFO: Inference done 1525/2562. 0.1523 s / img. ETA=0:02:39
[05/08 09:49:03] detectron2.evaluation.evaluator INFO: Inference done 1557/2562. 0.1524 s / img. ETA=0:02:34
[05/08 09:49:08] detectron2.evaluation.evaluator INFO: Inference done 1590/2562. 0.1524 s / img. ETA=0:02:29
[05/08 09:49:13] detectron2.evaluation.evaluator INFO: Inference done 1622/2562. 0.1524 s / img. ETA=0:02:24
[05/08 09:49:18] detectron2.evaluation.evaluator INFO: Inference done 1654/2562. 0.1525 s / img. ETA=0:02:20
[05/08 09:49:24] detectron2.evaluation.evaluator INFO: Inference done 1686/2562. 0.1526 s / img. ETA=0:02:15
[05/08 09:49:29] detectron2.evaluation.evaluator INFO: Inference done 1720/2562. 0.1526 s / img. ETA=0:02:10
[05/08 09:49:34] detectron2.evaluation.evaluator INFO: Inference done 1753/2562. 0.1526 s / img. ETA=0:02:04
[05/08 09:49:39] detectron2.evaluation.evaluator INFO: Inference done 1787/2562. 0.1525 s / img. ETA=0:01:59
[05/08 09:49:44] detectron2.evaluation.evaluator INFO: Inference done 1819/2562. 0.1526 s / img. ETA=0:01:54
[05/08 09:49:49] detectron2.evaluation.evaluator INFO: Inference done 1853/2562. 0.1524 s / img. ETA=0:01:49
[05/08 09:49:54] detectron2.evaluation.evaluator INFO: Inference done 1886/2562. 0.1524 s / img. ETA=0:01:44
[05/08 09:49:59] detectron2.evaluation.evaluator INFO: Inference done 1924/2562. 0.1521 s / img. ETA=0:01:38
[05/08 09:50:04] detectron2.evaluation.evaluator INFO: Inference done 1955/2562. 0.1523 s / img. ETA=0:01:33
[05/08 09:50:10] detectron2.evaluation.evaluator INFO: Inference done 1987/2562. 0.1524 s / img. ETA=0:01:28
[05/08 09:50:15] detectron2.evaluation.evaluator INFO: Inference done 2021/2562. 0.1523 s / img. ETA=0:01:23
[05/08 09:50:20] detectron2.evaluation.evaluator INFO: Inference done 2053/2562. 0.1525 s / img. ETA=0:01:18
[05/08 09:50:25] detectron2.evaluation.evaluator INFO: Inference done 2085/2562. 0.1525 s / img. ETA=0:01:13
[05/08 09:50:30] detectron2.evaluation.evaluator INFO: Inference done 2117/2562. 0.1526 s / img. ETA=0:01:08
[05/08 09:50:35] detectron2.evaluation.evaluator INFO: Inference done 2150/2562. 0.1525 s / img. ETA=0:01:03
[05/08 09:50:40] detectron2.evaluation.evaluator INFO: Inference done 2182/2562. 0.1527 s / img. ETA=0:00:58
[05/08 09:50:45] detectron2.evaluation.evaluator INFO: Inference done 2216/2562. 0.1526 s / img. ETA=0:00:53
[05/08 09:50:50] detectron2.evaluation.evaluator INFO: Inference done 2251/2562. 0.1524 s / img. ETA=0:00:47
[05/08 09:50:56] detectron2.evaluation.evaluator INFO: Inference done 2282/2562. 0.1526 s / img. ETA=0:00:43
[05/08 09:51:01] detectron2.evaluation.evaluator INFO: Inference done 2314/2562. 0.1527 s / img. ETA=0:00:38
[05/08 09:51:06] detectron2.evaluation.evaluator INFO: Inference done 2343/2562. 0.1529 s / img. ETA=0:00:33
[05/08 09:51:11] detectron2.evaluation.evaluator INFO: Inference done 2376/2562. 0.1529 s / img. ETA=0:00:28
[05/08 09:51:16] detectron2.evaluation.evaluator INFO: Inference done 2406/2562. 0.1531 s / img. ETA=0:00:24
[05/08 09:51:21] detectron2.evaluation.evaluator INFO: Inference done 2435/2562. 0.1533 s / img. ETA=0:00:19
[05/08 09:51:26] detectron2.evaluation.evaluator INFO: Inference done 2462/2562. 0.1537 s / img. ETA=0:00:15
[05/08 09:51:31] detectron2.evaluation.evaluator INFO: Inference done 2488/2562. 0.1541 s / img. ETA=0:00:11
[05/08 09:51:36] detectron2.evaluation.evaluator INFO: Inference done 2513/2562. 0.1546 s / img. ETA=0:00:07
[05/08 09:51:41] detectron2.evaluation.evaluator INFO: Inference done 2537/2562. 0.1551 s / img. ETA=0:00:03
[05/08 09:51:46] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:41.633306 (0.157072 s / img per device, on 4 devices)
[05/08 09:51:46] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:36 (0.155142 s / img per device, on 4 devices)
