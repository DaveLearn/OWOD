[05/07 16:05:54] detectron2 INFO: Rank of current process: 3. World size: 4
[05/07 16:05:55] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 16:05:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 16:05:55] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 16:05:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 16:05:55] detectron2.utils.env INFO: Using a generated random seed 55651814
[05/07 16:05:56] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 16:05:56] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 16:05:56] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 16:05:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 16:05:58] detectron2.data.build INFO: Known classes: range(0, 80)
[05/07 16:05:58] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 16:05:58] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 16:05:58] detectron2.data.build INFO: Number of datapoints: 10246
[05/07 16:05:58] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 16:05:58] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 16:05:58] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 16:05:58] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 16:05:58] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/07 16:06:07] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1701 s / img. ETA=0:07:17
[05/07 16:06:12] detectron2.evaluation.evaluator INFO: Inference done 40/2560. 0.1715 s / img. ETA=0:07:16
[05/07 16:06:17] detectron2.evaluation.evaluator INFO: Inference done 69/2560. 0.1711 s / img. ETA=0:07:11
[05/07 16:06:22] detectron2.evaluation.evaluator INFO: Inference done 99/2560. 0.1698 s / img. ETA=0:07:02
[05/07 16:06:28] detectron2.evaluation.evaluator INFO: Inference done 129/2560. 0.1695 s / img. ETA=0:06:56
[05/07 16:06:33] detectron2.evaluation.evaluator INFO: Inference done 175/2560. 0.1526 s / img. ETA=0:06:08
[05/07 16:06:38] detectron2.evaluation.evaluator INFO: Inference done 215/2560. 0.1474 s / img. ETA=0:05:50
[05/07 16:06:43] detectron2.evaluation.evaluator INFO: Inference done 249/2560. 0.1472 s / img. ETA=0:05:44
[05/07 16:06:48] detectron2.evaluation.evaluator INFO: Inference done 282/2560. 0.1477 s / img. ETA=0:05:40
[05/07 16:06:53] detectron2.evaluation.evaluator INFO: Inference done 312/2560. 0.1501 s / img. ETA=0:05:41
[05/07 16:06:58] detectron2.evaluation.evaluator INFO: Inference done 345/2560. 0.1503 s / img. ETA=0:05:37
[05/07 16:07:03] detectron2.evaluation.evaluator INFO: Inference done 376/2560. 0.1514 s / img. ETA=0:05:34
[05/07 16:07:08] detectron2.evaluation.evaluator INFO: Inference done 409/2560. 0.1514 s / img. ETA=0:05:29
[05/07 16:07:13] detectron2.evaluation.evaluator INFO: Inference done 440/2560. 0.1523 s / img. ETA=0:05:26
[05/07 16:07:18] detectron2.evaluation.evaluator INFO: Inference done 472/2560. 0.1526 s / img. ETA=0:05:22
[05/07 16:07:23] detectron2.evaluation.evaluator INFO: Inference done 512/2560. 0.1505 s / img. ETA=0:05:11
[05/07 16:07:29] detectron2.evaluation.evaluator INFO: Inference done 543/2560. 0.1513 s / img. ETA=0:05:08
[05/07 16:07:34] detectron2.evaluation.evaluator INFO: Inference done 570/2560. 0.1530 s / img. ETA=0:05:08
[05/07 16:07:39] detectron2.evaluation.evaluator INFO: Inference done 596/2560. 0.1547 s / img. ETA=0:05:07
[05/07 16:07:44] detectron2.evaluation.evaluator INFO: Inference done 626/2560. 0.1554 s / img. ETA=0:05:03
[05/07 16:07:49] detectron2.evaluation.evaluator INFO: Inference done 654/2560. 0.1563 s / img. ETA=0:05:01
[05/07 16:07:54] detectron2.evaluation.evaluator INFO: Inference done 681/2560. 0.1576 s / img. ETA=0:04:59
[05/07 16:07:59] detectron2.evaluation.evaluator INFO: Inference done 709/2560. 0.1586 s / img. ETA=0:04:56
[05/07 16:08:04] detectron2.evaluation.evaluator INFO: Inference done 737/2560. 0.1596 s / img. ETA=0:04:54
[05/07 16:08:09] detectron2.evaluation.evaluator INFO: Inference done 764/2560. 0.1605 s / img. ETA=0:04:51
[05/07 16:08:14] detectron2.evaluation.evaluator INFO: Inference done 798/2560. 0.1599 s / img. ETA=0:04:44
[05/07 16:08:20] detectron2.evaluation.evaluator INFO: Inference done 834/2560. 0.1592 s / img. ETA=0:04:37
[05/07 16:08:25] detectron2.evaluation.evaluator INFO: Inference done 862/2560. 0.1599 s / img. ETA=0:04:34
[05/07 16:08:30] detectron2.evaluation.evaluator INFO: Inference done 893/2560. 0.1600 s / img. ETA=0:04:29
[05/07 16:08:35] detectron2.evaluation.evaluator INFO: Inference done 919/2560. 0.1610 s / img. ETA=0:04:27
[05/07 16:08:40] detectron2.evaluation.evaluator INFO: Inference done 948/2560. 0.1614 s / img. ETA=0:04:23
[05/07 16:08:45] detectron2.evaluation.evaluator INFO: Inference done 978/2560. 0.1617 s / img. ETA=0:04:18
[05/07 16:08:50] detectron2.evaluation.evaluator INFO: Inference done 1011/2560. 0.1613 s / img. ETA=0:04:12
[05/07 16:08:55] detectron2.evaluation.evaluator INFO: Inference done 1047/2560. 0.1606 s / img. ETA=0:04:05
[05/07 16:09:01] detectron2.evaluation.evaluator INFO: Inference done 1084/2560. 0.1597 s / img. ETA=0:03:58
[05/07 16:09:06] detectron2.evaluation.evaluator INFO: Inference done 1122/2560. 0.1587 s / img. ETA=0:03:50
[05/07 16:09:11] detectron2.evaluation.evaluator INFO: Inference done 1150/2560. 0.1592 s / img. ETA=0:03:46
[05/07 16:09:16] detectron2.evaluation.evaluator INFO: Inference done 1177/2560. 0.1598 s / img. ETA=0:03:43
[05/07 16:09:21] detectron2.evaluation.evaluator INFO: Inference done 1215/2560. 0.1590 s / img. ETA=0:03:36
[05/07 16:09:26] detectron2.evaluation.evaluator INFO: Inference done 1256/2560. 0.1577 s / img. ETA=0:03:28
[05/07 16:09:31] detectron2.evaluation.evaluator INFO: Inference done 1286/2560. 0.1579 s / img. ETA=0:03:23
[05/07 16:09:36] detectron2.evaluation.evaluator INFO: Inference done 1327/2560. 0.1568 s / img. ETA=0:03:15
[05/07 16:09:41] detectron2.evaluation.evaluator INFO: Inference done 1357/2560. 0.1571 s / img. ETA=0:03:11
[05/07 16:09:46] detectron2.evaluation.evaluator INFO: Inference done 1395/2560. 0.1564 s / img. ETA=0:03:04
[05/07 16:09:51] detectron2.evaluation.evaluator INFO: Inference done 1435/2560. 0.1555 s / img. ETA=0:02:56
[05/07 16:09:56] detectron2.evaluation.evaluator INFO: Inference done 1480/2560. 0.1541 s / img. ETA=0:02:48
[05/07 16:10:01] detectron2.evaluation.evaluator INFO: Inference done 1516/2560. 0.1537 s / img. ETA=0:02:42
[05/07 16:10:06] detectron2.evaluation.evaluator INFO: Inference done 1556/2560. 0.1530 s / img. ETA=0:02:35
[05/07 16:10:11] detectron2.evaluation.evaluator INFO: Inference done 1591/2560. 0.1527 s / img. ETA=0:02:29
[05/07 16:10:16] detectron2.evaluation.evaluator INFO: Inference done 1635/2560. 0.1516 s / img. ETA=0:02:21
[05/07 16:10:21] detectron2.evaluation.evaluator INFO: Inference done 1663/2560. 0.1521 s / img. ETA=0:02:18
[05/07 16:10:27] detectron2.evaluation.evaluator INFO: Inference done 1690/2560. 0.1527 s / img. ETA=0:02:14
[05/07 16:10:32] detectron2.evaluation.evaluator INFO: Inference done 1721/2560. 0.1529 s / img. ETA=0:02:09
[05/07 16:10:37] detectron2.evaluation.evaluator INFO: Inference done 1750/2560. 0.1532 s / img. ETA=0:02:05
[05/07 16:10:42] detectron2.evaluation.evaluator INFO: Inference done 1784/2560. 0.1530 s / img. ETA=0:02:00
[05/07 16:10:47] detectron2.evaluation.evaluator INFO: Inference done 1822/2560. 0.1526 s / img. ETA=0:01:53
[05/07 16:10:52] detectron2.evaluation.evaluator INFO: Inference done 1859/2560. 0.1523 s / img. ETA=0:01:48
[05/07 16:10:57] detectron2.evaluation.evaluator INFO: Inference done 1896/2560. 0.1519 s / img. ETA=0:01:42
[05/07 16:11:02] detectron2.evaluation.evaluator INFO: Inference done 1937/2560. 0.1513 s / img. ETA=0:01:35
[05/07 16:11:07] detectron2.evaluation.evaluator INFO: Inference done 1970/2560. 0.1513 s / img. ETA=0:01:30
[05/07 16:11:12] detectron2.evaluation.evaluator INFO: Inference done 1997/2560. 0.1517 s / img. ETA=0:01:26
[05/07 16:11:17] detectron2.evaluation.evaluator INFO: Inference done 2027/2560. 0.1520 s / img. ETA=0:01:21
[05/07 16:11:22] detectron2.evaluation.evaluator INFO: Inference done 2054/2560. 0.1524 s / img. ETA=0:01:18
[05/07 16:11:27] detectron2.evaluation.evaluator INFO: Inference done 2084/2560. 0.1526 s / img. ETA=0:01:13
[05/07 16:11:32] detectron2.evaluation.evaluator INFO: Inference done 2115/2560. 0.1528 s / img. ETA=0:01:08
[05/07 16:11:37] detectron2.evaluation.evaluator INFO: Inference done 2151/2560. 0.1525 s / img. ETA=0:01:03
[05/07 16:11:43] detectron2.evaluation.evaluator INFO: Inference done 2189/2560. 0.1522 s / img. ETA=0:00:57
[05/07 16:11:48] detectron2.evaluation.evaluator INFO: Inference done 2222/2560. 0.1522 s / img. ETA=0:00:52
[05/07 16:11:53] detectron2.evaluation.evaluator INFO: Inference done 2255/2560. 0.1522 s / img. ETA=0:00:46
[05/07 16:11:58] detectron2.evaluation.evaluator INFO: Inference done 2290/2560. 0.1520 s / img. ETA=0:00:41
[05/07 16:12:03] detectron2.evaluation.evaluator INFO: Inference done 2330/2560. 0.1516 s / img. ETA=0:00:35
[05/07 16:12:08] detectron2.evaluation.evaluator INFO: Inference done 2362/2560. 0.1516 s / img. ETA=0:00:30
[05/07 16:12:13] detectron2.evaluation.evaluator INFO: Inference done 2388/2560. 0.1521 s / img. ETA=0:00:26
[05/07 16:12:18] detectron2.evaluation.evaluator INFO: Inference done 2418/2560. 0.1523 s / img. ETA=0:00:21
[05/07 16:12:23] detectron2.evaluation.evaluator INFO: Inference done 2450/2560. 0.1523 s / img. ETA=0:00:16
[05/07 16:12:28] detectron2.evaluation.evaluator INFO: Inference done 2489/2560. 0.1519 s / img. ETA=0:00:10
[05/07 16:12:33] detectron2.evaluation.evaluator INFO: Inference done 2526/2560. 0.1517 s / img. ETA=0:00:05
[05/07 16:12:38] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:31.622129 (0.153277 s / img per device, on 4 devices)
[05/07 16:12:38] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:26 (0.151306 s / img per device, on 4 devices)
[05/07 17:04:24] detectron2 INFO: Rank of current process: 3. World size: 4
[05/07 17:04:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/07 17:04:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/07 17:04:25] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/07 17:04:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/07 17:04:25] detectron2.utils.env INFO: Using a generated random seed 25378097
[05/07 17:04:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/07 17:04:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/07 17:04:26] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/07 17:04:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/07 17:04:27] detectron2.data.build INFO: Known classes: range(0, 80)
[05/07 17:04:27] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/07 17:04:28] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/07 17:04:28] detectron2.data.build INFO: Number of datapoints: 10246
[05/07 17:04:28] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/07 17:04:28] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/07 17:04:28] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/07 17:04:28] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/07 17:04:28] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/07 17:04:37] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1720 s / img. ETA=0:07:22
[05/07 17:04:42] detectron2.evaluation.evaluator INFO: Inference done 40/2560. 0.1717 s / img. ETA=0:07:17
[05/07 17:04:47] detectron2.evaluation.evaluator INFO: Inference done 70/2560. 0.1701 s / img. ETA=0:07:08
[05/07 17:04:52] detectron2.evaluation.evaluator INFO: Inference done 100/2560. 0.1703 s / img. ETA=0:07:03
[05/07 17:04:57] detectron2.evaluation.evaluator INFO: Inference done 130/2560. 0.1692 s / img. ETA=0:06:55
[05/07 17:05:03] detectron2.evaluation.evaluator INFO: Inference done 176/2560. 0.1532 s / img. ETA=0:06:09
[05/07 17:05:08] detectron2.evaluation.evaluator INFO: Inference done 217/2560. 0.1477 s / img. ETA=0:05:50
[05/07 17:05:13] detectron2.evaluation.evaluator INFO: Inference done 252/2560. 0.1470 s / img. ETA=0:05:43
[05/07 17:05:18] detectron2.evaluation.evaluator INFO: Inference done 284/2560. 0.1485 s / img. ETA=0:05:42
[05/07 17:05:23] detectron2.evaluation.evaluator INFO: Inference done 314/2560. 0.1508 s / img. ETA=0:05:43
[05/07 17:05:28] detectron2.evaluation.evaluator INFO: Inference done 348/2560. 0.1509 s / img. ETA=0:05:37
[05/07 17:05:34] detectron2.evaluation.evaluator INFO: Inference done 380/2560. 0.1517 s / img. ETA=0:05:34
[05/07 17:05:39] detectron2.evaluation.evaluator INFO: Inference done 412/2560. 0.1520 s / img. ETA=0:05:30
[05/07 17:05:44] detectron2.evaluation.evaluator INFO: Inference done 444/2560. 0.1522 s / img. ETA=0:05:26
[05/07 17:05:49] detectron2.evaluation.evaluator INFO: Inference done 474/2560. 0.1531 s / img. ETA=0:05:23
[05/07 17:05:54] detectron2.evaluation.evaluator INFO: Inference done 514/2560. 0.1509 s / img. ETA=0:05:12
[05/07 17:05:59] detectron2.evaluation.evaluator INFO: Inference done 545/2560. 0.1517 s / img. ETA=0:05:09
[05/07 17:06:04] detectron2.evaluation.evaluator INFO: Inference done 573/2560. 0.1533 s / img. ETA=0:05:08
[05/07 17:06:09] detectron2.evaluation.evaluator INFO: Inference done 599/2560. 0.1551 s / img. ETA=0:05:07
[05/07 17:06:14] detectron2.evaluation.evaluator INFO: Inference done 629/2560. 0.1558 s / img. ETA=0:05:04
[05/07 17:06:19] detectron2.evaluation.evaluator INFO: Inference done 657/2560. 0.1567 s / img. ETA=0:05:01
[05/07 17:06:25] detectron2.evaluation.evaluator INFO: Inference done 684/2560. 0.1581 s / img. ETA=0:04:59
[05/07 17:06:30] detectron2.evaluation.evaluator INFO: Inference done 713/2560. 0.1588 s / img. ETA=0:04:56
[05/07 17:06:35] detectron2.evaluation.evaluator INFO: Inference done 740/2560. 0.1598 s / img. ETA=0:04:54
[05/07 17:06:40] detectron2.evaluation.evaluator INFO: Inference done 769/2560. 0.1602 s / img. ETA=0:04:50
[05/07 17:06:45] detectron2.evaluation.evaluator INFO: Inference done 801/2560. 0.1600 s / img. ETA=0:04:44
[05/07 17:06:50] detectron2.evaluation.evaluator INFO: Inference done 836/2560. 0.1593 s / img. ETA=0:04:37
[05/07 17:06:55] detectron2.evaluation.evaluator INFO: Inference done 866/2560. 0.1596 s / img. ETA=0:04:33
[05/07 17:07:00] detectron2.evaluation.evaluator INFO: Inference done 895/2560. 0.1602 s / img. ETA=0:04:29
[05/07 17:07:05] detectron2.evaluation.evaluator INFO: Inference done 921/2560. 0.1612 s / img. ETA=0:04:27
[05/07 17:07:10] detectron2.evaluation.evaluator INFO: Inference done 950/2560. 0.1616 s / img. ETA=0:04:23
[05/07 17:07:16] detectron2.evaluation.evaluator INFO: Inference done 980/2560. 0.1618 s / img. ETA=0:04:18
[05/07 17:07:21] detectron2.evaluation.evaluator INFO: Inference done 1014/2560. 0.1614 s / img. ETA=0:04:12
[05/07 17:07:26] detectron2.evaluation.evaluator INFO: Inference done 1050/2560. 0.1606 s / img. ETA=0:04:05
[05/07 17:07:31] detectron2.evaluation.evaluator INFO: Inference done 1086/2560. 0.1598 s / img. ETA=0:03:58
[05/07 17:07:36] detectron2.evaluation.evaluator INFO: Inference done 1125/2560. 0.1588 s / img. ETA=0:03:50
[05/07 17:07:41] detectron2.evaluation.evaluator INFO: Inference done 1152/2560. 0.1594 s / img. ETA=0:03:47
[05/07 17:07:46] detectron2.evaluation.evaluator INFO: Inference done 1180/2560. 0.1599 s / img. ETA=0:03:43
[05/07 17:07:51] detectron2.evaluation.evaluator INFO: Inference done 1218/2560. 0.1591 s / img. ETA=0:03:36
[05/07 17:07:57] detectron2.evaluation.evaluator INFO: Inference done 1260/2560. 0.1579 s / img. ETA=0:03:27
[05/07 17:08:02] detectron2.evaluation.evaluator INFO: Inference done 1290/2560. 0.1581 s / img. ETA=0:03:23
[05/07 17:08:07] detectron2.evaluation.evaluator INFO: Inference done 1331/2560. 0.1571 s / img. ETA=0:03:15
[05/07 17:08:12] detectron2.evaluation.evaluator INFO: Inference done 1361/2560. 0.1573 s / img. ETA=0:03:10
[05/07 17:08:17] detectron2.evaluation.evaluator INFO: Inference done 1400/2560. 0.1565 s / img. ETA=0:03:03
[05/07 17:08:22] detectron2.evaluation.evaluator INFO: Inference done 1441/2560. 0.1555 s / img. ETA=0:02:56
[05/07 17:08:27] detectron2.evaluation.evaluator INFO: Inference done 1485/2560. 0.1543 s / img. ETA=0:02:47
[05/07 17:08:32] detectron2.evaluation.evaluator INFO: Inference done 1523/2560. 0.1537 s / img. ETA=0:02:41
[05/07 17:08:37] detectron2.evaluation.evaluator INFO: Inference done 1562/2560. 0.1531 s / img. ETA=0:02:34
[05/07 17:08:42] detectron2.evaluation.evaluator INFO: Inference done 1598/2560. 0.1528 s / img. ETA=0:02:28
[05/07 17:08:48] detectron2.evaluation.evaluator INFO: Inference done 1641/2560. 0.1519 s / img. ETA=0:02:21
[05/07 17:08:53] detectron2.evaluation.evaluator INFO: Inference done 1668/2560. 0.1524 s / img. ETA=0:02:17
[05/07 17:08:58] detectron2.evaluation.evaluator INFO: Inference done 1696/2560. 0.1529 s / img. ETA=0:02:13
[05/07 17:09:03] detectron2.evaluation.evaluator INFO: Inference done 1726/2560. 0.1531 s / img. ETA=0:02:09
[05/07 17:09:08] detectron2.evaluation.evaluator INFO: Inference done 1756/2560. 0.1533 s / img. ETA=0:02:04
[05/07 17:09:13] detectron2.evaluation.evaluator INFO: Inference done 1792/2560. 0.1530 s / img. ETA=0:01:58
[05/07 17:09:18] detectron2.evaluation.evaluator INFO: Inference done 1828/2560. 0.1528 s / img. ETA=0:01:53
[05/07 17:09:23] detectron2.evaluation.evaluator INFO: Inference done 1864/2560. 0.1525 s / img. ETA=0:01:47
[05/07 17:09:28] detectron2.evaluation.evaluator INFO: Inference done 1903/2560. 0.1520 s / img. ETA=0:01:41
[05/07 17:09:33] detectron2.evaluation.evaluator INFO: Inference done 1944/2560. 0.1514 s / img. ETA=0:01:34
[05/07 17:09:38] detectron2.evaluation.evaluator INFO: Inference done 1975/2560. 0.1516 s / img. ETA=0:01:29
[05/07 17:09:43] detectron2.evaluation.evaluator INFO: Inference done 2002/2560. 0.1520 s / img. ETA=0:01:25
[05/07 17:09:49] detectron2.evaluation.evaluator INFO: Inference done 2032/2560. 0.1523 s / img. ETA=0:01:21
[05/07 17:09:54] detectron2.evaluation.evaluator INFO: Inference done 2060/2560. 0.1527 s / img. ETA=0:01:17
[05/07 17:09:59] detectron2.evaluation.evaluator INFO: Inference done 2090/2560. 0.1528 s / img. ETA=0:01:12
[05/07 17:10:04] detectron2.evaluation.evaluator INFO: Inference done 2120/2560. 0.1530 s / img. ETA=0:01:08
[05/07 17:10:09] detectron2.evaluation.evaluator INFO: Inference done 2157/2560. 0.1527 s / img. ETA=0:01:02
[05/07 17:10:14] detectron2.evaluation.evaluator INFO: Inference done 2194/2560. 0.1524 s / img. ETA=0:00:56
[05/07 17:10:19] detectron2.evaluation.evaluator INFO: Inference done 2227/2560. 0.1524 s / img. ETA=0:00:51
[05/07 17:10:24] detectron2.evaluation.evaluator INFO: Inference done 2261/2560. 0.1524 s / img. ETA=0:00:46
[05/07 17:10:29] detectron2.evaluation.evaluator INFO: Inference done 2296/2560. 0.1522 s / img. ETA=0:00:40
[05/07 17:10:34] detectron2.evaluation.evaluator INFO: Inference done 2336/2560. 0.1518 s / img. ETA=0:00:34
[05/07 17:10:39] detectron2.evaluation.evaluator INFO: Inference done 2366/2560. 0.1520 s / img. ETA=0:00:29
[05/07 17:10:44] detectron2.evaluation.evaluator INFO: Inference done 2393/2560. 0.1524 s / img. ETA=0:00:25
[05/07 17:10:50] detectron2.evaluation.evaluator INFO: Inference done 2423/2560. 0.1526 s / img. ETA=0:00:21
[05/07 17:10:55] detectron2.evaluation.evaluator INFO: Inference done 2457/2560. 0.1526 s / img. ETA=0:00:15
[05/07 17:11:00] detectron2.evaluation.evaluator INFO: Inference done 2496/2560. 0.1522 s / img. ETA=0:00:09
[05/07 17:11:05] detectron2.evaluation.evaluator INFO: Inference done 2534/2560. 0.1518 s / img. ETA=0:00:03
[05/07 17:11:09] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:32.439771 (0.153597 s / img per device, on 4 devices)
[05/07 17:11:09] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:27 (0.151609 s / img per device, on 4 devices)
[05/08 08:50:10] detectron2 INFO: Rank of current process: 3. World size: 4
[05/08 08:50:11] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 08:50:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 08:50:11] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 10
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 08:50:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 10
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 08:50:11] detectron2.utils.env INFO: Using a generated random seed 11411403
[05/08 08:50:11] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 08:50:11] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 08:50:12] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 08:50:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 08:50:13] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 08:50:13] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 08:50:14] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 08:50:14] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 08:50:14] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 08:50:14] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 08:50:14] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 08:50:14] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 08:50:14] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/08 08:50:23] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1691 s / img. ETA=0:07:13
[05/08 08:50:28] detectron2.evaluation.evaluator INFO: Inference done 41/2560. 0.1714 s / img. ETA=0:07:15
[05/08 08:50:33] detectron2.evaluation.evaluator INFO: Inference done 71/2560. 0.1692 s / img. ETA=0:07:04
[05/08 08:50:38] detectron2.evaluation.evaluator INFO: Inference done 101/2560. 0.1687 s / img. ETA=0:06:58
[05/08 08:50:43] detectron2.evaluation.evaluator INFO: Inference done 132/2560. 0.1666 s / img. ETA=0:06:47
[05/08 08:50:48] detectron2.evaluation.evaluator INFO: Inference done 178/2560. 0.1513 s / img. ETA=0:06:03
[05/08 08:50:53] detectron2.evaluation.evaluator INFO: Inference done 218/2560. 0.1464 s / img. ETA=0:05:46
[05/08 08:50:59] detectron2.evaluation.evaluator INFO: Inference done 253/2560. 0.1462 s / img. ETA=0:05:40
[05/08 08:51:04] detectron2.evaluation.evaluator INFO: Inference done 285/2560. 0.1472 s / img. ETA=0:05:38
[05/08 08:51:09] detectron2.evaluation.evaluator INFO: Inference done 314/2560. 0.1497 s / img. ETA=0:05:39
[05/08 08:51:14] detectron2.evaluation.evaluator INFO: Inference done 348/2560. 0.1498 s / img. ETA=0:05:34
[05/08 08:51:19] detectron2.evaluation.evaluator INFO: Inference done 380/2560. 0.1507 s / img. ETA=0:05:31
[05/08 08:51:24] detectron2.evaluation.evaluator INFO: Inference done 413/2560. 0.1511 s / img. ETA=0:05:27
[05/08 08:51:29] detectron2.evaluation.evaluator INFO: Inference done 447/2560. 0.1509 s / img. ETA=0:05:21
[05/08 08:51:34] detectron2.evaluation.evaluator INFO: Inference done 476/2560. 0.1522 s / img. ETA=0:05:20
[05/08 08:51:40] detectron2.evaluation.evaluator INFO: Inference done 518/2560. 0.1497 s / img. ETA=0:05:08
[05/08 08:51:45] detectron2.evaluation.evaluator INFO: Inference done 547/2560. 0.1509 s / img. ETA=0:05:06
[05/08 08:51:50] detectron2.evaluation.evaluator INFO: Inference done 575/2560. 0.1522 s / img. ETA=0:05:05
[05/08 08:51:55] detectron2.evaluation.evaluator INFO: Inference done 601/2560. 0.1542 s / img. ETA=0:05:04
[05/08 08:52:00] detectron2.evaluation.evaluator INFO: Inference done 631/2560. 0.1550 s / img. ETA=0:05:01
[05/08 08:52:05] detectron2.evaluation.evaluator INFO: Inference done 660/2560. 0.1558 s / img. ETA=0:04:58
[05/08 08:52:10] detectron2.evaluation.evaluator INFO: Inference done 687/2560. 0.1570 s / img. ETA=0:04:56
[05/08 08:52:15] detectron2.evaluation.evaluator INFO: Inference done 717/2560. 0.1574 s / img. ETA=0:04:52
[05/08 08:52:20] detectron2.evaluation.evaluator INFO: Inference done 743/2560. 0.1587 s / img. ETA=0:04:51
[05/08 08:52:25] detectron2.evaluation.evaluator INFO: Inference done 773/2560. 0.1592 s / img. ETA=0:04:47
[05/08 08:52:30] detectron2.evaluation.evaluator INFO: Inference done 808/2560. 0.1585 s / img. ETA=0:04:40
[05/08 08:52:36] detectron2.evaluation.evaluator INFO: Inference done 840/2560. 0.1585 s / img. ETA=0:04:35
[05/08 08:52:41] detectron2.evaluation.evaluator INFO: Inference done 873/2560. 0.1583 s / img. ETA=0:04:29
[05/08 08:52:46] detectron2.evaluation.evaluator INFO: Inference done 901/2560. 0.1590 s / img. ETA=0:04:26
[05/08 08:52:51] detectron2.evaluation.evaluator INFO: Inference done 926/2560. 0.1603 s / img. ETA=0:04:24
[05/08 08:52:56] detectron2.evaluation.evaluator INFO: Inference done 955/2560. 0.1607 s / img. ETA=0:04:20
[05/08 08:53:01] detectron2.evaluation.evaluator INFO: Inference done 986/2560. 0.1607 s / img. ETA=0:04:15
[05/08 08:53:06] detectron2.evaluation.evaluator INFO: Inference done 1021/2560. 0.1602 s / img. ETA=0:04:08
[05/08 08:53:11] detectron2.evaluation.evaluator INFO: Inference done 1057/2560. 0.1594 s / img. ETA=0:04:01
[05/08 08:53:16] detectron2.evaluation.evaluator INFO: Inference done 1094/2560. 0.1586 s / img. ETA=0:03:54
[05/08 08:53:21] detectron2.evaluation.evaluator INFO: Inference done 1131/2560. 0.1579 s / img. ETA=0:03:47
[05/08 08:53:27] detectron2.evaluation.evaluator INFO: Inference done 1158/2560. 0.1587 s / img. ETA=0:03:44
[05/08 08:53:32] detectron2.evaluation.evaluator INFO: Inference done 1189/2560. 0.1588 s / img. ETA=0:03:39
[05/08 08:53:37] detectron2.evaluation.evaluator INFO: Inference done 1227/2560. 0.1579 s / img. ETA=0:03:32
[05/08 08:53:42] detectron2.evaluation.evaluator INFO: Inference done 1265/2560. 0.1572 s / img. ETA=0:03:25
[05/08 08:53:47] detectron2.evaluation.evaluator INFO: Inference done 1297/2560. 0.1571 s / img. ETA=0:03:20
[05/08 08:53:52] detectron2.evaluation.evaluator INFO: Inference done 1336/2560. 0.1563 s / img. ETA=0:03:13
[05/08 08:53:57] detectron2.evaluation.evaluator INFO: Inference done 1368/2560. 0.1563 s / img. ETA=0:03:08
[05/08 08:54:02] detectron2.evaluation.evaluator INFO: Inference done 1407/2560. 0.1556 s / img. ETA=0:03:01
[05/08 08:54:07] detectron2.evaluation.evaluator INFO: Inference done 1450/2560. 0.1544 s / img. ETA=0:02:53
[05/08 08:54:12] detectron2.evaluation.evaluator INFO: Inference done 1492/2560. 0.1534 s / img. ETA=0:02:45
[05/08 08:54:17] detectron2.evaluation.evaluator INFO: Inference done 1531/2560. 0.1528 s / img. ETA=0:02:38
[05/08 08:54:23] detectron2.evaluation.evaluator INFO: Inference done 1570/2560. 0.1522 s / img. ETA=0:02:32
[05/08 08:54:28] detectron2.evaluation.evaluator INFO: Inference done 1608/2560. 0.1517 s / img. ETA=0:02:25
[05/08 08:54:33] detectron2.evaluation.evaluator INFO: Inference done 1647/2560. 0.1512 s / img. ETA=0:02:19
[05/08 08:54:38] detectron2.evaluation.evaluator INFO: Inference done 1674/2560. 0.1519 s / img. ETA=0:02:15
[05/08 08:54:43] detectron2.evaluation.evaluator INFO: Inference done 1704/2560. 0.1522 s / img. ETA=0:02:11
[05/08 08:54:48] detectron2.evaluation.evaluator INFO: Inference done 1733/2560. 0.1526 s / img. ETA=0:02:07
[05/08 08:54:53] detectron2.evaluation.evaluator INFO: Inference done 1766/2560. 0.1526 s / img. ETA=0:02:02
[05/08 08:54:58] detectron2.evaluation.evaluator INFO: Inference done 1803/2560. 0.1522 s / img. ETA=0:01:56
[05/08 08:55:03] detectron2.evaluation.evaluator INFO: Inference done 1838/2560. 0.1521 s / img. ETA=0:01:50
[05/08 08:55:08] detectron2.evaluation.evaluator INFO: Inference done 1874/2560. 0.1518 s / img. ETA=0:01:45
[05/08 08:55:14] detectron2.evaluation.evaluator INFO: Inference done 1915/2560. 0.1512 s / img. ETA=0:01:38
[05/08 08:55:19] detectron2.evaluation.evaluator INFO: Inference done 1955/2560. 0.1507 s / img. ETA=0:01:32
[05/08 08:55:24] detectron2.evaluation.evaluator INFO: Inference done 1982/2560. 0.1511 s / img. ETA=0:01:28
[05/08 08:55:29] detectron2.evaluation.evaluator INFO: Inference done 2010/2560. 0.1515 s / img. ETA=0:01:24
[05/08 08:55:34] detectron2.evaluation.evaluator INFO: Inference done 2040/2560. 0.1517 s / img. ETA=0:01:19
[05/08 08:55:39] detectron2.evaluation.evaluator INFO: Inference done 2070/2560. 0.1519 s / img. ETA=0:01:15
[05/08 08:55:44] detectron2.evaluation.evaluator INFO: Inference done 2098/2560. 0.1523 s / img. ETA=0:01:11
[05/08 08:55:49] detectron2.evaluation.evaluator INFO: Inference done 2130/2560. 0.1524 s / img. ETA=0:01:06
[05/08 08:55:54] detectron2.evaluation.evaluator INFO: Inference done 2170/2560. 0.1519 s / img. ETA=0:00:59
[05/08 08:55:59] detectron2.evaluation.evaluator INFO: Inference done 2205/2560. 0.1517 s / img. ETA=0:00:54
[05/08 08:56:04] detectron2.evaluation.evaluator INFO: Inference done 2237/2560. 0.1518 s / img. ETA=0:00:49
[05/08 08:56:09] detectron2.evaluation.evaluator INFO: Inference done 2270/2560. 0.1518 s / img. ETA=0:00:44
[05/08 08:56:14] detectron2.evaluation.evaluator INFO: Inference done 2308/2560. 0.1515 s / img. ETA=0:00:38
[05/08 08:56:19] detectron2.evaluation.evaluator INFO: Inference done 2348/2560. 0.1510 s / img. ETA=0:00:32
[05/08 08:56:25] detectron2.evaluation.evaluator INFO: Inference done 2375/2560. 0.1515 s / img. ETA=0:00:28
[05/08 08:56:30] detectron2.evaluation.evaluator INFO: Inference done 2403/2560. 0.1519 s / img. ETA=0:00:24
[05/08 08:56:35] detectron2.evaluation.evaluator INFO: Inference done 2435/2560. 0.1520 s / img. ETA=0:00:19
[05/08 08:56:40] detectron2.evaluation.evaluator INFO: Inference done 2470/2560. 0.1518 s / img. ETA=0:00:13
[05/08 08:56:45] detectron2.evaluation.evaluator INFO: Inference done 2511/2560. 0.1514 s / img. ETA=0:00:07
[05/08 08:56:50] detectron2.evaluation.evaluator INFO: Inference done 2552/2560. 0.1509 s / img. ETA=0:00:01
[05/08 08:56:52] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:29.568246 (0.152473 s / img per device, on 4 devices)
[05/08 08:56:52] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:25 (0.150860 s / img per device, on 4 devices)
[05/08 09:08:03] detectron2 INFO: Rank of current process: 3. World size: 4
[05/08 09:08:04] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:08:04] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:08:04] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
TEST:
  DETECTIONS_PER_IMAGE: 200
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:08:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:08:04] detectron2.utils.env INFO: Using a generated random seed 4703379
[05/08 09:08:05] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:08:05] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:08:05] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:08:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:08:07] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:08:07] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:08:07] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:08:07] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:08:07] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:08:07] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:08:07] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:08:07] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:08:07] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/08 09:08:16] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1713 s / img. ETA=0:07:20
[05/08 09:08:21] detectron2.evaluation.evaluator INFO: Inference done 40/2560. 0.1712 s / img. ETA=0:07:16
[05/08 09:08:26] detectron2.evaluation.evaluator INFO: Inference done 70/2560. 0.1695 s / img. ETA=0:07:07
[05/08 09:08:32] detectron2.evaluation.evaluator INFO: Inference done 100/2560. 0.1697 s / img. ETA=0:07:02
[05/08 09:08:37] detectron2.evaluation.evaluator INFO: Inference done 130/2560. 0.1687 s / img. ETA=0:06:55
[05/08 09:08:42] detectron2.evaluation.evaluator INFO: Inference done 176/2560. 0.1528 s / img. ETA=0:06:09
[05/08 09:08:47] detectron2.evaluation.evaluator INFO: Inference done 216/2560. 0.1472 s / img. ETA=0:05:49
[05/08 09:08:52] detectron2.evaluation.evaluator INFO: Inference done 250/2560. 0.1472 s / img. ETA=0:05:44
[05/08 09:08:57] detectron2.evaluation.evaluator INFO: Inference done 283/2560. 0.1480 s / img. ETA=0:05:41
[05/08 09:09:02] detectron2.evaluation.evaluator INFO: Inference done 312/2560. 0.1502 s / img. ETA=0:05:42
[05/08 09:09:07] detectron2.evaluation.evaluator INFO: Inference done 345/2560. 0.1503 s / img. ETA=0:05:37
[05/08 09:09:12] detectron2.evaluation.evaluator INFO: Inference done 376/2560. 0.1514 s / img. ETA=0:05:35
[05/08 09:09:17] detectron2.evaluation.evaluator INFO: Inference done 409/2560. 0.1514 s / img. ETA=0:05:30
[05/08 09:09:22] detectron2.evaluation.evaluator INFO: Inference done 440/2560. 0.1523 s / img. ETA=0:05:27
[05/08 09:09:27] detectron2.evaluation.evaluator INFO: Inference done 472/2560. 0.1526 s / img. ETA=0:05:22
[05/08 09:09:33] detectron2.evaluation.evaluator INFO: Inference done 512/2560. 0.1505 s / img. ETA=0:05:12
[05/08 09:09:38] detectron2.evaluation.evaluator INFO: Inference done 543/2560. 0.1513 s / img. ETA=0:05:09
[05/08 09:09:43] detectron2.evaluation.evaluator INFO: Inference done 570/2560. 0.1531 s / img. ETA=0:05:08
[05/08 09:09:48] detectron2.evaluation.evaluator INFO: Inference done 596/2560. 0.1547 s / img. ETA=0:05:07
[05/08 09:09:53] detectron2.evaluation.evaluator INFO: Inference done 626/2560. 0.1553 s / img. ETA=0:05:04
[05/08 09:09:58] detectron2.evaluation.evaluator INFO: Inference done 655/2560. 0.1563 s / img. ETA=0:05:01
[05/08 09:10:03] detectron2.evaluation.evaluator INFO: Inference done 682/2560. 0.1576 s / img. ETA=0:04:59
[05/08 09:10:08] detectron2.evaluation.evaluator INFO: Inference done 710/2560. 0.1584 s / img. ETA=0:04:56
[05/08 09:10:13] detectron2.evaluation.evaluator INFO: Inference done 737/2560. 0.1593 s / img. ETA=0:04:54
[05/08 09:10:18] detectron2.evaluation.evaluator INFO: Inference done 764/2560. 0.1602 s / img. ETA=0:04:51
[05/08 09:10:23] detectron2.evaluation.evaluator INFO: Inference done 798/2560. 0.1596 s / img. ETA=0:04:44
[05/08 09:10:28] detectron2.evaluation.evaluator INFO: Inference done 833/2560. 0.1588 s / img. ETA=0:04:37
[05/08 09:10:33] detectron2.evaluation.evaluator INFO: Inference done 859/2560. 0.1599 s / img. ETA=0:04:35
[05/08 09:10:39] detectron2.evaluation.evaluator INFO: Inference done 891/2560. 0.1597 s / img. ETA=0:04:30
[05/08 09:10:44] detectron2.evaluation.evaluator INFO: Inference done 917/2560. 0.1608 s / img. ETA=0:04:27
[05/08 09:10:49] detectron2.evaluation.evaluator INFO: Inference done 945/2560. 0.1612 s / img. ETA=0:04:23
[05/08 09:10:54] detectron2.evaluation.evaluator INFO: Inference done 975/2560. 0.1615 s / img. ETA=0:04:19
[05/08 09:10:59] detectron2.evaluation.evaluator INFO: Inference done 1008/2560. 0.1612 s / img. ETA=0:04:13
[05/08 09:11:04] detectron2.evaluation.evaluator INFO: Inference done 1044/2560. 0.1604 s / img. ETA=0:04:06
[05/08 09:11:09] detectron2.evaluation.evaluator INFO: Inference done 1080/2560. 0.1597 s / img. ETA=0:03:59
[05/08 09:11:14] detectron2.evaluation.evaluator INFO: Inference done 1118/2560. 0.1588 s / img. ETA=0:03:51
[05/08 09:11:19] detectron2.evaluation.evaluator INFO: Inference done 1147/2560. 0.1591 s / img. ETA=0:03:47
[05/08 09:11:24] detectron2.evaluation.evaluator INFO: Inference done 1175/2560. 0.1595 s / img. ETA=0:03:43
[05/08 09:11:29] detectron2.evaluation.evaluator INFO: Inference done 1211/2560. 0.1589 s / img. ETA=0:03:37
[05/08 09:11:34] detectron2.evaluation.evaluator INFO: Inference done 1251/2560. 0.1578 s / img. ETA=0:03:29
[05/08 09:11:40] detectron2.evaluation.evaluator INFO: Inference done 1282/2560. 0.1579 s / img. ETA=0:03:24
[05/08 09:11:45] detectron2.evaluation.evaluator INFO: Inference done 1322/2560. 0.1569 s / img. ETA=0:03:16
[05/08 09:11:50] detectron2.evaluation.evaluator INFO: Inference done 1352/2560. 0.1571 s / img. ETA=0:03:12
[05/08 09:11:55] detectron2.evaluation.evaluator INFO: Inference done 1391/2560. 0.1563 s / img. ETA=0:03:05
[05/08 09:12:00] detectron2.evaluation.evaluator INFO: Inference done 1429/2560. 0.1557 s / img. ETA=0:02:58
[05/08 09:12:05] detectron2.evaluation.evaluator INFO: Inference done 1474/2560. 0.1543 s / img. ETA=0:02:49
[05/08 09:12:10] detectron2.evaluation.evaluator INFO: Inference done 1512/2560. 0.1538 s / img. ETA=0:02:43
[05/08 09:12:15] detectron2.evaluation.evaluator INFO: Inference done 1551/2560. 0.1532 s / img. ETA=0:02:36
[05/08 09:12:20] detectron2.evaluation.evaluator INFO: Inference done 1586/2560. 0.1529 s / img. ETA=0:02:30
[05/08 09:12:25] detectron2.evaluation.evaluator INFO: Inference done 1631/2560. 0.1517 s / img. ETA=0:02:22
[05/08 09:12:30] detectron2.evaluation.evaluator INFO: Inference done 1659/2560. 0.1522 s / img. ETA=0:02:18
[05/08 09:12:35] detectron2.evaluation.evaluator INFO: Inference done 1686/2560. 0.1527 s / img. ETA=0:02:15
[05/08 09:12:40] detectron2.evaluation.evaluator INFO: Inference done 1717/2560. 0.1528 s / img. ETA=0:02:10
[05/08 09:12:46] detectron2.evaluation.evaluator INFO: Inference done 1745/2560. 0.1533 s / img. ETA=0:02:06
[05/08 09:12:51] detectron2.evaluation.evaluator INFO: Inference done 1781/2560. 0.1531 s / img. ETA=0:02:00
[05/08 09:12:56] detectron2.evaluation.evaluator INFO: Inference done 1818/2560. 0.1527 s / img. ETA=0:01:54
[05/08 09:13:01] detectron2.evaluation.evaluator INFO: Inference done 1855/2560. 0.1523 s / img. ETA=0:01:48
[05/08 09:13:06] detectron2.evaluation.evaluator INFO: Inference done 1891/2560. 0.1520 s / img. ETA=0:01:43
[05/08 09:13:11] detectron2.evaluation.evaluator INFO: Inference done 1929/2560. 0.1516 s / img. ETA=0:01:36
[05/08 09:13:16] detectron2.evaluation.evaluator INFO: Inference done 1966/2560. 0.1513 s / img. ETA=0:01:31
[05/08 09:13:21] detectron2.evaluation.evaluator INFO: Inference done 1992/2560. 0.1518 s / img. ETA=0:01:27
[05/08 09:13:26] detectron2.evaluation.evaluator INFO: Inference done 2020/2560. 0.1522 s / img. ETA=0:01:23
[05/08 09:13:31] detectron2.evaluation.evaluator INFO: Inference done 2049/2560. 0.1524 s / img. ETA=0:01:18
[05/08 09:13:36] detectron2.evaluation.evaluator INFO: Inference done 2079/2560. 0.1526 s / img. ETA=0:01:14
[05/08 09:13:41] detectron2.evaluation.evaluator INFO: Inference done 2107/2560. 0.1530 s / img. ETA=0:01:10
[05/08 09:13:46] detectron2.evaluation.evaluator INFO: Inference done 2145/2560. 0.1526 s / img. ETA=0:01:04
[05/08 09:13:51] detectron2.evaluation.evaluator INFO: Inference done 2181/2560. 0.1524 s / img. ETA=0:00:58
[05/08 09:13:56] detectron2.evaluation.evaluator INFO: Inference done 2216/2560. 0.1522 s / img. ETA=0:00:53
[05/08 09:14:01] detectron2.evaluation.evaluator INFO: Inference done 2247/2560. 0.1523 s / img. ETA=0:00:48
[05/08 09:14:06] detectron2.evaluation.evaluator INFO: Inference done 2280/2560. 0.1523 s / img. ETA=0:00:43
[05/08 09:14:11] detectron2.evaluation.evaluator INFO: Inference done 2320/2560. 0.1518 s / img. ETA=0:00:36
[05/08 09:14:17] detectron2.evaluation.evaluator INFO: Inference done 2355/2560. 0.1517 s / img. ETA=0:00:31
[05/08 09:14:22] detectron2.evaluation.evaluator INFO: Inference done 2382/2560. 0.1522 s / img. ETA=0:00:27
[05/08 09:14:27] detectron2.evaluation.evaluator INFO: Inference done 2411/2560. 0.1524 s / img. ETA=0:00:23
[05/08 09:14:32] detectron2.evaluation.evaluator INFO: Inference done 2444/2560. 0.1524 s / img. ETA=0:00:17
[05/08 09:14:37] detectron2.evaluation.evaluator INFO: Inference done 2480/2560. 0.1522 s / img. ETA=0:00:12
[05/08 09:14:42] detectron2.evaluation.evaluator INFO: Inference done 2519/2560. 0.1518 s / img. ETA=0:00:06
[05/08 09:14:47] detectron2.evaluation.evaluator INFO: Inference done 2559/2560. 0.1514 s / img. ETA=0:00:00
[05/08 09:14:48] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:32.534136 (0.153634 s / img per device, on 4 devices)
[05/08 09:14:48] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:26 (0.151410 s / img per device, on 4 devices)
[05/08 09:23:00] detectron2 INFO: Rank of current process: 3. World size: 4
[05/08 09:23:01] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:23:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:23:01] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:23:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.3
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:23:01] detectron2.utils.env INFO: Using a generated random seed 1787881
[05/08 09:23:02] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:23:02] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:23:02] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:23:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:23:04] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:23:04] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:23:04] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:23:04] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:23:04] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:23:04] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:23:04] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:23:04] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:23:04] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/08 09:23:13] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1715 s / img. ETA=0:07:20
[05/08 09:23:18] detectron2.evaluation.evaluator INFO: Inference done 40/2560. 0.1710 s / img. ETA=0:07:14
[05/08 09:23:23] detectron2.evaluation.evaluator INFO: Inference done 70/2560. 0.1692 s / img. ETA=0:07:05
[05/08 09:23:29] detectron2.evaluation.evaluator INFO: Inference done 100/2560. 0.1693 s / img. ETA=0:07:00
[05/08 09:23:34] detectron2.evaluation.evaluator INFO: Inference done 130/2560. 0.1684 s / img. ETA=0:06:53
[05/08 09:23:39] detectron2.evaluation.evaluator INFO: Inference done 176/2560. 0.1525 s / img. ETA=0:06:07
[05/08 09:23:44] detectron2.evaluation.evaluator INFO: Inference done 217/2560. 0.1471 s / img. ETA=0:05:48
[05/08 09:23:49] detectron2.evaluation.evaluator INFO: Inference done 252/2560. 0.1465 s / img. ETA=0:05:42
[05/08 09:23:54] detectron2.evaluation.evaluator INFO: Inference done 284/2560. 0.1479 s / img. ETA=0:05:40
[05/08 09:23:59] detectron2.evaluation.evaluator INFO: Inference done 314/2560. 0.1502 s / img. ETA=0:05:41
[05/08 09:24:04] detectron2.evaluation.evaluator INFO: Inference done 348/2560. 0.1503 s / img. ETA=0:05:36
[05/08 09:24:10] detectron2.evaluation.evaluator INFO: Inference done 380/2560. 0.1512 s / img. ETA=0:05:33
[05/08 09:24:15] detectron2.evaluation.evaluator INFO: Inference done 412/2560. 0.1515 s / img. ETA=0:05:29
[05/08 09:24:20] detectron2.evaluation.evaluator INFO: Inference done 444/2560. 0.1517 s / img. ETA=0:05:24
[05/08 09:24:25] detectron2.evaluation.evaluator INFO: Inference done 474/2560. 0.1526 s / img. ETA=0:05:21
[05/08 09:24:30] detectron2.evaluation.evaluator INFO: Inference done 514/2560. 0.1504 s / img. ETA=0:05:11
[05/08 09:24:35] detectron2.evaluation.evaluator INFO: Inference done 545/2560. 0.1512 s / img. ETA=0:05:08
[05/08 09:24:40] detectron2.evaluation.evaluator INFO: Inference done 573/2560. 0.1527 s / img. ETA=0:05:07
[05/08 09:24:45] detectron2.evaluation.evaluator INFO: Inference done 599/2560. 0.1546 s / img. ETA=0:05:06
[05/08 09:24:50] detectron2.evaluation.evaluator INFO: Inference done 629/2560. 0.1552 s / img. ETA=0:05:03
[05/08 09:24:55] detectron2.evaluation.evaluator INFO: Inference done 658/2560. 0.1561 s / img. ETA=0:05:00
[05/08 09:25:01] detectron2.evaluation.evaluator INFO: Inference done 685/2560. 0.1574 s / img. ETA=0:04:58
[05/08 09:25:06] detectron2.evaluation.evaluator INFO: Inference done 715/2560. 0.1580 s / img. ETA=0:04:54
[05/08 09:25:11] detectron2.evaluation.evaluator INFO: Inference done 742/2560. 0.1590 s / img. ETA=0:04:52
[05/08 09:25:16] detectron2.evaluation.evaluator INFO: Inference done 772/2560. 0.1593 s / img. ETA=0:04:48
[05/08 09:25:21] detectron2.evaluation.evaluator INFO: Inference done 805/2560. 0.1590 s / img. ETA=0:04:42
[05/08 09:25:26] detectron2.evaluation.evaluator INFO: Inference done 839/2560. 0.1587 s / img. ETA=0:04:36
[05/08 09:25:31] detectron2.evaluation.evaluator INFO: Inference done 871/2560. 0.1586 s / img. ETA=0:04:30
[05/08 09:25:36] detectron2.evaluation.evaluator INFO: Inference done 899/2560. 0.1593 s / img. ETA=0:04:27
[05/08 09:25:41] detectron2.evaluation.evaluator INFO: Inference done 924/2560. 0.1604 s / img. ETA=0:04:25
[05/08 09:25:47] detectron2.evaluation.evaluator INFO: Inference done 953/2560. 0.1609 s / img. ETA=0:04:21
[05/08 09:25:52] detectron2.evaluation.evaluator INFO: Inference done 983/2560. 0.1610 s / img. ETA=0:04:16
[05/08 09:25:57] detectron2.evaluation.evaluator INFO: Inference done 1018/2560. 0.1604 s / img. ETA=0:04:10
[05/08 09:26:02] detectron2.evaluation.evaluator INFO: Inference done 1054/2560. 0.1597 s / img. ETA=0:04:03
[05/08 09:26:07] detectron2.evaluation.evaluator INFO: Inference done 1092/2560. 0.1588 s / img. ETA=0:03:55
[05/08 09:26:12] detectron2.evaluation.evaluator INFO: Inference done 1129/2560. 0.1580 s / img. ETA=0:03:48
[05/08 09:26:17] detectron2.evaluation.evaluator INFO: Inference done 1155/2560. 0.1588 s / img. ETA=0:03:45
[05/08 09:26:22] detectron2.evaluation.evaluator INFO: Inference done 1185/2560. 0.1590 s / img. ETA=0:03:41
[05/08 09:26:27] detectron2.evaluation.evaluator INFO: Inference done 1223/2560. 0.1583 s / img. ETA=0:03:34
[05/08 09:26:32] detectron2.evaluation.evaluator INFO: Inference done 1263/2560. 0.1573 s / img. ETA=0:03:26
[05/08 09:26:38] detectron2.evaluation.evaluator INFO: Inference done 1295/2560. 0.1573 s / img. ETA=0:03:21
[05/08 09:26:43] detectron2.evaluation.evaluator INFO: Inference done 1334/2560. 0.1564 s / img. ETA=0:03:13
[05/08 09:26:48] detectron2.evaluation.evaluator INFO: Inference done 1366/2560. 0.1564 s / img. ETA=0:03:08
[05/08 09:26:53] detectron2.evaluation.evaluator INFO: Inference done 1405/2560. 0.1556 s / img. ETA=0:03:01
[05/08 09:26:58] detectron2.evaluation.evaluator INFO: Inference done 1446/2560. 0.1546 s / img. ETA=0:02:54
[05/08 09:27:03] detectron2.evaluation.evaluator INFO: Inference done 1488/2560. 0.1536 s / img. ETA=0:02:46
[05/08 09:27:08] detectron2.evaluation.evaluator INFO: Inference done 1527/2560. 0.1529 s / img. ETA=0:02:39
[05/08 09:27:13] detectron2.evaluation.evaluator INFO: Inference done 1565/2560. 0.1523 s / img. ETA=0:02:33
[05/08 09:27:18] detectron2.evaluation.evaluator INFO: Inference done 1601/2560. 0.1520 s / img. ETA=0:02:27
[05/08 09:27:23] detectron2.evaluation.evaluator INFO: Inference done 1642/2560. 0.1512 s / img. ETA=0:02:20
[05/08 09:27:28] detectron2.evaluation.evaluator INFO: Inference done 1669/2560. 0.1518 s / img. ETA=0:02:16
[05/08 09:27:33] detectron2.evaluation.evaluator INFO: Inference done 1697/2560. 0.1522 s / img. ETA=0:02:12
[05/08 09:27:38] detectron2.evaluation.evaluator INFO: Inference done 1727/2560. 0.1525 s / img. ETA=0:02:08
[05/08 09:27:43] detectron2.evaluation.evaluator INFO: Inference done 1758/2560. 0.1527 s / img. ETA=0:02:03
[05/08 09:27:48] detectron2.evaluation.evaluator INFO: Inference done 1795/2560. 0.1523 s / img. ETA=0:01:57
[05/08 09:27:53] detectron2.evaluation.evaluator INFO: Inference done 1830/2560. 0.1521 s / img. ETA=0:01:52
[05/08 09:27:58] detectron2.evaluation.evaluator INFO: Inference done 1866/2560. 0.1519 s / img. ETA=0:01:46
[05/08 09:28:04] detectron2.evaluation.evaluator INFO: Inference done 1906/2560. 0.1513 s / img. ETA=0:01:40
[05/08 09:28:09] detectron2.evaluation.evaluator INFO: Inference done 1947/2560. 0.1507 s / img. ETA=0:01:33
[05/08 09:28:14] detectron2.evaluation.evaluator INFO: Inference done 1977/2560. 0.1510 s / img. ETA=0:01:29
[05/08 09:28:19] detectron2.evaluation.evaluator INFO: Inference done 2004/2560. 0.1515 s / img. ETA=0:01:25
[05/08 09:28:24] detectron2.evaluation.evaluator INFO: Inference done 2035/2560. 0.1516 s / img. ETA=0:01:20
[05/08 09:28:29] detectron2.evaluation.evaluator INFO: Inference done 2064/2560. 0.1519 s / img. ETA=0:01:16
[05/08 09:28:34] detectron2.evaluation.evaluator INFO: Inference done 2093/2560. 0.1522 s / img. ETA=0:01:11
[05/08 09:28:39] detectron2.evaluation.evaluator INFO: Inference done 2124/2560. 0.1524 s / img. ETA=0:01:07
[05/08 09:28:44] detectron2.evaluation.evaluator INFO: Inference done 2163/2560. 0.1519 s / img. ETA=0:01:01
[05/08 09:28:49] detectron2.evaluation.evaluator INFO: Inference done 2199/2560. 0.1517 s / img. ETA=0:00:55
[05/08 09:28:54] detectron2.evaluation.evaluator INFO: Inference done 2231/2560. 0.1518 s / img. ETA=0:00:50
[05/08 09:28:59] detectron2.evaluation.evaluator INFO: Inference done 2264/2560. 0.1518 s / img. ETA=0:00:45
[05/08 09:29:04] detectron2.evaluation.evaluator INFO: Inference done 2300/2560. 0.1516 s / img. ETA=0:00:39
[05/08 09:29:10] detectron2.evaluation.evaluator INFO: Inference done 2342/2560. 0.1510 s / img. ETA=0:00:33
[05/08 09:29:15] detectron2.evaluation.evaluator INFO: Inference done 2369/2560. 0.1514 s / img. ETA=0:00:29
[05/08 09:29:20] detectron2.evaluation.evaluator INFO: Inference done 2396/2560. 0.1517 s / img. ETA=0:00:25
[05/08 09:29:25] detectron2.evaluation.evaluator INFO: Inference done 2426/2560. 0.1519 s / img. ETA=0:00:20
[05/08 09:29:30] detectron2.evaluation.evaluator INFO: Inference done 2462/2560. 0.1517 s / img. ETA=0:00:15
[05/08 09:29:35] detectron2.evaluation.evaluator INFO: Inference done 2500/2560. 0.1514 s / img. ETA=0:00:09
[05/08 09:29:40] detectron2.evaluation.evaluator INFO: Inference done 2538/2560. 0.1511 s / img. ETA=0:00:03
[05/08 09:29:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:30.641414 (0.152893 s / img per device, on 4 devices)
[05/08 09:29:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:25 (0.150894 s / img per device, on 4 devices)
[05/08 09:32:23] detectron2 INFO: Rank of current process: 3. World size: 4
[05/08 09:32:24] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:32:24] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:32:24] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.2
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:32:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:32:24] detectron2.utils.env INFO: Using a generated random seed 24498254
[05/08 09:32:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:32:25] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:32:25] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:32:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:32:27] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:32:27] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:32:27] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:32:27] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:32:27] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:32:27] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:32:27] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:32:27] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:32:27] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/08 09:32:36] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1709 s / img. ETA=0:07:18
[05/08 09:32:41] detectron2.evaluation.evaluator INFO: Inference done 40/2560. 0.1714 s / img. ETA=0:07:15
[05/08 09:32:46] detectron2.evaluation.evaluator INFO: Inference done 70/2560. 0.1699 s / img. ETA=0:07:06
[05/08 09:32:52] detectron2.evaluation.evaluator INFO: Inference done 100/2560. 0.1702 s / img. ETA=0:07:02
[05/08 09:32:57] detectron2.evaluation.evaluator INFO: Inference done 130/2560. 0.1694 s / img. ETA=0:06:55
[05/08 09:33:02] detectron2.evaluation.evaluator INFO: Inference done 176/2560. 0.1534 s / img. ETA=0:06:09
[05/08 09:33:07] detectron2.evaluation.evaluator INFO: Inference done 216/2560. 0.1477 s / img. ETA=0:05:50
[05/08 09:33:12] detectron2.evaluation.evaluator INFO: Inference done 250/2560. 0.1476 s / img. ETA=0:05:44
[05/08 09:33:17] detectron2.evaluation.evaluator INFO: Inference done 283/2560. 0.1485 s / img. ETA=0:05:41
[05/08 09:33:22] detectron2.evaluation.evaluator INFO: Inference done 313/2560. 0.1508 s / img. ETA=0:05:42
[05/08 09:33:27] detectron2.evaluation.evaluator INFO: Inference done 346/2560. 0.1508 s / img. ETA=0:05:37
[05/08 09:33:32] detectron2.evaluation.evaluator INFO: Inference done 377/2560. 0.1520 s / img. ETA=0:05:35
[05/08 09:33:37] detectron2.evaluation.evaluator INFO: Inference done 410/2560. 0.1521 s / img. ETA=0:05:30
[05/08 09:33:42] detectron2.evaluation.evaluator INFO: Inference done 441/2560. 0.1527 s / img. ETA=0:05:26
[05/08 09:33:48] detectron2.evaluation.evaluator INFO: Inference done 473/2560. 0.1532 s / img. ETA=0:05:23
[05/08 09:33:53] detectron2.evaluation.evaluator INFO: Inference done 513/2560. 0.1510 s / img. ETA=0:05:12
[05/08 09:33:58] detectron2.evaluation.evaluator INFO: Inference done 543/2560. 0.1518 s / img. ETA=0:05:09
[05/08 09:34:03] detectron2.evaluation.evaluator INFO: Inference done 569/2560. 0.1536 s / img. ETA=0:05:09
[05/08 09:34:08] detectron2.evaluation.evaluator INFO: Inference done 596/2560. 0.1552 s / img. ETA=0:05:08
[05/08 09:34:13] detectron2.evaluation.evaluator INFO: Inference done 626/2560. 0.1559 s / img. ETA=0:05:04
[05/08 09:34:18] detectron2.evaluation.evaluator INFO: Inference done 655/2560. 0.1568 s / img. ETA=0:05:01
[05/08 09:34:23] detectron2.evaluation.evaluator INFO: Inference done 682/2560. 0.1581 s / img. ETA=0:04:59
[05/08 09:34:28] detectron2.evaluation.evaluator INFO: Inference done 709/2560. 0.1590 s / img. ETA=0:04:57
[05/08 09:34:34] detectron2.evaluation.evaluator INFO: Inference done 737/2560. 0.1600 s / img. ETA=0:04:54
[05/08 09:34:39] detectron2.evaluation.evaluator INFO: Inference done 765/2560. 0.1607 s / img. ETA=0:04:51
[05/08 09:34:44] detectron2.evaluation.evaluator INFO: Inference done 799/2560. 0.1602 s / img. ETA=0:04:45
[05/08 09:34:49] detectron2.evaluation.evaluator INFO: Inference done 834/2560. 0.1595 s / img. ETA=0:04:38
[05/08 09:34:54] detectron2.evaluation.evaluator INFO: Inference done 861/2560. 0.1603 s / img. ETA=0:04:35
[05/08 09:34:59] detectron2.evaluation.evaluator INFO: Inference done 893/2560. 0.1603 s / img. ETA=0:04:30
[05/08 09:35:04] detectron2.evaluation.evaluator INFO: Inference done 919/2560. 0.1612 s / img. ETA=0:04:27
[05/08 09:35:09] detectron2.evaluation.evaluator INFO: Inference done 948/2560. 0.1617 s / img. ETA=0:04:23
[05/08 09:35:14] detectron2.evaluation.evaluator INFO: Inference done 978/2560. 0.1619 s / img. ETA=0:04:18
[05/08 09:35:19] detectron2.evaluation.evaluator INFO: Inference done 1011/2560. 0.1616 s / img. ETA=0:04:12
[05/08 09:35:25] detectron2.evaluation.evaluator INFO: Inference done 1047/2560. 0.1609 s / img. ETA=0:04:05
[05/08 09:35:30] detectron2.evaluation.evaluator INFO: Inference done 1084/2560. 0.1600 s / img. ETA=0:03:58
[05/08 09:35:35] detectron2.evaluation.evaluator INFO: Inference done 1122/2560. 0.1590 s / img. ETA=0:03:51
[05/08 09:35:40] detectron2.evaluation.evaluator INFO: Inference done 1150/2560. 0.1595 s / img. ETA=0:03:47
[05/08 09:35:45] detectron2.evaluation.evaluator INFO: Inference done 1177/2560. 0.1600 s / img. ETA=0:03:43
[05/08 09:35:50] detectron2.evaluation.evaluator INFO: Inference done 1215/2560. 0.1592 s / img. ETA=0:03:36
[05/08 09:35:55] detectron2.evaluation.evaluator INFO: Inference done 1256/2560. 0.1579 s / img. ETA=0:03:28
[05/08 09:36:00] detectron2.evaluation.evaluator INFO: Inference done 1286/2560. 0.1581 s / img. ETA=0:03:23
[05/08 09:36:05] detectron2.evaluation.evaluator INFO: Inference done 1327/2560. 0.1570 s / img. ETA=0:03:15
[05/08 09:36:10] detectron2.evaluation.evaluator INFO: Inference done 1357/2560. 0.1572 s / img. ETA=0:03:11
[05/08 09:36:15] detectron2.evaluation.evaluator INFO: Inference done 1395/2560. 0.1565 s / img. ETA=0:03:04
[05/08 09:36:20] detectron2.evaluation.evaluator INFO: Inference done 1435/2560. 0.1556 s / img. ETA=0:02:56
[05/08 09:36:25] detectron2.evaluation.evaluator INFO: Inference done 1480/2560. 0.1542 s / img. ETA=0:02:48
[05/08 09:36:30] detectron2.evaluation.evaluator INFO: Inference done 1516/2560. 0.1538 s / img. ETA=0:02:42
[05/08 09:36:35] detectron2.evaluation.evaluator INFO: Inference done 1556/2560. 0.1531 s / img. ETA=0:02:35
[05/08 09:36:40] detectron2.evaluation.evaluator INFO: Inference done 1591/2560. 0.1528 s / img. ETA=0:02:29
[05/08 09:36:45] detectron2.evaluation.evaluator INFO: Inference done 1636/2560. 0.1517 s / img. ETA=0:02:21
[05/08 09:36:50] detectron2.evaluation.evaluator INFO: Inference done 1663/2560. 0.1522 s / img. ETA=0:02:18
[05/08 09:36:56] detectron2.evaluation.evaluator INFO: Inference done 1690/2560. 0.1528 s / img. ETA=0:02:14
[05/08 09:37:01] detectron2.evaluation.evaluator INFO: Inference done 1721/2560. 0.1530 s / img. ETA=0:02:09
[05/08 09:37:06] detectron2.evaluation.evaluator INFO: Inference done 1750/2560. 0.1533 s / img. ETA=0:02:05
[05/08 09:37:11] detectron2.evaluation.evaluator INFO: Inference done 1785/2560. 0.1531 s / img. ETA=0:02:00
[05/08 09:37:16] detectron2.evaluation.evaluator INFO: Inference done 1822/2560. 0.1527 s / img. ETA=0:01:54
[05/08 09:37:21] detectron2.evaluation.evaluator INFO: Inference done 1859/2560. 0.1524 s / img. ETA=0:01:48
[05/08 09:37:26] detectron2.evaluation.evaluator INFO: Inference done 1896/2560. 0.1521 s / img. ETA=0:01:42
[05/08 09:37:31] detectron2.evaluation.evaluator INFO: Inference done 1937/2560. 0.1515 s / img. ETA=0:01:35
[05/08 09:37:36] detectron2.evaluation.evaluator INFO: Inference done 1970/2560. 0.1514 s / img. ETA=0:01:30
[05/08 09:37:41] detectron2.evaluation.evaluator INFO: Inference done 1997/2560. 0.1519 s / img. ETA=0:01:26
[05/08 09:37:46] detectron2.evaluation.evaluator INFO: Inference done 2027/2560. 0.1521 s / img. ETA=0:01:22
[05/08 09:37:51] detectron2.evaluation.evaluator INFO: Inference done 2054/2560. 0.1525 s / img. ETA=0:01:18
[05/08 09:37:56] detectron2.evaluation.evaluator INFO: Inference done 2084/2560. 0.1527 s / img. ETA=0:01:13
[05/08 09:38:02] detectron2.evaluation.evaluator INFO: Inference done 2115/2560. 0.1529 s / img. ETA=0:01:08
[05/08 09:38:07] detectron2.evaluation.evaluator INFO: Inference done 2152/2560. 0.1526 s / img. ETA=0:01:02
[05/08 09:38:12] detectron2.evaluation.evaluator INFO: Inference done 2189/2560. 0.1523 s / img. ETA=0:00:57
[05/08 09:38:17] detectron2.evaluation.evaluator INFO: Inference done 2221/2560. 0.1523 s / img. ETA=0:00:52
[05/08 09:38:22] detectron2.evaluation.evaluator INFO: Inference done 2253/2560. 0.1523 s / img. ETA=0:00:47
[05/08 09:38:27] detectron2.evaluation.evaluator INFO: Inference done 2287/2560. 0.1522 s / img. ETA=0:00:42
[05/08 09:38:32] detectron2.evaluation.evaluator INFO: Inference done 2326/2560. 0.1518 s / img. ETA=0:00:35
[05/08 09:38:37] detectron2.evaluation.evaluator INFO: Inference done 2359/2560. 0.1518 s / img. ETA=0:00:30
[05/08 09:38:42] detectron2.evaluation.evaluator INFO: Inference done 2385/2560. 0.1523 s / img. ETA=0:00:26
[05/08 09:38:47] detectron2.evaluation.evaluator INFO: Inference done 2416/2560. 0.1524 s / img. ETA=0:00:22
[05/08 09:38:52] detectron2.evaluation.evaluator INFO: Inference done 2448/2560. 0.1525 s / img. ETA=0:00:17
[05/08 09:38:57] detectron2.evaluation.evaluator INFO: Inference done 2486/2560. 0.1521 s / img. ETA=0:00:11
[05/08 09:39:02] detectron2.evaluation.evaluator INFO: Inference done 2523/2560. 0.1518 s / img. ETA=0:00:05
[05/08 09:39:07] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:31.792656 (0.153344 s / img per device, on 4 devices)
[05/08 09:39:07] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:26 (0.151417 s / img per device, on 4 devices)
[05/08 09:44:52] detectron2 INFO: Rank of current process: 3. World size: 4
[05/08 09:44:53] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 09:44:53] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t4/t4_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t4_final'], resume=False)
[05/08 09:44:53] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t4/t4_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t4_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4 # 0.2, 0.3
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 60
  CUR_INTRODUCED_CLS: 20
[05/08 09:44:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth
OUTPUT_DIR: ./output/t4_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 60
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 09:44:53] detectron2.utils.env INFO: Using a generated random seed 53688159
[05/08 09:44:54] detectron2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: []
[05/08 09:44:54] detectron2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t4_final/feature_store/feat.pt. Creating new feature store.
[05/08 09:44:54] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 09:44:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t4_ft/model_final.pth ...
[05/08 09:44:56] detectron2.data.build INFO: Known classes: range(0, 80)
[05/08 09:44:56] detectron2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 09:44:56] detectron2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 189          |    toilet     | 256          |   laptop   | 291          |
|     mouse     | 121          |    remote     | 330          |  keyboard  | 176          |
|  cell phone   | 382          |     book      | 1507         |   clock    | 356          |
|     vase      | 380          |   scissors    | 46           | teddy bear | 248          |
|  hair drier   | 17           |  toothbrush   | 88           | wine glass | 558          |
|      cup      | 1586         |     fork      | 407          |   knife    | 681          |
|     spoon     | 455          |     bowl      | 1225         |  unknown   | 0            |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 09:44:56] detectron2.data.build INFO: Number of datapoints: 10246
[05/08 09:44:56] detectron2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 09:44:56] detectron2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 09:44:56] detectron2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 09:44:56] detectron2.evaluation.pascal_voc_evaluation INFO: Energy distribution is not found at ./output/t4_final/energy_dist_80.pkl
[05/08 09:44:56] detectron2.evaluation.evaluator INFO: Start inference on 2560 images
[05/08 09:45:05] detectron2.evaluation.evaluator INFO: Inference done 11/2560. 0.1717 s / img. ETA=0:07:21
[05/08 09:45:10] detectron2.evaluation.evaluator INFO: Inference done 40/2560. 0.1718 s / img. ETA=0:07:17
[05/08 09:45:15] detectron2.evaluation.evaluator INFO: Inference done 70/2560. 0.1701 s / img. ETA=0:07:08
[05/08 09:45:20] detectron2.evaluation.evaluator INFO: Inference done 99/2560. 0.1703 s / img. ETA=0:07:04
[05/08 09:45:25] detectron2.evaluation.evaluator INFO: Inference done 128/2560. 0.1705 s / img. ETA=0:06:59
[05/08 09:45:30] detectron2.evaluation.evaluator INFO: Inference done 174/2560. 0.1535 s / img. ETA=0:06:10
[05/08 09:45:35] detectron2.evaluation.evaluator INFO: Inference done 214/2560. 0.1480 s / img. ETA=0:05:51
[05/08 09:45:40] detectron2.evaluation.evaluator INFO: Inference done 248/2560. 0.1480 s / img. ETA=0:05:46
[05/08 09:45:45] detectron2.evaluation.evaluator INFO: Inference done 281/2560. 0.1484 s / img. ETA=0:05:42
[05/08 09:45:50] detectron2.evaluation.evaluator INFO: Inference done 311/2560. 0.1503 s / img. ETA=0:05:42
[05/08 09:45:56] detectron2.evaluation.evaluator INFO: Inference done 344/2560. 0.1505 s / img. ETA=0:05:37
[05/08 09:46:01] detectron2.evaluation.evaluator INFO: Inference done 375/2560. 0.1517 s / img. ETA=0:05:35
[05/08 09:46:06] detectron2.evaluation.evaluator INFO: Inference done 408/2560. 0.1518 s / img. ETA=0:05:30
[05/08 09:46:11] detectron2.evaluation.evaluator INFO: Inference done 439/2560. 0.1527 s / img. ETA=0:05:27
[05/08 09:46:16] detectron2.evaluation.evaluator INFO: Inference done 472/2560. 0.1530 s / img. ETA=0:05:23
[05/08 09:46:21] detectron2.evaluation.evaluator INFO: Inference done 512/2560. 0.1509 s / img. ETA=0:05:12
[05/08 09:46:26] detectron2.evaluation.evaluator INFO: Inference done 543/2560. 0.1517 s / img. ETA=0:05:09
[05/08 09:46:31] detectron2.evaluation.evaluator INFO: Inference done 569/2560. 0.1535 s / img. ETA=0:05:09
[05/08 09:46:36] detectron2.evaluation.evaluator INFO: Inference done 595/2560. 0.1552 s / img. ETA=0:05:08
[05/08 09:46:42] detectron2.evaluation.evaluator INFO: Inference done 624/2560. 0.1559 s / img. ETA=0:05:05
[05/08 09:46:47] detectron2.evaluation.evaluator INFO: Inference done 653/2560. 0.1567 s / img. ETA=0:05:02
[05/08 09:46:52] detectron2.evaluation.evaluator INFO: Inference done 680/2560. 0.1580 s / img. ETA=0:05:00
[05/08 09:46:57] detectron2.evaluation.evaluator INFO: Inference done 708/2560. 0.1588 s / img. ETA=0:04:57
[05/08 09:47:02] detectron2.evaluation.evaluator INFO: Inference done 736/2560. 0.1598 s / img. ETA=0:04:54
[05/08 09:47:07] detectron2.evaluation.evaluator INFO: Inference done 763/2560. 0.1607 s / img. ETA=0:04:52
[05/08 09:47:12] detectron2.evaluation.evaluator INFO: Inference done 797/2560. 0.1601 s / img. ETA=0:04:45
[05/08 09:47:17] detectron2.evaluation.evaluator INFO: Inference done 833/2560. 0.1592 s / img. ETA=0:04:38
[05/08 09:47:22] detectron2.evaluation.evaluator INFO: Inference done 859/2560. 0.1603 s / img. ETA=0:04:35
[05/08 09:47:27] detectron2.evaluation.evaluator INFO: Inference done 891/2560. 0.1602 s / img. ETA=0:04:30
[05/08 09:47:33] detectron2.evaluation.evaluator INFO: Inference done 917/2560. 0.1612 s / img. ETA=0:04:27
[05/08 09:47:38] detectron2.evaluation.evaluator INFO: Inference done 945/2560. 0.1616 s / img. ETA=0:04:24
[05/08 09:47:43] detectron2.evaluation.evaluator INFO: Inference done 975/2560. 0.1619 s / img. ETA=0:04:19
[05/08 09:47:48] detectron2.evaluation.evaluator INFO: Inference done 1008/2560. 0.1616 s / img. ETA=0:04:13
[05/08 09:47:53] detectron2.evaluation.evaluator INFO: Inference done 1044/2560. 0.1608 s / img. ETA=0:04:06
[05/08 09:47:58] detectron2.evaluation.evaluator INFO: Inference done 1080/2560. 0.1600 s / img. ETA=0:03:59
[05/08 09:48:03] detectron2.evaluation.evaluator INFO: Inference done 1118/2560. 0.1591 s / img. ETA=0:03:52
[05/08 09:48:08] detectron2.evaluation.evaluator INFO: Inference done 1147/2560. 0.1595 s / img. ETA=0:03:48
[05/08 09:48:13] detectron2.evaluation.evaluator INFO: Inference done 1176/2560. 0.1599 s / img. ETA=0:03:43
[05/08 09:48:18] detectron2.evaluation.evaluator INFO: Inference done 1213/2560. 0.1592 s / img. ETA=0:03:36
[05/08 09:48:23] detectron2.evaluation.evaluator INFO: Inference done 1254/2560. 0.1579 s / img. ETA=0:03:28
[05/08 09:48:29] detectron2.evaluation.evaluator INFO: Inference done 1283/2560. 0.1583 s / img. ETA=0:03:24
[05/08 09:48:34] detectron2.evaluation.evaluator INFO: Inference done 1324/2560. 0.1571 s / img. ETA=0:03:16
[05/08 09:48:39] detectron2.evaluation.evaluator INFO: Inference done 1355/2560. 0.1573 s / img. ETA=0:03:11
[05/08 09:48:44] detectron2.evaluation.evaluator INFO: Inference done 1393/2560. 0.1566 s / img. ETA=0:03:04
[05/08 09:48:49] detectron2.evaluation.evaluator INFO: Inference done 1431/2560. 0.1559 s / img. ETA=0:02:58
[05/08 09:48:54] detectron2.evaluation.evaluator INFO: Inference done 1476/2560. 0.1546 s / img. ETA=0:02:49
[05/08 09:48:59] detectron2.evaluation.evaluator INFO: Inference done 1513/2560. 0.1541 s / img. ETA=0:02:43
[05/08 09:49:04] detectron2.evaluation.evaluator INFO: Inference done 1552/2560. 0.1535 s / img. ETA=0:02:36
[05/08 09:49:09] detectron2.evaluation.evaluator INFO: Inference done 1587/2560. 0.1532 s / img. ETA=0:02:30
[05/08 09:49:14] detectron2.evaluation.evaluator INFO: Inference done 1632/2560. 0.1521 s / img. ETA=0:02:22
[05/08 09:49:20] detectron2.evaluation.evaluator INFO: Inference done 1661/2560. 0.1525 s / img. ETA=0:02:18
[05/08 09:49:25] detectron2.evaluation.evaluator INFO: Inference done 1689/2560. 0.1530 s / img. ETA=0:02:14
[05/08 09:49:30] detectron2.evaluation.evaluator INFO: Inference done 1720/2560. 0.1532 s / img. ETA=0:02:10
[05/08 09:49:35] detectron2.evaluation.evaluator INFO: Inference done 1749/2560. 0.1535 s / img. ETA=0:02:06
[05/08 09:49:40] detectron2.evaluation.evaluator INFO: Inference done 1783/2560. 0.1534 s / img. ETA=0:02:00
[05/08 09:49:45] detectron2.evaluation.evaluator INFO: Inference done 1821/2560. 0.1530 s / img. ETA=0:01:54
[05/08 09:49:50] detectron2.evaluation.evaluator INFO: Inference done 1857/2560. 0.1527 s / img. ETA=0:01:48
[05/08 09:49:55] detectron2.evaluation.evaluator INFO: Inference done 1894/2560. 0.1523 s / img. ETA=0:01:42
[05/08 09:50:00] detectron2.evaluation.evaluator INFO: Inference done 1934/2560. 0.1518 s / img. ETA=0:01:36
[05/08 09:50:05] detectron2.evaluation.evaluator INFO: Inference done 1969/2560. 0.1516 s / img. ETA=0:01:30
[05/08 09:50:10] detectron2.evaluation.evaluator INFO: Inference done 1995/2560. 0.1521 s / img. ETA=0:01:27
[05/08 09:50:16] detectron2.evaluation.evaluator INFO: Inference done 2024/2560. 0.1524 s / img. ETA=0:01:22
[05/08 09:50:21] detectron2.evaluation.evaluator INFO: Inference done 2052/2560. 0.1528 s / img. ETA=0:01:18
[05/08 09:50:26] detectron2.evaluation.evaluator INFO: Inference done 2082/2560. 0.1530 s / img. ETA=0:01:14
[05/08 09:50:31] detectron2.evaluation.evaluator INFO: Inference done 2112/2560. 0.1532 s / img. ETA=0:01:09
[05/08 09:50:36] detectron2.evaluation.evaluator INFO: Inference done 2149/2560. 0.1529 s / img. ETA=0:01:03
[05/08 09:50:41] detectron2.evaluation.evaluator INFO: Inference done 2186/2560. 0.1526 s / img. ETA=0:00:57
[05/08 09:50:46] detectron2.evaluation.evaluator INFO: Inference done 2220/2560. 0.1526 s / img. ETA=0:00:52
[05/08 09:50:51] detectron2.evaluation.evaluator INFO: Inference done 2252/2560. 0.1526 s / img. ETA=0:00:47
[05/08 09:50:56] detectron2.evaluation.evaluator INFO: Inference done 2285/2560. 0.1526 s / img. ETA=0:00:42
[05/08 09:51:01] detectron2.evaluation.evaluator INFO: Inference done 2325/2560. 0.1521 s / img. ETA=0:00:36
[05/08 09:51:06] detectron2.evaluation.evaluator INFO: Inference done 2358/2560. 0.1521 s / img. ETA=0:00:31
[05/08 09:51:11] detectron2.evaluation.evaluator INFO: Inference done 2384/2560. 0.1525 s / img. ETA=0:00:27
[05/08 09:51:16] detectron2.evaluation.evaluator INFO: Inference done 2414/2560. 0.1527 s / img. ETA=0:00:22
[05/08 09:51:21] detectron2.evaluation.evaluator INFO: Inference done 2446/2560. 0.1527 s / img. ETA=0:00:17
[05/08 09:51:26] detectron2.evaluation.evaluator INFO: Inference done 2484/2560. 0.1524 s / img. ETA=0:00:11
[05/08 09:51:31] detectron2.evaluation.evaluator INFO: Inference done 2522/2560. 0.1521 s / img. ETA=0:00:05
[05/08 09:51:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:32.723546 (0.153708 s / img per device, on 4 devices)
[05/08 09:51:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:27 (0.151656 s / img per device, on 4 devices)
