[05/08 10:54:56] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 10:54:57] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 10:54:57] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t3/t3_val.yaml', dist_url='tcp://127.0.0.1:52133', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.01', 'OWOD.TEMPERATURE', '1.5', 'OUTPUT_DIR', './output/t3_final'], resume=False)
[05/08 10:54:57] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t3/t3_val.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t3_ft/model_final.pth"
DATASETS:
  TRAIN: ('voc_coco_2007_val', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_val', )
SOLVER:
  STEPS: (50000, 60000)
  MAX_ITER: 500
  WARMUP_ITERS: 0
OUTPUT_DIR: "./output/t3_val"
OWOD:
  PREV_INTRODUCED_CLS: 40
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: False
  COMPUTE_ENERGY: True
  ENERGY_SAVE_PATH: 'energy'
  SKIP_TRAINING_WHILE_EVAL: False
[05/08 10:54:57] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_val',)
  TRAIN: ('voc_coco_2007_val',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t3_ft/model_final.pth
OUTPUT_DIR: ./output/t3_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: True
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: False
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: energy
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 40
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 500
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (50000, 60000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 10:54:57] detectron2 INFO: Full config saved to ./output/t3_final/config.yaml
[05/08 10:54:57] d2.utils.env INFO: Using a generated random seed 57279638
[05/08 10:54:57] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
[05/08 10:54:57] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t3_final/feature_store/feat.pt. Creating new feature store.
[05/08 10:54:57] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 10:54:58] d2.data.build INFO: Removed 0 images with no usable annotations. 4000 images left.
[05/08 10:54:58] d2.data.build INFO: Known classes: range(0, 60)
[05/08 10:54:58] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 10:54:58] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 90           |    bicycle    | 215          |    bird    | 206          |
|     boat      | 165          |    bottle     | 1146         |    bus     | 157          |
|      car      | 1218         |      cat      | 174          |   chair    | 1531         |
|      cow      | 88           |  diningtable  | 693          |    dog     | 247          |
|     horse     | 105          |   motorbike   | 252          |   person   | 8393         |
|  pottedplant  | 314          |     sheep     | 163          |    sofa    | 258          |
|     train     | 86           |   tvmonitor   | 269          |   truck    | 307          |
| traffic light | 341          | fire hydrant  | 33           | stop sign  | 40           |
| parking meter | 41           |     bench     | 334          |  elephant  | 150          |
|     bear      | 34           |     zebra     | 116          |  giraffe   | 150          |
|   backpack    | 317          |   umbrella    | 304          |  handbag   | 375          |
|      tie      | 217          |   suitcase    | 115          | microwave  | 77           |
|     oven      | 162          |    toaster    | 13           |    sink    | 220          |
| refrigerator  | 128          |    frisbee    | 91           |    skis    | 185          |
|   snowboard   | 72           |  sports ball  | 160          |    kite    | 218          |
| baseball bat  | 99           | baseball gl.. | 122          | skateboard | 178          |
|   surfboard   | 164          | tennis racket | 150          |   banana   | 395          |
|     apple     | 199          |   sandwich    | 223          |   orange   | 196          |
|   broccoli    | 229          |    carrot     | 302          |  hot dog   | 122          |
|     pizza     | 272          |     donut     | 270          |    cake    | 349          |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 5371         |
|               |              |               |              |            |              |
|     total     | 28611        |               |              |            |              |[0m
[05/08 10:54:58] d2.data.build INFO: Number of datapoints: 4000
[05/08 10:54:58] d2.data.common INFO: Serializing 4000 elements to byte tensors and concatenating them all ...
[05/08 10:54:58] d2.data.common INFO: Serialized dataset takes 2.86 MiB
[05/08 10:54:58] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[05/08 10:54:58] d2.data.build INFO: Using training sampler TrainingSampler
[05/08 10:54:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t3_ft/model_final.pth ...
[05/08 10:54:59] d2.engine.train_loop INFO: Starting training from iteration 0
[05/08 10:55:15] d2.utils.events INFO:  eta: 0:03:46  iter: 19  total_loss: 1.164  loss_cls: 0.4278  loss_box_reg: 0.3645  loss_clustering: 0  loss_rpn_cls: 0.2317  loss_rpn_loc: 0.1451  time: 0.4741  data_time: 0.3524  lr: 0.01  max_mem: 2557M
[05/08 10:55:25] d2.utils.events INFO:  eta: 0:03:35  iter: 39  total_loss: 1.007  loss_cls: 0.4035  loss_box_reg: 0.2938  loss_clustering: 0  loss_rpn_cls: 0.1968  loss_rpn_loc: 0.1371  time: 0.4702  data_time: 0.0031  lr: 0.01  max_mem: 2598M
[05/08 10:55:34] d2.utils.events INFO:  eta: 0:03:26  iter: 59  total_loss: 1.185  loss_cls: 0.4017  loss_box_reg: 0.3558  loss_clustering: 0  loss_rpn_cls: 0.1824  loss_rpn_loc: 0.1821  time: 0.4711  data_time: 0.0036  lr: 0.01  max_mem: 2598M
[05/08 10:55:44] d2.utils.events INFO:  eta: 0:03:17  iter: 79  total_loss: 1.065  loss_cls: 0.3774  loss_box_reg: 0.3279  loss_clustering: 0  loss_rpn_cls: 0.1951  loss_rpn_loc: 0.1249  time: 0.4720  data_time: 0.0031  lr: 0.01  max_mem: 2598M
[05/08 10:55:53] d2.utils.events INFO:  eta: 0:03:08  iter: 99  total_loss: 1.027  loss_cls: 0.344  loss_box_reg: 0.3209  loss_clustering: 0  loss_rpn_cls: 0.1645  loss_rpn_loc: 0.1761  time: 0.4731  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:56:03] d2.utils.events INFO:  eta: 0:02:58  iter: 119  total_loss: 1.042  loss_cls: 0.3911  loss_box_reg: 0.3474  loss_clustering: 0  loss_rpn_cls: 0.2102  loss_rpn_loc: 0.1572  time: 0.4732  data_time: 0.0031  lr: 0.01  max_mem: 2641M
[05/08 10:56:12] d2.utils.events INFO:  eta: 0:02:50  iter: 139  total_loss: 1.084  loss_cls: 0.3838  loss_box_reg: 0.3427  loss_clustering: 0  loss_rpn_cls: 0.1909  loss_rpn_loc: 0.1425  time: 0.4740  data_time: 0.0031  lr: 0.01  max_mem: 2641M
[05/08 10:56:22] d2.utils.events INFO:  eta: 0:02:40  iter: 159  total_loss: 1.09  loss_cls: 0.3965  loss_box_reg: 0.3453  loss_clustering: 0  loss_rpn_cls: 0.1865  loss_rpn_loc: 0.1471  time: 0.4746  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:56:32] d2.utils.events INFO:  eta: 0:02:31  iter: 179  total_loss: 1.048  loss_cls: 0.3333  loss_box_reg: 0.3027  loss_clustering: 0  loss_rpn_cls: 0.2012  loss_rpn_loc: 0.1675  time: 0.4746  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:56:41] d2.utils.events INFO:  eta: 0:02:22  iter: 199  total_loss: 1.041  loss_cls: 0.382  loss_box_reg: 0.3459  loss_clustering: 0  loss_rpn_cls: 0.1868  loss_rpn_loc: 0.1528  time: 0.4753  data_time: 0.0034  lr: 0.01  max_mem: 2641M
[05/08 10:56:51] d2.utils.events INFO:  eta: 0:02:13  iter: 219  total_loss: 1.131  loss_cls: 0.4081  loss_box_reg: 0.3432  loss_clustering: 0  loss_rpn_cls: 0.1957  loss_rpn_loc: 0.1513  time: 0.4759  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:57:01] d2.utils.events INFO:  eta: 0:02:04  iter: 239  total_loss: 1.085  loss_cls: 0.3453  loss_box_reg: 0.338  loss_clustering: 0  loss_rpn_cls: 0.205  loss_rpn_loc: 0.1995  time: 0.4773  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:57:11] d2.utils.events INFO:  eta: 0:01:54  iter: 259  total_loss: 1.16  loss_cls: 0.4288  loss_box_reg: 0.3939  loss_clustering: 0  loss_rpn_cls: 0.1914  loss_rpn_loc: 0.1514  time: 0.4775  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:57:20] d2.utils.events INFO:  eta: 0:01:45  iter: 279  total_loss: 1.126  loss_cls: 0.411  loss_box_reg: 0.3887  loss_clustering: 0  loss_rpn_cls: 0.1942  loss_rpn_loc: 0.1495  time: 0.4778  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:57:30] d2.utils.events INFO:  eta: 0:01:35  iter: 299  total_loss: 1.175  loss_cls: 0.3891  loss_box_reg: 0.3785  loss_clustering: 0  loss_rpn_cls: 0.2007  loss_rpn_loc: 0.1879  time: 0.4789  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:57:40] d2.utils.events INFO:  eta: 0:01:26  iter: 319  total_loss: 1.095  loss_cls: 0.3794  loss_box_reg: 0.3538  loss_clustering: 0  loss_rpn_cls: 0.1901  loss_rpn_loc: 0.138  time: 0.4791  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:57:49] d2.utils.events INFO:  eta: 0:01:16  iter: 339  total_loss: 1.188  loss_cls: 0.3937  loss_box_reg: 0.3825  loss_clustering: 0  loss_rpn_cls: 0.2134  loss_rpn_loc: 0.1672  time: 0.4791  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:57:59] d2.utils.events INFO:  eta: 0:01:07  iter: 359  total_loss: 1.007  loss_cls: 0.3452  loss_box_reg: 0.3244  loss_clustering: 0  loss_rpn_cls: 0.195  loss_rpn_loc: 0.1358  time: 0.4793  data_time: 0.0031  lr: 0.01  max_mem: 2641M
[05/08 10:58:09] d2.utils.events INFO:  eta: 0:00:57  iter: 379  total_loss: 1.081  loss_cls: 0.356  loss_box_reg: 0.3151  loss_clustering: 0  loss_rpn_cls: 0.1771  loss_rpn_loc: 0.1899  time: 0.4794  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:58:19] d2.utils.events INFO:  eta: 0:00:47  iter: 399  total_loss: 1.041  loss_cls: 0.3845  loss_box_reg: 0.3469  loss_clustering: 0  loss_rpn_cls: 0.1649  loss_rpn_loc: 0.1487  time: 0.4795  data_time: 0.0031  lr: 0.01  max_mem: 2641M
[05/08 10:58:28] d2.utils.events INFO:  eta: 0:00:38  iter: 419  total_loss: 1.25  loss_cls: 0.4355  loss_box_reg: 0.4401  loss_clustering: 0  loss_rpn_cls: 0.183  loss_rpn_loc: 0.1412  time: 0.4793  data_time: 0.0033  lr: 0.01  max_mem: 2641M
[05/08 10:58:38] d2.utils.events INFO:  eta: 0:00:28  iter: 439  total_loss: 1.076  loss_cls: 0.3717  loss_box_reg: 0.3632  loss_clustering: 0  loss_rpn_cls: 0.188  loss_rpn_loc: 0.1538  time: 0.4792  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:58:47] d2.utils.events INFO:  eta: 0:00:19  iter: 459  total_loss: 1.107  loss_cls: 0.4112  loss_box_reg: 0.3683  loss_clustering: 0  loss_rpn_cls: 0.1758  loss_rpn_loc: 0.142  time: 0.4791  data_time: 0.0030  lr: 0.01  max_mem: 2641M
[05/08 10:58:57] d2.utils.events INFO:  eta: 0:00:09  iter: 479  total_loss: 1.03  loss_cls: 0.3498  loss_box_reg: 0.3843  loss_clustering: 0  loss_rpn_cls: 0.1674  loss_rpn_loc: 0.146  time: 0.4790  data_time: 0.0032  lr: 0.01  max_mem: 2641M
[05/08 10:59:06] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t3_final/model_final.pth
[05/08 10:59:07] d2.utils.events INFO:  eta: 0:00:00  iter: 499  total_loss: 1.194  loss_cls: 0.3437  loss_box_reg: 0.3754  loss_clustering: 0  loss_rpn_cls: 0.216  loss_rpn_loc: 0.1795  time: 0.4790  data_time: 0.0034  lr: 0.01  max_mem: 2641M
[05/08 10:59:07] d2.engine.train_loop INFO: Going to analyse the energy files...
[05/08 10:59:07] d2.engine.train_loop INFO: Temperature value: 1.5
[05/08 10:59:10] d2.engine.train_loop INFO: Analysing 0 / 2000
[05/08 10:59:19] d2.engine.train_loop INFO: Analysing 100 / 2000
[05/08 10:59:25] d2.engine.train_loop INFO: Analysing 200 / 2000
[05/08 10:59:30] d2.engine.train_loop INFO: Analysing 300 / 2000
[05/08 10:59:34] d2.engine.train_loop INFO: Analysing 400 / 2000
[05/08 10:59:39] d2.engine.train_loop INFO: Analysing 500 / 2000
[05/08 10:59:44] d2.engine.train_loop INFO: Analysing 600 / 2000
[05/08 10:59:49] d2.engine.train_loop INFO: Analysing 700 / 2000
[05/08 10:59:54] d2.engine.train_loop INFO: Analysing 800 / 2000
[05/08 10:59:58] d2.engine.train_loop INFO: Analysing 900 / 2000
[05/08 11:00:02] d2.engine.train_loop INFO: Analysing 1000 / 2000
[05/08 11:00:07] d2.engine.train_loop INFO: Analysing 1100 / 2000
[05/08 11:00:12] d2.engine.train_loop INFO: Analysing 1200 / 2000
[05/08 11:00:16] d2.engine.train_loop INFO: Analysing 1300 / 2000
[05/08 11:00:21] d2.engine.train_loop INFO: Analysing 1400 / 2000
[05/08 11:00:25] d2.engine.train_loop INFO: Analysing 1500 / 2000
[05/08 11:00:29] d2.engine.train_loop INFO: Analysing 1600 / 2000
[05/08 11:00:34] d2.engine.train_loop INFO: Analysing 1700 / 2000
[05/08 11:00:38] d2.engine.train_loop INFO: Analysing 1800 / 2000
[05/08 11:00:42] d2.engine.train_loop INFO: Analysing 1900 / 2000
[05/08 11:00:46] d2.engine.train_loop INFO: len(unk): 19120
[05/08 11:00:46] d2.engine.train_loop INFO: len(known): 103935
[05/08 11:00:46] d2.engine.train_loop INFO: Fitting Weibull distribution...
[05/08 11:00:47] d2.engine.train_loop INFO: --- 0.6421148777008057 seconds ---
[05/08 11:00:49] d2.engine.train_loop INFO: --- 2.243262767791748 seconds ---
[05/08 11:00:49] d2.engine.train_loop INFO: Pickling the parameters to ./output/t3_final/energy_dist_60.pkl
[05/08 11:00:49] d2.engine.train_loop INFO: Plotting the computed energy values...
[05/08 11:00:51] d2.engine.hooks INFO: Overall training speed: 498 iterations in 0:03:58 (0.4790 s / it)
[05/08 11:00:51] d2.engine.hooks INFO: Total training time: 0:05:43 (0:01:45 on hooks)
[05/08 11:00:58] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 11:00:59] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 11:00:59] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t3/t3_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t3_final'], resume=False)
[05/08 11:00:59] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t3/t3_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t3_ft/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4
TEST:
  DETECTIONS_PER_IMAGE: 100
DATASETS:
  TRAIN: ('t3_voc_coco_2007_train', )
  TEST: ('voc_coco_2007_test', )
SOLVER:
  STEPS: (110000, 112000)
  MAX_ITER: 114000
  WARMUP_ITERS: 0
OUTPUT_DIR: "./output/t3_evalulate"
OWOD:
  PREV_INTRODUCED_CLS: 40
  CUR_INTRODUCED_CLS: 20
[05/08 11:00:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t3_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t3_ft/model_final.pth
OUTPUT_DIR: ./output/t3_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 40
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 114000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (110000, 112000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 11:00:59] detectron2 INFO: Full config saved to ./output/t3_final/config.yaml
[05/08 11:00:59] d2.utils.env INFO: Using a generated random seed 59437972
[05/08 11:00:59] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
[05/08 11:00:59] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t3_final/feature_store/feat.pt. Creating new feature store.
[05/08 11:01:00] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 11:01:00] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t3_ft/model_final.pth ...
[05/08 11:01:01] d2.data.build INFO: Known classes: range(0, 60)
[05/08 11:01:01] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 11:01:02] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 474          |
| traffic light | 729          | fire hydrant  | 108          | stop sign  | 77           |
| parking meter | 63           |     bench     | 631          |  elephant  | 259          |
|     bear      | 73           |     zebra     | 270          |  giraffe   | 234          |
|   backpack    | 560          |   umbrella    | 516          |  handbag   | 772          |
|      tie      | 367          |   suitcase    | 358          | microwave  | 107          |
|     oven      | 295          |    toaster    | 17           |    sink    | 428          |
| refrigerator  | 214          |    frisbee    | 138          |    skis    | 315          |
|   snowboard   | 83           |  sports ball  | 321          |    kite    | 474          |
| baseball bat  | 195          | baseball gl.. | 178          | skateboard | 233          |
|   surfboard   | 309          | tennis racket | 266          |   banana   | 586          |
|     apple     | 394          |   sandwich    | 335          |   orange   | 484          |
|   broccoli    | 541          |    carrot     | 717          |  hot dog   | 210          |
|     pizza     | 518          |     donut     | 520          |    cake    | 652          |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 9299         |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 11:01:02] d2.data.build INFO: Number of datapoints: 10246
[05/08 11:01:02] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 11:01:02] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 11:01:02] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 11:01:02] d2.evaluation.pascal_voc_evaluation INFO: Loading energy distribution from ./output/t3_final/energy_dist_60.pkl
[05/08 11:01:02] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 11:01:11] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1405 s / img. ETA=0:06:33
[05/08 11:01:16] d2.evaluation.evaluator INFO: Inference done 46/2562. 0.1364 s / img. ETA=0:06:11
[05/08 11:01:21] d2.evaluation.evaluator INFO: Inference done 78/2562. 0.1387 s / img. ETA=0:06:17
[05/08 11:01:26] d2.evaluation.evaluator INFO: Inference done 110/2562. 0.1402 s / img. ETA=0:06:18
[05/08 11:01:31] d2.evaluation.evaluator INFO: Inference done 139/2562. 0.1443 s / img. ETA=0:06:26
[05/08 11:01:36] d2.evaluation.evaluator INFO: Inference done 170/2562. 0.1445 s / img. ETA=0:06:23
[05/08 11:01:42] d2.evaluation.evaluator INFO: Inference done 201/2562. 0.1459 s / img. ETA=0:06:21
[05/08 11:01:47] d2.evaluation.evaluator INFO: Inference done 235/2562. 0.1447 s / img. ETA=0:06:11
[05/08 11:01:52] d2.evaluation.evaluator INFO: Inference done 266/2562. 0.1448 s / img. ETA=0:06:07
[05/08 11:01:57] d2.evaluation.evaluator INFO: Inference done 297/2562. 0.1452 s / img. ETA=0:06:03
[05/08 11:02:02] d2.evaluation.evaluator INFO: Inference done 326/2562. 0.1462 s / img. ETA=0:06:01
[05/08 11:02:07] d2.evaluation.evaluator INFO: Inference done 359/2562. 0.1460 s / img. ETA=0:05:55
[05/08 11:02:12] d2.evaluation.evaluator INFO: Inference done 390/2562. 0.1461 s / img. ETA=0:05:50
[05/08 11:02:17] d2.evaluation.evaluator INFO: Inference done 422/2562. 0.1460 s / img. ETA=0:05:44
[05/08 11:02:22] d2.evaluation.evaluator INFO: Inference done 454/2562. 0.1459 s / img. ETA=0:05:39
[05/08 11:02:28] d2.evaluation.evaluator INFO: Inference done 487/2562. 0.1454 s / img. ETA=0:05:33
[05/08 11:02:33] d2.evaluation.evaluator INFO: Inference done 522/2562. 0.1446 s / img. ETA=0:05:25
[05/08 11:02:38] d2.evaluation.evaluator INFO: Inference done 555/2562. 0.1443 s / img. ETA=0:05:19
[05/08 11:02:43] d2.evaluation.evaluator INFO: Inference done 587/2562. 0.1443 s / img. ETA=0:05:14
[05/08 11:02:48] d2.evaluation.evaluator INFO: Inference done 618/2562. 0.1446 s / img. ETA=0:05:10
[05/08 11:02:53] d2.evaluation.evaluator INFO: Inference done 649/2562. 0.1448 s / img. ETA=0:05:06
[05/08 11:02:58] d2.evaluation.evaluator INFO: Inference done 681/2562. 0.1447 s / img. ETA=0:05:00
[05/08 11:03:03] d2.evaluation.evaluator INFO: Inference done 709/2562. 0.1454 s / img. ETA=0:04:57
[05/08 11:03:08] d2.evaluation.evaluator INFO: Inference done 740/2562. 0.1456 s / img. ETA=0:04:53
[05/08 11:03:13] d2.evaluation.evaluator INFO: Inference done 769/2562. 0.1461 s / img. ETA=0:04:49
[05/08 11:03:18] d2.evaluation.evaluator INFO: Inference done 801/2562. 0.1461 s / img. ETA=0:04:44
[05/08 11:03:24] d2.evaluation.evaluator INFO: Inference done 831/2562. 0.1463 s / img. ETA=0:04:39
[05/08 11:03:29] d2.evaluation.evaluator INFO: Inference done 863/2562. 0.1463 s / img. ETA=0:04:34
[05/08 11:03:34] d2.evaluation.evaluator INFO: Inference done 893/2562. 0.1465 s / img. ETA=0:04:29
[05/08 11:03:39] d2.evaluation.evaluator INFO: Inference done 923/2562. 0.1467 s / img. ETA=0:04:25
[05/08 11:03:44] d2.evaluation.evaluator INFO: Inference done 955/2562. 0.1466 s / img. ETA=0:04:20
[05/08 11:03:49] d2.evaluation.evaluator INFO: Inference done 986/2562. 0.1466 s / img. ETA=0:04:15
[05/08 11:03:54] d2.evaluation.evaluator INFO: Inference done 1018/2562. 0.1465 s / img. ETA=0:04:09
[05/08 11:03:59] d2.evaluation.evaluator INFO: Inference done 1052/2562. 0.1461 s / img. ETA=0:04:03
[05/08 11:04:04] d2.evaluation.evaluator INFO: Inference done 1083/2562. 0.1463 s / img. ETA=0:03:58
[05/08 11:04:09] d2.evaluation.evaluator INFO: Inference done 1116/2562. 0.1461 s / img. ETA=0:03:53
[05/08 11:04:14] d2.evaluation.evaluator INFO: Inference done 1147/2562. 0.1461 s / img. ETA=0:03:48
[05/08 11:04:19] d2.evaluation.evaluator INFO: Inference done 1180/2562. 0.1460 s / img. ETA=0:03:42
[05/08 11:04:25] d2.evaluation.evaluator INFO: Inference done 1209/2562. 0.1463 s / img. ETA=0:03:38
[05/08 11:04:30] d2.evaluation.evaluator INFO: Inference done 1240/2562. 0.1464 s / img. ETA=0:03:33
[05/08 11:04:35] d2.evaluation.evaluator INFO: Inference done 1272/2562. 0.1463 s / img. ETA=0:03:28
[05/08 11:04:40] d2.evaluation.evaluator INFO: Inference done 1303/2562. 0.1463 s / img. ETA=0:03:23
[05/08 11:04:45] d2.evaluation.evaluator INFO: Inference done 1333/2562. 0.1465 s / img. ETA=0:03:18
[05/08 11:04:50] d2.evaluation.evaluator INFO: Inference done 1363/2562. 0.1467 s / img. ETA=0:03:14
[05/08 11:04:55] d2.evaluation.evaluator INFO: Inference done 1389/2562. 0.1472 s / img. ETA=0:03:10
[05/08 11:05:00] d2.evaluation.evaluator INFO: Inference done 1420/2562. 0.1472 s / img. ETA=0:03:05
[05/08 11:05:05] d2.evaluation.evaluator INFO: Inference done 1454/2562. 0.1470 s / img. ETA=0:03:00
[05/08 11:05:11] d2.evaluation.evaluator INFO: Inference done 1487/2562. 0.1468 s / img. ETA=0:02:54
[05/08 11:05:16] d2.evaluation.evaluator INFO: Inference done 1518/2562. 0.1468 s / img. ETA=0:02:49
[05/08 11:05:21] d2.evaluation.evaluator INFO: Inference done 1549/2562. 0.1468 s / img. ETA=0:02:44
[05/08 11:05:26] d2.evaluation.evaluator INFO: Inference done 1584/2562. 0.1464 s / img. ETA=0:02:38
[05/08 11:05:31] d2.evaluation.evaluator INFO: Inference done 1617/2562. 0.1462 s / img. ETA=0:02:32
[05/08 11:05:36] d2.evaluation.evaluator INFO: Inference done 1650/2562. 0.1461 s / img. ETA=0:02:27
[05/08 11:05:41] d2.evaluation.evaluator INFO: Inference done 1681/2562. 0.1462 s / img. ETA=0:02:22
[05/08 11:05:46] d2.evaluation.evaluator INFO: Inference done 1713/2562. 0.1462 s / img. ETA=0:02:17
[05/08 11:05:51] d2.evaluation.evaluator INFO: Inference done 1744/2562. 0.1462 s / img. ETA=0:02:12
[05/08 11:05:56] d2.evaluation.evaluator INFO: Inference done 1773/2562. 0.1464 s / img. ETA=0:02:07
[05/08 11:06:01] d2.evaluation.evaluator INFO: Inference done 1805/2562. 0.1463 s / img. ETA=0:02:02
[05/08 11:06:06] d2.evaluation.evaluator INFO: Inference done 1833/2562. 0.1465 s / img. ETA=0:01:58
[05/08 11:06:12] d2.evaluation.evaluator INFO: Inference done 1865/2562. 0.1465 s / img. ETA=0:01:52
[05/08 11:06:17] d2.evaluation.evaluator INFO: Inference done 1898/2562. 0.1463 s / img. ETA=0:01:47
[05/08 11:06:22] d2.evaluation.evaluator INFO: Inference done 1930/2562. 0.1463 s / img. ETA=0:01:42
[05/08 11:06:27] d2.evaluation.evaluator INFO: Inference done 1961/2562. 0.1463 s / img. ETA=0:01:37
[05/08 11:06:32] d2.evaluation.evaluator INFO: Inference done 1994/2562. 0.1462 s / img. ETA=0:01:31
[05/08 11:06:37] d2.evaluation.evaluator INFO: Inference done 2029/2562. 0.1460 s / img. ETA=0:01:26
[05/08 11:06:42] d2.evaluation.evaluator INFO: Inference done 2059/2562. 0.1460 s / img. ETA=0:01:21
[05/08 11:06:47] d2.evaluation.evaluator INFO: Inference done 2092/2562. 0.1459 s / img. ETA=0:01:15
[05/08 11:06:52] d2.evaluation.evaluator INFO: Inference done 2120/2562. 0.1461 s / img. ETA=0:01:11
[05/08 11:06:57] d2.evaluation.evaluator INFO: Inference done 2149/2562. 0.1463 s / img. ETA=0:01:06
[05/08 11:07:02] d2.evaluation.evaluator INFO: Inference done 2180/2562. 0.1463 s / img. ETA=0:01:01
[05/08 11:07:08] d2.evaluation.evaluator INFO: Inference done 2213/2562. 0.1463 s / img. ETA=0:00:56
[05/08 11:07:13] d2.evaluation.evaluator INFO: Inference done 2245/2562. 0.1462 s / img. ETA=0:00:51
[05/08 11:07:18] d2.evaluation.evaluator INFO: Inference done 2278/2562. 0.1462 s / img. ETA=0:00:45
[05/08 11:07:23] d2.evaluation.evaluator INFO: Inference done 2308/2562. 0.1463 s / img. ETA=0:00:41
[05/08 11:07:28] d2.evaluation.evaluator INFO: Inference done 2338/2562. 0.1464 s / img. ETA=0:00:36
[05/08 11:07:33] d2.evaluation.evaluator INFO: Inference done 2370/2562. 0.1463 s / img. ETA=0:00:31
[05/08 11:07:38] d2.evaluation.evaluator INFO: Inference done 2402/2562. 0.1463 s / img. ETA=0:00:25
[05/08 11:07:43] d2.evaluation.evaluator INFO: Inference done 2435/2562. 0.1463 s / img. ETA=0:00:20
[05/08 11:07:49] d2.evaluation.evaluator INFO: Inference done 2469/2562. 0.1462 s / img. ETA=0:00:15
[05/08 11:07:54] d2.evaluation.evaluator INFO: Inference done 2500/2562. 0.1462 s / img. ETA=0:00:10
[05/08 11:07:59] d2.evaluation.evaluator INFO: Inference done 2531/2562. 0.1463 s / img. ETA=0:00:05
[05/08 11:08:04] d2.evaluation.evaluator INFO: Inference done 2561/2562. 0.1463 s / img. ETA=0:00:00
[05/08 11:08:04] d2.evaluation.evaluator INFO: Total inference time: 0:06:54.405108 (0.162067 s / img per device, on 4 devices)
[05/08 11:08:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:06:14 (0.146365 s / img per device, on 4 devices)
[05/08 11:08:59] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 11:08:59] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 1561 predictions.
[05/08 11:09:00] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 2105 predictions.
[05/08 11:09:00] d2.evaluation.pascal_voc_evaluation INFO: bird has 2439 predictions.
[05/08 11:09:01] d2.evaluation.pascal_voc_evaluation INFO: boat has 3368 predictions.
[05/08 11:09:01] d2.evaluation.pascal_voc_evaluation INFO: bottle has 13305 predictions.
[05/08 11:09:02] d2.evaluation.pascal_voc_evaluation INFO: bus has 2873 predictions.
[05/08 11:09:02] d2.evaluation.pascal_voc_evaluation INFO: car has 19031 predictions.
[05/08 11:09:03] d2.evaluation.pascal_voc_evaluation INFO: cat has 1990 predictions.
[05/08 11:09:03] d2.evaluation.pascal_voc_evaluation INFO: chair has 18573 predictions.
[05/08 11:09:04] d2.evaluation.pascal_voc_evaluation INFO: cow has 1356 predictions.
[05/08 11:09:04] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 12023 predictions.
[05/08 11:09:05] d2.evaluation.pascal_voc_evaluation INFO: dog has 2915 predictions.
[05/08 11:09:05] d2.evaluation.pascal_voc_evaluation INFO: horse has 1678 predictions.
[05/08 11:09:05] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 2254 predictions.
[05/08 11:09:06] d2.evaluation.pascal_voc_evaluation INFO: person has 68719 predictions.
[05/08 11:09:09] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 6124 predictions.
[05/08 11:09:09] d2.evaluation.pascal_voc_evaluation INFO: sheep has 1137 predictions.
[05/08 11:09:09] d2.evaluation.pascal_voc_evaluation INFO: sofa has 5420 predictions.
[05/08 11:09:10] d2.evaluation.pascal_voc_evaluation INFO: train has 2430 predictions.
[05/08 11:09:10] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 3075 predictions.
[05/08 11:09:10] d2.evaluation.pascal_voc_evaluation INFO: truck has 9228 predictions.
[05/08 11:09:11] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 4534 predictions.
[05/08 11:09:11] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1441 predictions.
[05/08 11:09:11] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1499 predictions.
[05/08 11:09:11] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1964 predictions.
[05/08 11:09:12] d2.evaluation.pascal_voc_evaluation INFO: bench has 6075 predictions.
[05/08 11:09:12] d2.evaluation.pascal_voc_evaluation INFO: elephant has 1371 predictions.
[05/08 11:09:12] d2.evaluation.pascal_voc_evaluation INFO: bear has 2164 predictions.
[05/08 11:09:13] d2.evaluation.pascal_voc_evaluation INFO: zebra has 789 predictions.
[05/08 11:09:13] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 781 predictions.
[05/08 11:09:13] d2.evaluation.pascal_voc_evaluation INFO: backpack has 4158 predictions.
[05/08 11:09:13] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 2733 predictions.
[05/08 11:09:14] d2.evaluation.pascal_voc_evaluation INFO: handbag has 4751 predictions.
[05/08 11:09:14] d2.evaluation.pascal_voc_evaluation INFO: tie has 839 predictions.
[05/08 11:09:14] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 2982 predictions.
[05/08 11:09:15] d2.evaluation.pascal_voc_evaluation INFO: microwave has 4451 predictions.
[05/08 11:09:15] d2.evaluation.pascal_voc_evaluation INFO: oven has 6436 predictions.
[05/08 11:09:15] d2.evaluation.pascal_voc_evaluation INFO: toaster has 4255 predictions.
[05/08 11:09:16] d2.evaluation.pascal_voc_evaluation INFO: sink has 4582 predictions.
[05/08 11:09:16] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 4992 predictions.
[05/08 11:09:16] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 2017 predictions.
[05/08 11:09:17] d2.evaluation.pascal_voc_evaluation INFO: skis has 1692 predictions.
[05/08 11:09:17] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 2189 predictions.
[05/08 11:09:17] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 2191 predictions.
[05/08 11:09:17] d2.evaluation.pascal_voc_evaluation INFO: kite has 3054 predictions.
[05/08 11:09:17] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1544 predictions.
[05/08 11:09:18] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 1887 predictions.
[05/08 11:09:18] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 2909 predictions.
[05/08 11:09:18] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 3029 predictions.
[05/08 11:09:19] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1329 predictions.
[05/08 11:09:19] d2.evaluation.pascal_voc_evaluation INFO: banana has 2356 predictions.
[05/08 11:09:19] d2.evaluation.pascal_voc_evaluation INFO: apple has 2402 predictions.
[05/08 11:09:19] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 2878 predictions.
[05/08 11:09:20] d2.evaluation.pascal_voc_evaluation INFO: orange has 2086 predictions.
[05/08 11:09:20] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 2705 predictions.
[05/08 11:09:20] d2.evaluation.pascal_voc_evaluation INFO: carrot has 2386 predictions.
[05/08 11:09:21] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 2138 predictions.
[05/08 11:09:21] d2.evaluation.pascal_voc_evaluation INFO: pizza has 2069 predictions.
[05/08 11:09:21] d2.evaluation.pascal_voc_evaluation INFO: donut has 3486 predictions.
[05/08 11:09:21] d2.evaluation.pascal_voc_evaluation INFO: cake has 4799 predictions.
[05/08 11:09:22] d2.evaluation.pascal_voc_evaluation INFO: bed has 1 predictions.
[05/08 11:09:22] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1 predictions.
[05/08 11:09:22] d2.evaluation.pascal_voc_evaluation INFO: laptop has 1 predictions.
[05/08 11:09:22] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1 predictions.
[05/08 11:09:23] d2.evaluation.pascal_voc_evaluation INFO: remote has 1 predictions.
[05/08 11:09:23] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1 predictions.
[05/08 11:09:23] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 1 predictions.
[05/08 11:09:23] d2.evaluation.pascal_voc_evaluation INFO: book has 1 predictions.
[05/08 11:09:23] d2.evaluation.pascal_voc_evaluation INFO: clock has 1 predictions.
[05/08 11:09:24] d2.evaluation.pascal_voc_evaluation INFO: vase has 1 predictions.
[05/08 11:09:24] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1 predictions.
[05/08 11:09:24] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 1 predictions.
[05/08 11:09:24] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1 predictions.
[05/08 11:09:25] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1 predictions.
[05/08 11:09:25] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 1 predictions.
[05/08 11:09:25] d2.evaluation.pascal_voc_evaluation INFO: cup has 1 predictions.
[05/08 11:09:25] d2.evaluation.pascal_voc_evaluation INFO: fork has 1 predictions.
[05/08 11:09:25] d2.evaluation.pascal_voc_evaluation INFO: knife has 1 predictions.
[05/08 11:09:26] d2.evaluation.pascal_voc_evaluation INFO: spoon has 1 predictions.
[05/08 11:09:26] d2.evaluation.pascal_voc_evaluation INFO: bowl has 1 predictions.
[05/08 11:09:26] d2.evaluation.pascal_voc_evaluation INFO: unknown has 64007 predictions.
[05/08 11:09:28] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.007744076703235917}, 0.2: {50: 0.014433763459484427}, 0.3: {50: 0.0046738246638173}, 0.4: {50: 0.009272831439067822}, 0.5: {50: 0.009272591285261948}, 0.6: {50: 0.00952583130683517}, 0.7: {50: 0.00920912441489989}, 0.8: {50: 0.00920418551987821}, 0.9: {50: 0.009201998537199455}}
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.010065322529991835}, 0.2: {50: 0.010065322529991835}, 0.3: {50: 0.010065322529991835}, 0.4: {50: 0.010065322529991835}, 0.5: {50: 0.010065322529991835}, 0.6: {50: 0.010065322529991835}, 0.7: {50: 0.010065322529991835}, 0.8: {50: 0.010065322529991835}, 0.9: {50: 0.010065322529991835}}
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 6234.0}
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 9299
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['67.5', '52.5', '47.3', '34.5', '22.1', '63.3', '50.7', '70.5', '17.5', '67.1', '15.2', '69.6', '78.0', '64.7', '46.7', '23.9', '61.9', '44.8', '71.8', '50.4', '14.0', '10.5', '49.3', '46.8', '42.2', '7.9', '57.3', '49.8', '70.2', '75.6', '2.9', '14.6', '1.4', '4.6', '8.4', '9.6', '5.7', '3.4', '8.0', '14.6', '29.6', '5.9', '10.7', '23.3', '17.7', '5.3', '12.6', '16.2', '16.3', '26.4', '8.7', '4.0', '9.1', '9.8', '9.3', '3.5', '5.1', '15.0', '13.6', '6.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1']
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['18.1', '20.5', '17.8', '8.7', '6.9', '11.5', '11.4', '22.3', '7.2', '19.2', '4.8', '19.9', '21.6', '19.3', '17.0', '9.1', '22.5', '7.2', '13.5', '15.2', '3.1', '5.2', '4.4', '3.5', '2.1', '2.4', '14.9', '2.9', '27.8', '24.3', '2.8', '6.6', '1.9', '5.2', '3.5', '1.0', '1.4', '0.1', '3.0', '1.8', '3.8', '4.4', '1.6', '5.8', '6.6', '3.1', '2.5', '3.3', '4.6', '8.2', '6.5', '3.6', '4.0', '7.0', '6.7', '6.1', '3.0', '9.8', '5.1', '3.7', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0']
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['83.9', '65.9', '62.5', '60.2', '42.7', '84.8', '68.6', '86.5', '38.6', '81.4', '41.8', '88.0', '87.5', '79.0', '65.4', '59.3', '78.6', '72.4', '89.6', '73.7', '61.0', '32.6', '59.3', '67.5', '65.1', '23.3', '78.8', '84.9', '81.1', '81.2', '20.5', '34.9', '11.9', '12.0', '29.3', '43.0', '30.5', '35.3', '32.2', '42.5', '55.1', '23.5', '42.2', '39.3', '42.4', '24.6', '27.0', '41.2', '45.3', '41.0', '26.3', '22.1', '34.3', '30.0', '33.3', '20.2', '30.5', '39.2', '34.0', '27.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '6.9']
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Prev class AP50: 37.92238972502251
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Prev class Precisions50: 10.298918055424235
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Prev class Recall50: 58.43152781475631
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 12.400080321558978
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 4.961785990501742
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 33.914978855386906
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 29.414953257201333
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 8.519874033783404
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 50.259344828299845
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: 0.11519434482358529
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 1.0014529660818348
[05/08 11:09:29] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: 6.893214324120874
[05/08 11:09:29] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 11:09:29] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 11:09:29] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 11:09:29] d2.evaluation.testing INFO: copypaste: 21.7903,21.7903
