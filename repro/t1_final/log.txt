[05/08 10:26:53] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 10:26:54] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 10:26:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t1/t1_val.yaml', dist_url='tcp://127.0.0.1:52133', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.01', 'OWOD.TEMPERATURE', '1.5', 'OUTPUT_DIR', './output/t1_final'], resume=False)
[05/08 10:26:54] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t1/t1_val.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/t1_clustering_with_save/model_final.pth"
DATASETS:
  TRAIN: ('voc_coco_2007_val', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_val', )   # voc_coco_2007_test
SOLVER:
  STEPS: (12000, 16000)
  MAX_ITER: 500
  WARMUP_ITERS: 0
OUTPUT_DIR: "./output/temp_3"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20
  COMPUTE_ENERGY: True
  ENERGY_SAVE_PATH: 'energy'
  SKIP_TRAINING_WHILE_EVAL: False
  ENABLE_CLUSTERING: False
  TEMPERATURE: 1.5
[05/08 10:26:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_val',)
  TRAIN: ('voc_coco_2007_val',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/t1_clustering_with_save/model_final.pth
OUTPUT_DIR: ./output/t1_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: True
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: False
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: energy
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 500
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 10:26:54] detectron2 INFO: Full config saved to ./output/t1_final/config.yaml
[05/08 10:26:54] d2.utils.env INFO: Using a generated random seed 54956683
[05/08 10:26:55] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
[05/08 10:26:55] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t1_final/feature_store/feat.pt. Creating new feature store.
[05/08 10:26:55] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 10:26:56] d2.data.build INFO: Removed 0 images with no usable annotations. 4000 images left.
[05/08 10:26:56] d2.data.build INFO: Known classes: range(0, 20)
[05/08 10:26:56] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 10:26:56] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 90           |    bicycle    | 215          |    bird    | 206          |
|     boat      | 165          |    bottle     | 1146         |    bus     | 157          |
|      car      | 1218         |      cat      | 174          |   chair    | 1531         |
|      cow      | 88           |  diningtable  | 693          |    dog     | 247          |
|     horse     | 105          |   motorbike   | 252          |   person   | 8393         |
|  pottedplant  | 314          |     sheep     | 163          |    sofa    | 258          |
|     train     | 86           |   tvmonitor   | 269          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 12841        |
|               |              |               |              |            |              |
|     total     | 28611        |               |              |            |              |[0m
[05/08 10:26:56] d2.data.build INFO: Number of datapoints: 4000
[05/08 10:26:56] d2.data.common INFO: Serializing 4000 elements to byte tensors and concatenating them all ...
[05/08 10:26:56] d2.data.common INFO: Serialized dataset takes 2.86 MiB
[05/08 10:26:56] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[05/08 10:26:56] d2.data.build INFO: Using training sampler TrainingSampler
[05/08 10:26:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/t1_clustering_with_save/model_final.pth ...
[05/08 10:26:56] d2.engine.train_loop INFO: Starting training from iteration 0
[05/08 10:27:13] d2.utils.events INFO:  eta: 0:03:45  iter: 19  total_loss: 1.06  loss_cls: 0.3298  loss_box_reg: 0.3478  loss_clustering: 0  loss_rpn_cls: 0.191  loss_rpn_loc: 0.1111  time: 0.4718  data_time: 0.3428  lr: 0.01  max_mem: 2522M
[05/08 10:27:22] d2.utils.events INFO:  eta: 0:03:35  iter: 39  total_loss: 0.9261  loss_cls: 0.2681  loss_box_reg: 0.3212  loss_clustering: 0  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.133  time: 0.4693  data_time: 0.0033  lr: 0.01  max_mem: 2567M
[05/08 10:27:31] d2.utils.events INFO:  eta: 0:03:25  iter: 59  total_loss: 1.001  loss_cls: 0.2958  loss_box_reg: 0.3822  loss_clustering: 0  loss_rpn_cls: 0.2005  loss_rpn_loc: 0.1443  time: 0.4686  data_time: 0.0036  lr: 0.01  max_mem: 2610M
[05/08 10:27:41] d2.utils.events INFO:  eta: 0:03:16  iter: 79  total_loss: 0.8854  loss_cls: 0.2732  loss_box_reg: 0.2996  loss_clustering: 0  loss_rpn_cls: 0.1693  loss_rpn_loc: 0.143  time: 0.4680  data_time: 0.0033  lr: 0.01  max_mem: 2610M
[05/08 10:27:50] d2.utils.events INFO:  eta: 0:03:07  iter: 99  total_loss: 0.8977  loss_cls: 0.2441  loss_box_reg: 0.2788  loss_clustering: 0  loss_rpn_cls: 0.1743  loss_rpn_loc: 0.1262  time: 0.4691  data_time: 0.0033  lr: 0.01  max_mem: 2617M
[05/08 10:28:00] d2.utils.events INFO:  eta: 0:02:58  iter: 119  total_loss: 0.9708  loss_cls: 0.3201  loss_box_reg: 0.3211  loss_clustering: 0  loss_rpn_cls: 0.1701  loss_rpn_loc: 0.1268  time: 0.4698  data_time: 0.0033  lr: 0.01  max_mem: 2617M
[05/08 10:28:09] d2.utils.events INFO:  eta: 0:02:49  iter: 139  total_loss: 1.064  loss_cls: 0.3259  loss_box_reg: 0.3645  loss_clustering: 0  loss_rpn_cls: 0.1926  loss_rpn_loc: 0.1803  time: 0.4711  data_time: 0.0035  lr: 0.01  max_mem: 2617M
[05/08 10:28:19] d2.utils.events INFO:  eta: 0:02:40  iter: 159  total_loss: 0.8702  loss_cls: 0.261  loss_box_reg: 0.32  loss_clustering: 0  loss_rpn_cls: 0.1702  loss_rpn_loc: 0.1535  time: 0.4713  data_time: 0.0033  lr: 0.01  max_mem: 2617M
[05/08 10:28:28] d2.utils.events INFO:  eta: 0:02:30  iter: 179  total_loss: 1.049  loss_cls: 0.2935  loss_box_reg: 0.3509  loss_clustering: 0  loss_rpn_cls: 0.2102  loss_rpn_loc: 0.1744  time: 0.4711  data_time: 0.0035  lr: 0.01  max_mem: 2617M
[05/08 10:28:38] d2.utils.events INFO:  eta: 0:02:21  iter: 199  total_loss: 0.8499  loss_cls: 0.244  loss_box_reg: 0.2682  loss_clustering: 0  loss_rpn_cls: 0.1741  loss_rpn_loc: 0.1586  time: 0.4717  data_time: 0.0033  lr: 0.01  max_mem: 2617M
[05/08 10:28:48] d2.utils.events INFO:  eta: 0:02:11  iter: 219  total_loss: 0.9212  loss_cls: 0.2758  loss_box_reg: 0.304  loss_clustering: 0  loss_rpn_cls: 0.1722  loss_rpn_loc: 0.146  time: 0.4722  data_time: 0.0035  lr: 0.01  max_mem: 2617M
[05/08 10:28:57] d2.utils.events INFO:  eta: 0:02:02  iter: 239  total_loss: 0.9604  loss_cls: 0.2734  loss_box_reg: 0.3069  loss_clustering: 0  loss_rpn_cls: 0.1896  loss_rpn_loc: 0.178  time: 0.4726  data_time: 0.0032  lr: 0.01  max_mem: 2619M
[05/08 10:29:07] d2.utils.events INFO:  eta: 0:01:53  iter: 259  total_loss: 0.9471  loss_cls: 0.2856  loss_box_reg: 0.3441  loss_clustering: 0  loss_rpn_cls: 0.1806  loss_rpn_loc: 0.1392  time: 0.4729  data_time: 0.0033  lr: 0.01  max_mem: 2619M
[05/08 10:29:16] d2.utils.events INFO:  eta: 0:01:44  iter: 279  total_loss: 1.024  loss_cls: 0.3245  loss_box_reg: 0.3683  loss_clustering: 0  loss_rpn_cls: 0.1884  loss_rpn_loc: 0.1652  time: 0.4735  data_time: 0.0034  lr: 0.01  max_mem: 2619M
[05/08 10:29:26] d2.utils.events INFO:  eta: 0:01:34  iter: 299  total_loss: 0.949  loss_cls: 0.2671  loss_box_reg: 0.3128  loss_clustering: 0  loss_rpn_cls: 0.1895  loss_rpn_loc: 0.1601  time: 0.4742  data_time: 0.0035  lr: 0.01  max_mem: 2619M
[05/08 10:29:36] d2.utils.events INFO:  eta: 0:01:25  iter: 319  total_loss: 0.987  loss_cls: 0.3109  loss_box_reg: 0.3442  loss_clustering: 0  loss_rpn_cls: 0.2034  loss_rpn_loc: 0.1469  time: 0.4743  data_time: 0.0036  lr: 0.01  max_mem: 2619M
[05/08 10:29:45] d2.utils.events INFO:  eta: 0:01:15  iter: 339  total_loss: 0.9203  loss_cls: 0.2759  loss_box_reg: 0.3141  loss_clustering: 0  loss_rpn_cls: 0.1713  loss_rpn_loc: 0.1743  time: 0.4747  data_time: 0.0036  lr: 0.01  max_mem: 2619M
[05/08 10:29:55] d2.utils.events INFO:  eta: 0:01:06  iter: 359  total_loss: 1.066  loss_cls: 0.3137  loss_box_reg: 0.3813  loss_clustering: 0  loss_rpn_cls: 0.1853  loss_rpn_loc: 0.1512  time: 0.4747  data_time: 0.0036  lr: 0.01  max_mem: 2619M
[05/08 10:30:05] d2.utils.events INFO:  eta: 0:00:56  iter: 379  total_loss: 0.9825  loss_cls: 0.315  loss_box_reg: 0.3646  loss_clustering: 0  loss_rpn_cls: 0.1619  loss_rpn_loc: 0.1421  time: 0.4751  data_time: 0.0035  lr: 0.01  max_mem: 2619M
[05/08 10:30:14] d2.utils.events INFO:  eta: 0:00:47  iter: 399  total_loss: 1.179  loss_cls: 0.3351  loss_box_reg: 0.3991  loss_clustering: 0  loss_rpn_cls: 0.193  loss_rpn_loc: 0.1823  time: 0.4754  data_time: 0.0034  lr: 0.01  max_mem: 2619M
[05/08 10:30:24] d2.utils.events INFO:  eta: 0:00:37  iter: 419  total_loss: 0.9609  loss_cls: 0.2813  loss_box_reg: 0.3492  loss_clustering: 0  loss_rpn_cls: 0.1784  loss_rpn_loc: 0.159  time: 0.4758  data_time: 0.0033  lr: 0.01  max_mem: 2619M
[05/08 10:30:34] d2.utils.events INFO:  eta: 0:00:28  iter: 439  total_loss: 1.111  loss_cls: 0.3345  loss_box_reg: 0.408  loss_clustering: 0  loss_rpn_cls: 0.1949  loss_rpn_loc: 0.147  time: 0.4761  data_time: 0.0035  lr: 0.01  max_mem: 2619M
[05/08 10:30:43] d2.utils.events INFO:  eta: 0:00:19  iter: 459  total_loss: 1.009  loss_cls: 0.2838  loss_box_reg: 0.3765  loss_clustering: 0  loss_rpn_cls: 0.1774  loss_rpn_loc: 0.1552  time: 0.4762  data_time: 0.0033  lr: 0.01  max_mem: 2619M
[05/08 10:30:53] d2.utils.events INFO:  eta: 0:00:09  iter: 479  total_loss: 0.909  loss_cls: 0.2652  loss_box_reg: 0.3156  loss_clustering: 0  loss_rpn_cls: 0.1803  loss_rpn_loc: 0.1473  time: 0.4766  data_time: 0.0034  lr: 0.01  max_mem: 2619M
[05/08 10:31:03] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/t1_final/model_final.pth
[05/08 10:31:04] d2.utils.events INFO:  eta: 0:00:00  iter: 499  total_loss: 0.8767  loss_cls: 0.2366  loss_box_reg: 0.2933  loss_clustering: 0  loss_rpn_cls: 0.1835  loss_rpn_loc: 0.1751  time: 0.4769  data_time: 0.0033  lr: 0.01  max_mem: 2619M
[05/08 10:31:04] d2.engine.train_loop INFO: Going to analyse the energy files...
[05/08 10:31:04] d2.engine.train_loop INFO: Temperature value: 1.5
[05/08 10:31:06] d2.engine.train_loop INFO: Analysing 0 / 2000
[05/08 10:31:15] d2.engine.train_loop INFO: Analysing 100 / 2000
[05/08 10:31:20] d2.engine.train_loop INFO: Analysing 200 / 2000
[05/08 10:31:24] d2.engine.train_loop INFO: Analysing 300 / 2000
[05/08 10:31:29] d2.engine.train_loop INFO: Analysing 400 / 2000
[05/08 10:31:34] d2.engine.train_loop INFO: Analysing 500 / 2000
[05/08 10:31:38] d2.engine.train_loop INFO: Analysing 600 / 2000
[05/08 10:31:42] d2.engine.train_loop INFO: Analysing 700 / 2000
[05/08 10:31:46] d2.engine.train_loop INFO: Analysing 800 / 2000
[05/08 10:31:50] d2.engine.train_loop INFO: Analysing 900 / 2000
[05/08 10:31:54] d2.engine.train_loop INFO: Analysing 1000 / 2000
[05/08 10:31:59] d2.engine.train_loop INFO: Analysing 1100 / 2000
[05/08 10:32:04] d2.engine.train_loop INFO: Analysing 1200 / 2000
[05/08 10:32:09] d2.engine.train_loop INFO: Analysing 1300 / 2000
[05/08 10:32:14] d2.engine.train_loop INFO: Analysing 1400 / 2000
[05/08 10:32:18] d2.engine.train_loop INFO: Analysing 1500 / 2000
[05/08 10:32:22] d2.engine.train_loop INFO: Analysing 1600 / 2000
[05/08 10:32:26] d2.engine.train_loop INFO: Analysing 1700 / 2000
[05/08 10:32:30] d2.engine.train_loop INFO: Analysing 1800 / 2000
[05/08 10:32:35] d2.engine.train_loop INFO: Analysing 1900 / 2000
[05/08 10:32:39] d2.engine.train_loop INFO: len(unk): 48816
[05/08 10:32:39] d2.engine.train_loop INFO: len(known): 75465
[05/08 10:32:39] d2.engine.train_loop INFO: Fitting Weibull distribution...
[05/08 10:32:41] d2.engine.train_loop INFO: --- 2.002898931503296 seconds ---
[05/08 10:32:43] d2.engine.train_loop INFO: --- 2.231570243835449 seconds ---
[05/08 10:32:43] d2.engine.train_loop INFO: Pickling the parameters to ./output/t1_final/energy_dist_20.pkl
[05/08 10:32:43] d2.engine.train_loop INFO: Plotting the computed energy values...
[05/08 10:32:45] d2.engine.hooks INFO: Overall training speed: 498 iterations in 0:03:57 (0.4770 s / it)
[05/08 10:32:45] d2.engine.hooks INFO: Total training time: 0:05:41 (0:01:43 on hooks)
[05/08 10:32:53] detectron2 INFO: Rank of current process: 0. World size: 4
[05/08 10:32:54] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.5
detectron2              0.2.1 @/DATA/joseph/OWOD/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.6.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.2.0
torchvision             0.7.0 @/DATA/joseph/py_owod/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210423
cv2                     Not found
----------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[05/08 10:32:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/OWOD/t1/t1_test.yaml', dist_url='tcp://127.0.0.1:50155', eval_only=True, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.005', 'OUTPUT_DIR', './output/t1_final'], resume=False)
[05/08 10:32:54] detectron2 INFO: Contents of args.config_file=./configs/OWOD/t1/t1_test.yaml:
_BASE_: "../../Base-RCNN-C4-OWOD.yaml"
MODEL:
  WEIGHTS: "/home/joseph/workspace/OWOD/output/models_backup/t1_clustering_with_save/model_final.pth"
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4
TEST:
  DETECTIONS_PER_IMAGE: 50
DATASETS:
  TRAIN: ('t1_voc_coco_2007_train', ) # t1_voc_coco_2007_train, t1_voc_coco_2007_ft
  TEST: ('voc_coco_2007_test', )   # voc_coco_2007_test
SOLVER:
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
OUTPUT_DIR: "./output/temp_3"
OWOD:
  PREV_INTRODUCED_CLS: 0
  CUR_INTRODUCED_CLS: 20
[05/08 10:32:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('voc_coco_2007_test',)
  TRAIN: ('t1_voc_coco_2007_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 81
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/joseph/workspace/OWOD/output/models_backup/t1_clustering_with_save/model_final.pth
OUTPUT_DIR: ./output/t1_final
OWOD:
  CLUSTERING:
    ITEMS_PER_CLASS: 20
    MARGIN: 10.0
    MOMENTUM: 0.99
    START_ITER: 1000
    UPDATE_MU_ITER: 3000
    Z_DIMENSION: 128
  COMPUTE_ENERGY: False
  CUR_INTRODUCED_CLS: 20
  ENABLE_CLUSTERING: True
  ENABLE_THRESHOLD_AUTOLABEL_UNK: True
  ENABLE_UNCERTAINITY_AUTOLABEL_UNK: False
  ENERGY_SAVE_PATH: 
  FEATURE_STORE_SAVE_PATH: feature_store
  NUM_UNK_PER_IMAGE: 1
  PREV_INTRODUCED_CLS: 0
  SKIP_TRAINING_WHILE_EVAL: False
  TEMPERATURE: 1.5
SEED: -1
SOLVER:
  BASE_LR: 0.005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 50
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[05/08 10:32:54] detectron2 INFO: Full config saved to ./output/t1_final/config.yaml
[05/08 10:32:54] d2.utils.env INFO: Using a generated random seed 54611310
[05/08 10:32:55] d2.modeling.roi_heads.fast_rcnn INFO: Invalid class range: [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
[05/08 10:32:55] d2.modeling.roi_heads.fast_rcnn INFO: Feature store not found in ./output/t1_final/feature_store/feat.pt. Creating new feature store.
[05/08 10:32:55] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=82, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=324, bias=True)
      (hingeloss): HingeEmbeddingLoss()
    )
  )
)
[05/08 10:32:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/joseph/workspace/OWOD/output/models_backup/t1_clustering_with_save/model_final.pth ...
[05/08 10:32:57] d2.data.build INFO: Known classes: range(0, 20)
[05/08 10:32:57] d2.data.build INFO: Labelling known instances the corresponding label, and unknown instances as unknown...
[05/08 10:32:57] d2.data.build INFO: Distribution of instances among all 81 categories:
[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|   aeroplane   | 361          |    bicycle    | 700          |    bird    | 800          |
|     boat      | 607          |    bottle     | 2339         |    bus     | 429          |
|      car      | 3463         |      cat      | 522          |   chair    | 3996         |
|      cow      | 392          |  diningtable  | 1477         |    dog     | 697          |
|     horse     | 455          |   motorbike   | 587          |   person   | 18378        |
|  pottedplant  | 1043         |     sheep     | 387          |    sofa    | 686          |
|     train     | 385          |   tvmonitor   | 683          |   truck    | 0            |
| traffic light | 0            | fire hydrant  | 0            | stop sign  | 0            |
| parking meter | 0            |     bench     | 0            |  elephant  | 0            |
|     bear      | 0            |     zebra     | 0            |  giraffe   | 0            |
|   backpack    | 0            |   umbrella    | 0            |  handbag   | 0            |
|      tie      | 0            |   suitcase    | 0            | microwave  | 0            |
|     oven      | 0            |    toaster    | 0            |    sink    | 0            |
| refrigerator  | 0            |    frisbee    | 0            |    skis    | 0            |
|   snowboard   | 0            |  sports ball  | 0            |    kite    | 0            |
| baseball bat  | 0            | baseball gl.. | 0            | skateboard | 0            |
|   surfboard   | 0            | tennis racket | 0            |   banana   | 0            |
|     apple     | 0            |   sandwich    | 0            |   orange   | 0            |
|   broccoli    | 0            |    carrot     | 0            |  hot dog   | 0            |
|     pizza     | 0            |     donut     | 0            |    cake    | 0            |
|      bed      | 0            |    toilet     | 0            |   laptop   | 0            |
|     mouse     | 0            |    remote     | 0            |  keyboard  | 0            |
|  cell phone   | 0            |     book      | 0            |   clock    | 0            |
|     vase      | 0            |   scissors    | 0            | teddy bear | 0            |
|  hair drier   | 0            |  toothbrush   | 0            | wine glass | 0            |
|      cup      | 0            |     fork      | 0            |   knife    | 0            |
|     spoon     | 0            |     bowl      | 0            |  unknown   | 23320        |
|               |              |               |              |            |              |
|     total     | 61707        |               |              |            |              |[0m
[05/08 10:32:57] d2.data.build INFO: Number of datapoints: 10246
[05/08 10:32:57] d2.data.common INFO: Serializing 10246 elements to byte tensors and concatenating them all ...
[05/08 10:32:57] d2.data.common INFO: Serialized dataset takes 6.62 MiB
[05/08 10:32:57] d2.data.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/08 10:32:57] d2.evaluation.pascal_voc_evaluation INFO: Loading energy distribution from ./output/t1_final/energy_dist_20.pkl
[05/08 10:32:57] d2.evaluation.evaluator INFO: Start inference on 2562 images
[05/08 10:33:06] d2.evaluation.evaluator INFO: Inference done 11/2562. 0.1145 s / img. ETA=0:05:07
[05/08 10:33:11] d2.evaluation.evaluator INFO: Inference done 51/2562. 0.1191 s / img. ETA=0:05:15
[05/08 10:33:16] d2.evaluation.evaluator INFO: Inference done 89/2562. 0.1206 s / img. ETA=0:05:18
[05/08 10:33:21] d2.evaluation.evaluator INFO: Inference done 123/2562. 0.1257 s / img. ETA=0:05:28
[05/08 10:33:26] d2.evaluation.evaluator INFO: Inference done 160/2562. 0.1263 s / img. ETA=0:05:25
[05/08 10:33:31] d2.evaluation.evaluator INFO: Inference done 195/2562. 0.1279 s / img. ETA=0:05:23
[05/08 10:33:36] d2.evaluation.evaluator INFO: Inference done 235/2562. 0.1267 s / img. ETA=0:05:14
[05/08 10:33:41] d2.evaluation.evaluator INFO: Inference done 272/2562. 0.1267 s / img. ETA=0:05:09
[05/08 10:33:46] d2.evaluation.evaluator INFO: Inference done 308/2562. 0.1273 s / img. ETA=0:05:06
[05/08 10:33:51] d2.evaluation.evaluator INFO: Inference done 346/2562. 0.1269 s / img. ETA=0:05:00
[05/08 10:33:56] d2.evaluation.evaluator INFO: Inference done 381/2562. 0.1276 s / img. ETA=0:04:57
[05/08 10:34:01] d2.evaluation.evaluator INFO: Inference done 420/2562. 0.1272 s / img. ETA=0:04:50
[05/08 10:34:06] d2.evaluation.evaluator INFO: Inference done 458/2562. 0.1269 s / img. ETA=0:04:44
[05/08 10:34:11] d2.evaluation.evaluator INFO: Inference done 498/2562. 0.1261 s / img. ETA=0:04:37
[05/08 10:34:16] d2.evaluation.evaluator INFO: Inference done 537/2562. 0.1260 s / img. ETA=0:04:31
[05/08 10:34:21] d2.evaluation.evaluator INFO: Inference done 576/2562. 0.1256 s / img. ETA=0:04:26
[05/08 10:34:26] d2.evaluation.evaluator INFO: Inference done 611/2562. 0.1261 s / img. ETA=0:04:22
[05/08 10:34:32] d2.evaluation.evaluator INFO: Inference done 648/2562. 0.1262 s / img. ETA=0:04:17
[05/08 10:34:37] d2.evaluation.evaluator INFO: Inference done 687/2562. 0.1260 s / img. ETA=0:04:12
[05/08 10:34:42] d2.evaluation.evaluator INFO: Inference done 723/2562. 0.1263 s / img. ETA=0:04:07
[05/08 10:34:47] d2.evaluation.evaluator INFO: Inference done 759/2562. 0.1265 s / img. ETA=0:04:03
[05/08 10:34:52] d2.evaluation.evaluator INFO: Inference done 797/2562. 0.1265 s / img. ETA=0:03:58
[05/08 10:34:57] d2.evaluation.evaluator INFO: Inference done 834/2562. 0.1267 s / img. ETA=0:03:53
[05/08 10:35:02] d2.evaluation.evaluator INFO: Inference done 870/2562. 0.1269 s / img. ETA=0:03:48
[05/08 10:35:07] d2.evaluation.evaluator INFO: Inference done 908/2562. 0.1267 s / img. ETA=0:03:43
[05/08 10:35:12] d2.evaluation.evaluator INFO: Inference done 945/2562. 0.1268 s / img. ETA=0:03:38
[05/08 10:35:17] d2.evaluation.evaluator INFO: Inference done 980/2562. 0.1271 s / img. ETA=0:03:34
[05/08 10:35:22] d2.evaluation.evaluator INFO: Inference done 1020/2562. 0.1267 s / img. ETA=0:03:28
[05/08 10:35:27] d2.evaluation.evaluator INFO: Inference done 1062/2562. 0.1264 s / img. ETA=0:03:22
[05/08 10:35:32] d2.evaluation.evaluator INFO: Inference done 1099/2562. 0.1264 s / img. ETA=0:03:17
[05/08 10:35:37] d2.evaluation.evaluator INFO: Inference done 1135/2562. 0.1265 s / img. ETA=0:03:12
[05/08 10:35:42] d2.evaluation.evaluator INFO: Inference done 1174/2562. 0.1263 s / img. ETA=0:03:07
[05/08 10:35:48] d2.evaluation.evaluator INFO: Inference done 1210/2562. 0.1266 s / img. ETA=0:03:02
[05/08 10:35:53] d2.evaluation.evaluator INFO: Inference done 1247/2562. 0.1267 s / img. ETA=0:02:57
[05/08 10:35:58] d2.evaluation.evaluator INFO: Inference done 1285/2562. 0.1266 s / img. ETA=0:02:52
[05/08 10:36:03] d2.evaluation.evaluator INFO: Inference done 1320/2562. 0.1269 s / img. ETA=0:02:48
[05/08 10:36:08] d2.evaluation.evaluator INFO: Inference done 1354/2562. 0.1271 s / img. ETA=0:02:43
[05/08 10:36:13] d2.evaluation.evaluator INFO: Inference done 1385/2562. 0.1277 s / img. ETA=0:02:40
[05/08 10:36:18] d2.evaluation.evaluator INFO: Inference done 1421/2562. 0.1278 s / img. ETA=0:02:35
[05/08 10:36:23] d2.evaluation.evaluator INFO: Inference done 1459/2562. 0.1277 s / img. ETA=0:02:30
[05/08 10:36:28] d2.evaluation.evaluator INFO: Inference done 1497/2562. 0.1276 s / img. ETA=0:02:25
[05/08 10:36:33] d2.evaluation.evaluator INFO: Inference done 1535/2562. 0.1275 s / img. ETA=0:02:19
[05/08 10:36:38] d2.evaluation.evaluator INFO: Inference done 1573/2562. 0.1274 s / img. ETA=0:02:14
[05/08 10:36:43] d2.evaluation.evaluator INFO: Inference done 1612/2562. 0.1273 s / img. ETA=0:02:09
[05/08 10:36:48] d2.evaluation.evaluator INFO: Inference done 1651/2562. 0.1271 s / img. ETA=0:02:03
[05/08 10:36:53] d2.evaluation.evaluator INFO: Inference done 1689/2562. 0.1271 s / img. ETA=0:01:58
[05/08 10:36:59] d2.evaluation.evaluator INFO: Inference done 1728/2562. 0.1270 s / img. ETA=0:01:53
[05/08 10:37:04] d2.evaluation.evaluator INFO: Inference done 1760/2562. 0.1274 s / img. ETA=0:01:49
[05/08 10:37:09] d2.evaluation.evaluator INFO: Inference done 1799/2562. 0.1272 s / img. ETA=0:01:43
[05/08 10:37:14] d2.evaluation.evaluator INFO: Inference done 1832/2562. 0.1275 s / img. ETA=0:01:39
[05/08 10:37:19] d2.evaluation.evaluator INFO: Inference done 1870/2562. 0.1275 s / img. ETA=0:01:34
[05/08 10:37:24] d2.evaluation.evaluator INFO: Inference done 1911/2562. 0.1273 s / img. ETA=0:01:28
[05/08 10:37:29] d2.evaluation.evaluator INFO: Inference done 1950/2562. 0.1271 s / img. ETA=0:01:23
[05/08 10:37:34] d2.evaluation.evaluator INFO: Inference done 1988/2562. 0.1271 s / img. ETA=0:01:17
[05/08 10:37:39] d2.evaluation.evaluator INFO: Inference done 2027/2562. 0.1270 s / img. ETA=0:01:12
[05/08 10:37:44] d2.evaluation.evaluator INFO: Inference done 2062/2562. 0.1271 s / img. ETA=0:01:07
[05/08 10:37:49] d2.evaluation.evaluator INFO: Inference done 2100/2562. 0.1271 s / img. ETA=0:01:02
[05/08 10:37:54] d2.evaluation.evaluator INFO: Inference done 2135/2562. 0.1272 s / img. ETA=0:00:58
[05/08 10:37:59] d2.evaluation.evaluator INFO: Inference done 2171/2562. 0.1274 s / img. ETA=0:00:53
[05/08 10:38:04] d2.evaluation.evaluator INFO: Inference done 2209/2562. 0.1273 s / img. ETA=0:00:47
[05/08 10:38:10] d2.evaluation.evaluator INFO: Inference done 2246/2562. 0.1274 s / img. ETA=0:00:42
[05/08 10:38:15] d2.evaluation.evaluator INFO: Inference done 2283/2562. 0.1274 s / img. ETA=0:00:37
[05/08 10:38:20] d2.evaluation.evaluator INFO: Inference done 2321/2562. 0.1273 s / img. ETA=0:00:32
[05/08 10:38:25] d2.evaluation.evaluator INFO: Inference done 2355/2562. 0.1275 s / img. ETA=0:00:28
[05/08 10:38:30] d2.evaluation.evaluator INFO: Inference done 2394/2562. 0.1274 s / img. ETA=0:00:22
[05/08 10:38:35] d2.evaluation.evaluator INFO: Inference done 2431/2562. 0.1274 s / img. ETA=0:00:17
[05/08 10:38:40] d2.evaluation.evaluator INFO: Inference done 2469/2562. 0.1274 s / img. ETA=0:00:12
[05/08 10:38:45] d2.evaluation.evaluator INFO: Inference done 2504/2562. 0.1275 s / img. ETA=0:00:07
[05/08 10:38:50] d2.evaluation.evaluator INFO: Inference done 2540/2562. 0.1276 s / img. ETA=0:00:02
[05/08 10:38:54] d2.evaluation.evaluator INFO: Total inference time: 0:05:48.635271 (0.136345 s / img per device, on 4 devices)
[05/08 10:38:54] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:05:26 (0.127613 s / img per device, on 4 devices)
[05/08 10:39:50] d2.evaluation.pascal_voc_evaluation INFO: Evaluating voc_coco_2007_test using 2012 metric. Note that results do not use the official Matlab API.
[05/08 10:39:50] d2.evaluation.pascal_voc_evaluation INFO: aeroplane has 1975 predictions.
[05/08 10:39:51] d2.evaluation.pascal_voc_evaluation INFO: bicycle has 2556 predictions.
[05/08 10:39:51] d2.evaluation.pascal_voc_evaluation INFO: bird has 3276 predictions.
[05/08 10:39:52] d2.evaluation.pascal_voc_evaluation INFO: boat has 4096 predictions.
[05/08 10:39:52] d2.evaluation.pascal_voc_evaluation INFO: bottle has 6416 predictions.
[05/08 10:39:53] d2.evaluation.pascal_voc_evaluation INFO: bus has 2345 predictions.
[05/08 10:39:53] d2.evaluation.pascal_voc_evaluation INFO: car has 9897 predictions.
[05/08 10:39:54] d2.evaluation.pascal_voc_evaluation INFO: cat has 1808 predictions.
[05/08 10:39:54] d2.evaluation.pascal_voc_evaluation INFO: chair has 16339 predictions.
[05/08 10:39:55] d2.evaluation.pascal_voc_evaluation INFO: cow has 2292 predictions.
[05/08 10:39:55] d2.evaluation.pascal_voc_evaluation INFO: diningtable has 5601 predictions.
[05/08 10:39:56] d2.evaluation.pascal_voc_evaluation INFO: dog has 2819 predictions.
[05/08 10:39:56] d2.evaluation.pascal_voc_evaluation INFO: horse has 2352 predictions.
[05/08 10:39:56] d2.evaluation.pascal_voc_evaluation INFO: motorbike has 2066 predictions.
[05/08 10:39:57] d2.evaluation.pascal_voc_evaluation INFO: person has 43986 predictions.
[05/08 10:40:00] d2.evaluation.pascal_voc_evaluation INFO: pottedplant has 6522 predictions.
[05/08 10:40:00] d2.evaluation.pascal_voc_evaluation INFO: sheep has 2240 predictions.
[05/08 10:40:00] d2.evaluation.pascal_voc_evaluation INFO: sofa has 4394 predictions.
[05/08 10:40:01] d2.evaluation.pascal_voc_evaluation INFO: train has 2537 predictions.
[05/08 10:40:01] d2.evaluation.pascal_voc_evaluation INFO: tvmonitor has 3928 predictions.
[05/08 10:40:02] d2.evaluation.pascal_voc_evaluation INFO: truck has 1 predictions.
[05/08 10:40:02] d2.evaluation.pascal_voc_evaluation INFO: traffic light has 1 predictions.
[05/08 10:40:02] d2.evaluation.pascal_voc_evaluation INFO: fire hydrant has 1 predictions.
[05/08 10:40:02] d2.evaluation.pascal_voc_evaluation INFO: stop sign has 1 predictions.
[05/08 10:40:02] d2.evaluation.pascal_voc_evaluation INFO: parking meter has 1 predictions.
[05/08 10:40:03] d2.evaluation.pascal_voc_evaluation INFO: bench has 1 predictions.
[05/08 10:40:03] d2.evaluation.pascal_voc_evaluation INFO: elephant has 1 predictions.
[05/08 10:40:03] d2.evaluation.pascal_voc_evaluation INFO: bear has 1 predictions.
[05/08 10:40:03] d2.evaluation.pascal_voc_evaluation INFO: zebra has 1 predictions.
[05/08 10:40:04] d2.evaluation.pascal_voc_evaluation INFO: giraffe has 1 predictions.
[05/08 10:40:04] d2.evaluation.pascal_voc_evaluation INFO: backpack has 1 predictions.
[05/08 10:40:04] d2.evaluation.pascal_voc_evaluation INFO: umbrella has 1 predictions.
[05/08 10:40:04] d2.evaluation.pascal_voc_evaluation INFO: handbag has 1 predictions.
[05/08 10:40:05] d2.evaluation.pascal_voc_evaluation INFO: tie has 1 predictions.
[05/08 10:40:05] d2.evaluation.pascal_voc_evaluation INFO: suitcase has 1 predictions.
[05/08 10:40:05] d2.evaluation.pascal_voc_evaluation INFO: microwave has 1 predictions.
[05/08 10:40:05] d2.evaluation.pascal_voc_evaluation INFO: oven has 1 predictions.
[05/08 10:40:06] d2.evaluation.pascal_voc_evaluation INFO: toaster has 1 predictions.
[05/08 10:40:06] d2.evaluation.pascal_voc_evaluation INFO: sink has 1 predictions.
[05/08 10:40:06] d2.evaluation.pascal_voc_evaluation INFO: refrigerator has 1 predictions.
[05/08 10:40:06] d2.evaluation.pascal_voc_evaluation INFO: frisbee has 1 predictions.
[05/08 10:40:07] d2.evaluation.pascal_voc_evaluation INFO: skis has 1 predictions.
[05/08 10:40:07] d2.evaluation.pascal_voc_evaluation INFO: snowboard has 1 predictions.
[05/08 10:40:07] d2.evaluation.pascal_voc_evaluation INFO: sports ball has 1 predictions.
[05/08 10:40:07] d2.evaluation.pascal_voc_evaluation INFO: kite has 1 predictions.
[05/08 10:40:08] d2.evaluation.pascal_voc_evaluation INFO: baseball bat has 1 predictions.
[05/08 10:40:08] d2.evaluation.pascal_voc_evaluation INFO: baseball glove has 1 predictions.
[05/08 10:40:08] d2.evaluation.pascal_voc_evaluation INFO: skateboard has 1 predictions.
[05/08 10:40:08] d2.evaluation.pascal_voc_evaluation INFO: surfboard has 1 predictions.
[05/08 10:40:09] d2.evaluation.pascal_voc_evaluation INFO: tennis racket has 1 predictions.
[05/08 10:40:09] d2.evaluation.pascal_voc_evaluation INFO: banana has 1 predictions.
[05/08 10:40:09] d2.evaluation.pascal_voc_evaluation INFO: apple has 1 predictions.
[05/08 10:40:09] d2.evaluation.pascal_voc_evaluation INFO: sandwich has 1 predictions.
[05/08 10:40:10] d2.evaluation.pascal_voc_evaluation INFO: orange has 1 predictions.
[05/08 10:40:10] d2.evaluation.pascal_voc_evaluation INFO: broccoli has 1 predictions.
[05/08 10:40:10] d2.evaluation.pascal_voc_evaluation INFO: carrot has 1 predictions.
[05/08 10:40:10] d2.evaluation.pascal_voc_evaluation INFO: hot dog has 1 predictions.
[05/08 10:40:11] d2.evaluation.pascal_voc_evaluation INFO: pizza has 1 predictions.
[05/08 10:40:11] d2.evaluation.pascal_voc_evaluation INFO: donut has 1 predictions.
[05/08 10:40:11] d2.evaluation.pascal_voc_evaluation INFO: cake has 1 predictions.
[05/08 10:40:11] d2.evaluation.pascal_voc_evaluation INFO: bed has 1 predictions.
[05/08 10:40:12] d2.evaluation.pascal_voc_evaluation INFO: toilet has 1 predictions.
[05/08 10:40:12] d2.evaluation.pascal_voc_evaluation INFO: laptop has 1 predictions.
[05/08 10:40:12] d2.evaluation.pascal_voc_evaluation INFO: mouse has 1 predictions.
[05/08 10:40:12] d2.evaluation.pascal_voc_evaluation INFO: remote has 1 predictions.
[05/08 10:40:13] d2.evaluation.pascal_voc_evaluation INFO: keyboard has 1 predictions.
[05/08 10:40:13] d2.evaluation.pascal_voc_evaluation INFO: cell phone has 1 predictions.
[05/08 10:40:13] d2.evaluation.pascal_voc_evaluation INFO: book has 1 predictions.
[05/08 10:40:13] d2.evaluation.pascal_voc_evaluation INFO: clock has 1 predictions.
[05/08 10:40:14] d2.evaluation.pascal_voc_evaluation INFO: vase has 1 predictions.
[05/08 10:40:14] d2.evaluation.pascal_voc_evaluation INFO: scissors has 1 predictions.
[05/08 10:40:14] d2.evaluation.pascal_voc_evaluation INFO: teddy bear has 1 predictions.
[05/08 10:40:14] d2.evaluation.pascal_voc_evaluation INFO: hair drier has 1 predictions.
[05/08 10:40:15] d2.evaluation.pascal_voc_evaluation INFO: toothbrush has 1 predictions.
[05/08 10:40:15] d2.evaluation.pascal_voc_evaluation INFO: wine glass has 1 predictions.
[05/08 10:40:15] d2.evaluation.pascal_voc_evaluation INFO: cup has 1 predictions.
[05/08 10:40:15] d2.evaluation.pascal_voc_evaluation INFO: fork has 1 predictions.
[05/08 10:40:16] d2.evaluation.pascal_voc_evaluation INFO: knife has 1 predictions.
[05/08 10:40:16] d2.evaluation.pascal_voc_evaluation INFO: spoon has 1 predictions.
[05/08 10:40:16] d2.evaluation.pascal_voc_evaluation INFO: bowl has 1 predictions.
[05/08 10:40:16] d2.evaluation.pascal_voc_evaluation INFO: unknown has 33398 predictions.
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Wilderness Impact: {0.1: {50: 0.016233766233766236}, 0.2: {50: 0.02221516978736909}, 0.3: {50: 0.03897826212304676}, 0.4: {50: 0.05032632000565464}, 0.5: {50: 0.049384489125974554}, 0.6: {50: 0.03855823809884205}, 0.7: {50: 0.030828969119560226}, 0.8: {50: 0.022213126464122256}, 0.9: {50: 0.03572568363901211}}
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: avg_precision: {0.1: {50: 0.06045938307979075}, 0.2: {50: 0.06045938307979075}, 0.3: {50: 0.06045938307979075}, 0.4: {50: 0.06045938307979075}, 0.5: {50: 0.06045938307979075}, 0.6: {50: 0.06045938307979075}, 0.7: {50: 0.06045938307979075}, 0.8: {50: 0.06045938307979075}, 0.9: {50: 0.06045938307979075}}
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Absolute OSE (total_num_unk_det_as_known): {50: 7185.0}
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: total_num_unk 23320
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'truck', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'bed', 'toilet', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'unknown']
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: AP50: ['79.5', '56.5', '58.4', '43.0', '24.1', '71.7', '54.3', '80.9', '20.3', '70.0', '16.1', '77.8', '80.3', '66.9', '46.7', '30.6', '67.4', '48.0', '76.4', '56.8', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.2']
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Precisions50: ['15.4', '17.2', '15.0', '7.9', '13.6', '14.4', '21.5', '25.8', '8.4', '11.8', '9.7', '21.3', '16.3', '20.7', '26.1', '9.2', '11.9', '9.2', '12.9', '12.5', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '6.0']
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Recall50: ['90.1', '67.3', '71.0', '66.5', '40.1', '86.6', '66.4', '91.0', '39.5', '85.7', '38.7', '90.9', '92.6', '77.7', '64.1', '63.6', '82.7', '73.9', '89.0', '77.6', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '8.6']
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Current class AP50: 56.27120252374192
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Current class Precisions50: 15.041341850296462
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Current class Recall50: 72.75154196469228
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Known AP50: 56.27120252374192
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Known Precisions50: 15.041341850296462
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Known Recall50: 72.75154196469228
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Unknown AP50: 1.1752642016886532
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Unknown Precisions50: 6.02131864183484
[05/08 10:40:18] d2.evaluation.pascal_voc_evaluation INFO: Unknown Recall50: 8.623499142367066
[05/08 10:40:18] d2.engine.defaults INFO: Evaluation results for voc_coco_2007_test in csv format:
[05/08 10:40:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[05/08 10:40:18] d2.evaluation.testing INFO: copypaste: AP,AP50
[05/08 10:40:18] d2.evaluation.testing INFO: copypaste: 13.9086,13.9086
